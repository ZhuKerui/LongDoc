{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../..')\n",
    "\n",
    "from src.index_files import *\n",
    "# from src.corenlp_base import Doc, Mention, Sentence\n",
    "# from huggingface_hub import login\n",
    "# login(os.environ['HF_TOKEN'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = QualityDataset(split='dev')\n",
    "f = Factory(chunk_size=300, llm_name='meta-llama/Llama-2-7b-chat-hf')\n",
    "tokenizer = AutoTokenizer.from_pretrained(f.llm_name)\n",
    "# article = dataset.get_article(dataset.data[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline 32k QA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "templates = {\n",
    "    \"narrativeqa\": \"You are given a story, which can be either a novel or a movie script, and a question. Answer the question asconcisely as you can, using a single phrase if possible. Do not provide any explanation.\\n\\nStory: {context}\\n\\nNow, answer the question based on the story asconcisely as you can, using a single phrase if possible. Do not provide any explanation.\\n\\nQuestion: {input}\\n\\nAnswer:\",\n",
    "    \"qasper\": \"You are given a scientific article and a question. Answer the question as concisely as you can, using a single phrase or sentence if possible. If the question cannot be answered based on the information in the article, write \\\"unanswerable\\\". If the question is a yes/no question, answer \\\"yes\\\", \\\"no\\\", or \\\"unanswerable\\\". Do not provide any explanation.\\n\\nArticle: {context}\\n\\n Answer the question based on the above article as concisely as you can, using a single phrase or sentence if possible. If the question cannot be answered based on the information in the article, write \\\"unanswerable\\\". If the question is a yes/no question, answer \\\"yes\\\", \\\"no\\\", or \\\"unanswerable\\\". Do not provide any explanation.\\n\\nQuestion: {input}\\n\\nAnswer:\",\n",
    "    \"multifieldqa_en\": \"Read the following text and answer briefly.\\n\\n{context}\\n\\nNow, answer the following question based on the above text, only give me the answer and do not output any other words.\\n\\nQuestion: {input}\\nAnswer:\",\n",
    "    \"multifieldqa_zh\": \"阅读以下文字并用中文简短回答：\\n\\n{context}\\n\\n现在请基于上面的文章回答下面的问题，只告诉我答案，不要输出任何其他字词。\\n\\n问题：{input}\\n回答：\",\n",
    "    \"hotpotqa\": \"Answer the question based on the given passages. Only give me the answer and do not output any other words.\\n\\nThe following are given passages.\\n{context}\\n\\nAnswer the question based on the given passages. Only give me the answer and do not output any other words.\\n\\nQuestion: {input}\\nAnswer:\",\n",
    "    \"2wikimqa\": \"Answer the question based on the given passages. Only give me the answer and do not output any other words.\\n\\nThe following are given passages.\\n{context}\\n\\nAnswer the question based on the given passages. Only give me the answer and do not output any other words.\\n\\nQuestion: {input}\\nAnswer:\",\n",
    "    \"musique\": \"Answer the question based on the given passages. Only give me the answer and do not output any other words.\\n\\nThe following are given passages.\\n{context}\\n\\nAnswer the question based on the given passages. Only give me the answer and do not output any other words.\\n\\nQuestion: {input}\\nAnswer:\",\n",
    "    \"dureader\": \"请基于给定的文章回答下述问题。\\n\\n文章：{context}\\n\\n请基于上述文章回答下面的问题。\\n\\n问题：{input}\\n回答：\",\n",
    "    \"gov_report\": \"You are given a report by a government agency. Write a one-page summary of the report.\\n\\nReport:\\n{context}\\n\\nNow, write a one-page summary of the report.\\n\\nSummary:\",\n",
    "    \"qmsum\": \"You are given a meeting transcript and a query containing a question or instruction. Answer the query in one or more sentences.\\n\\nTranscript:\\n{context}\\n\\nNow, answer the query based on the above meeting transcript in one or more sentences.\\n\\nQuery: {input}\\nAnswer:\",\n",
    "    \"multi_news\": \"You are given several news passages. Write a one-page summary of all news. \\n\\nNews:\\n{context}\\n\\nNow, write a one-page summary of all the news.\\n\\nSummary:\",\n",
    "    \"vcsum\": \"下面有一段会议记录，请你阅读后，写一段总结，总结会议的内容。\\n会议记录：\\n{context}\\n\\n会议总结：\",\n",
    "    \"trec\": \"Please determine the type of the question below. Here are some examples of questions.\\n\\n{context}\\n{input}\",\n",
    "    \"triviaqa\": \"Answer the question based on the given passage. Only give me the answer and do not output any other words. The following are some examples.\\n\\n{context}\\n\\n{input}\",\n",
    "    \"samsum\": \"Summarize the dialogue into a few short sentences. The following are some examples.\\n\\n{context}\\n\\n{input}\",\n",
    "    \"lsht\": \"请判断给定新闻的类别，下面是一些例子。\\n\\n{context}\\n{input}\",\n",
    "    \"passage_count\": \"There are some paragraphs below sourced from Wikipedia. Some of them may be duplicates. Please carefully read these paragraphs and determine how many unique paragraphs there are after removing duplicates. In other words, how many non-repeating paragraphs are there in total?\\n\\n{context}\\n\\nPlease enter the final count of unique paragraphs after removing duplicates. The output format should only contain the number, such as 1, 2, 3, and so on.\\n\\nThe final answer is: \",\n",
    "    \"passage_retrieval_en\": \"Here are 30 paragraphs from Wikipedia, along with an abstract. Please determine which paragraph the abstract is from.\\n\\n{context}\\n\\nThe following is an abstract.\\n\\n{input}\\n\\nPlease enter the number of the paragraph that the abstract is from. The answer format must be like \\\"Paragraph 1\\\", \\\"Paragraph 2\\\", etc.\\n\\nThe answer is: \",\n",
    "    \"passage_retrieval_zh\": \"以下是若干段落文字，以及其中一个段落的摘要。请确定给定的摘要出自哪一段。\\n\\n{context}\\n\\n下面是一个摘要\\n\\n{input}\\n\\n请输入摘要所属段落的编号。答案格式必须是\\\"段落1\\\"，\\\"段落2\\\"等格式\\n\\n答案是：\",\n",
    "    \"lcc\": \"Please complete the code given below. \\n{context}Next line of code:\\n\",\n",
    "    \"repobench-p\": \"Please complete the code given below. \\n{context}{input}Next line of code:\\n\"\n",
    "}\n",
    "\n",
    "# answers = defaultdict(list)\n",
    "# for task in [\"narrativeqa\", \"qasper\", \"multifieldqa_en\", \"hotpotqa\", \"2wikimqa\", \"musique\", \"gov_report\", \"qmsum\"]:\n",
    "#     dataset = []\n",
    "#     for sample in load_dataset('THUDM/LongBench', task, split='test'):\n",
    "#         prompt = templates[task].format(context=sample['context']) if task == 'gov_report' else templates[task].format(context=sample['context'], input=sample['input'])\n",
    "#         if len(tokenizer.encode(prompt)) < 32000 - 500:\n",
    "#             sample['prompt'] = prompt\n",
    "#             dataset.append(sample)\n",
    "#     for i in tqdm(range((len(dataset) + 1) // 5)):\n",
    "#         batch_samples = dataset[i*5 : (i+1)*5]\n",
    "#         for sample, gen in zip(batch_samples, f.llm.generate([[HumanMessage(content=sample['prompt'])] for sample in batch_samples]).generations):\n",
    "#             sample['gen'] = gen[0].text\n",
    "#             sample['token_usage'] = gen[0].message.response_metadata['token_usage']\n",
    "#             answers[task].append(sample)\n",
    "# write_json('baseline.json', answers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 32k Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "templates = {\n",
    "    \"narrativeqa\": \"You are given a story, which can be either a novel or a movie script, and a question. Answer the question asconcisely as you can, using a single phrase if possible. Do not provide any explanation.\\n\\nStory: {context}\\n\\nNow, answer the question based on the story asconcisely as you can, using a single phrase if possible. Do not provide any explanation.\\n\\nQuestion: {input}\\n\\nAnswer:\",\n",
    "    \"qasper\": \"You are given a scientific article and a question. Answer the question as concisely as you can, using a single phrase or sentence if possible. If the question cannot be answered based on the information in the article, write \\\"unanswerable\\\". If the question is a yes/no question, answer \\\"yes\\\", \\\"no\\\", or \\\"unanswerable\\\". Do not provide any explanation.\\n\\nArticle: {context}\\n\\n Answer the question based on the above article as concisely as you can, using a single phrase or sentence if possible. If the question cannot be answered based on the information in the article, write \\\"unanswerable\\\". If the question is a yes/no question, answer \\\"yes\\\", \\\"no\\\", or \\\"unanswerable\\\". Do not provide any explanation.\\n\\nQuestion: {input}\\n\\nAnswer:\",\n",
    "    \"multifieldqa_en\": \"Read the following text and answer briefly.\\n\\n{context}\\n\\nNow, answer the following question based on the above text, only give me the answer and do not output any other words.\\n\\nQuestion: {input}\\nAnswer:\",\n",
    "    \"multifieldqa_zh\": \"阅读以下文字并用中文简短回答：\\n\\n{context}\\n\\n现在请基于上面的文章回答下面的问题，只告诉我答案，不要输出任何其他字词。\\n\\n问题：{input}\\n回答：\",\n",
    "    \"hotpotqa\": \"Answer the question based on the given passages. Only give me the answer and do not output any other words.\\n\\nThe following are given passages.\\n{context}\\n\\nAnswer the question based on the given passages. Only give me the answer and do not output any other words.\\n\\nQuestion: {input}\\nAnswer:\",\n",
    "    \"2wikimqa\": \"Answer the question based on the given passages. Only give me the answer and do not output any other words.\\n\\nThe following are given passages.\\n{context}\\n\\nAnswer the question based on the given passages. Only give me the answer and do not output any other words.\\n\\nQuestion: {input}\\nAnswer:\",\n",
    "    \"musique\": \"Answer the question based on the given passages. Only give me the answer and do not output any other words.\\n\\nThe following are given passages.\\n{context}\\n\\nAnswer the question based on the given passages. Only give me the answer and do not output any other words.\\n\\nQuestion: {input}\\nAnswer:\",\n",
    "    \"dureader\": \"请基于给定的文章回答下述问题。\\n\\n文章：{context}\\n\\n请基于上述文章回答下面的问题。\\n\\n问题：{input}\\n回答：\",\n",
    "    \"gov_report\": \"You are given a report by a government agency. Write a one-page summary of the report.\\n\\nReport:\\n{context}\\n\\nNow, write a one-page summary of the report.\\n\\nSummary:\",\n",
    "    \"qmsum\": \"You are given a meeting transcript and a query containing a question or instruction. Answer the query in one or more sentences.\\n\\nTranscript:\\n{context}\\n\\nNow, answer the query based on the above meeting transcript in one or more sentences.\\n\\nQuery: {input}\\nAnswer:\",\n",
    "    \"multi_news\": \"You are given several news passages. Write a one-page summary of all news. \\n\\nNews:\\n{context}\\n\\nNow, write a one-page summary of all the news.\\n\\nSummary:\",\n",
    "    \"vcsum\": \"下面有一段会议记录，请你阅读后，写一段总结，总结会议的内容。\\n会议记录：\\n{context}\\n\\n会议总结：\",\n",
    "    \"trec\": \"Please determine the type of the question below. Here are some examples of questions.\\n\\n{context}\\n{input}\",\n",
    "    \"triviaqa\": \"Answer the question based on the given passage. Only give me the answer and do not output any other words. The following are some examples.\\n\\n{context}\\n\\n{input}\",\n",
    "    \"samsum\": \"Summarize the dialogue into a few short sentences. The following are some examples.\\n\\n{context}\\n\\n{input}\",\n",
    "    \"lsht\": \"请判断给定新闻的类别，下面是一些例子。\\n\\n{context}\\n{input}\",\n",
    "    \"passage_count\": \"There are some paragraphs below sourced from Wikipedia. Some of them may be duplicates. Please carefully read these paragraphs and determine how many unique paragraphs there are after removing duplicates. In other words, how many non-repeating paragraphs are there in total?\\n\\n{context}\\n\\nPlease enter the final count of unique paragraphs after removing duplicates. The output format should only contain the number, such as 1, 2, 3, and so on.\\n\\nThe final answer is: \",\n",
    "    \"passage_retrieval_en\": \"Here are 30 paragraphs from Wikipedia, along with an abstract. Please determine which paragraph the abstract is from.\\n\\n{context}\\n\\nThe following is an abstract.\\n\\n{input}\\n\\nPlease enter the number of the paragraph that the abstract is from. The answer format must be like \\\"Paragraph 1\\\", \\\"Paragraph 2\\\", etc.\\n\\nThe answer is: \",\n",
    "    \"passage_retrieval_zh\": \"以下是若干段落文字，以及其中一个段落的摘要。请确定给定的摘要出自哪一段。\\n\\n{context}\\n\\n下面是一个摘要\\n\\n{input}\\n\\n请输入摘要所属段落的编号。答案格式必须是\\\"段落1\\\"，\\\"段落2\\\"等格式\\n\\n答案是：\",\n",
    "    \"lcc\": \"Please complete the code given below. \\n{context}Next line of code:\\n\",\n",
    "    \"repobench-p\": \"Please complete the code given below. \\n{context}{input}Next line of code:\\n\"\n",
    "}\n",
    "\n",
    "relevant_templates = {\n",
    "    \"narrativeqa\": 'You are given a story, which can be either a novel or a movie script, a chunk of text from the story, and a question. Decide whether this chunk is relevant to the question. Do not provide any explanation.\\n\\nStory: {context}\\n\\nNow, decide whether the following chunk is relevant to the question or not. Only return \"Yes\" or \"No\" and do not provide any explanation.\\n\\nChunk: {chunk}\\n\\nQuestion: {input}\\n\\nAnswer:',\n",
    "    \"qasper\": \"You are given a scientific article, a chunk of text from the article and a question. Decide whether this chunk is relevant to the question. Do not provide any explanation.\\n\\nArticle: {context}\\n\\n Now, decide whether the following chunk is relevant to the question or not. Only return \\\"Yes\\\" or \\\"No\\\" and do not provide any explanation.\\n\\nChunk: {chunk}\\n\\nQuestion: {input}\\n\\nAnswer:\",\n",
    "    # \"multifieldqa_en\": \"Read the following text and answer briefly.\\n\\n{context}\\n\\nNow, answer the following question based on the above text, only give me the answer and do not output any other words.\\n\\nQuestion: {input}\\nAnswer:\",\n",
    "    # \"multifieldqa_zh\": \"阅读以下文字并用中文简短回答：\\n\\n{context}\\n\\n现在请基于上面的文章回答下面的问题，只告诉我答案，不要输出任何其他字词。\\n\\n问题：{input}\\n回答：\",\n",
    "    # \"hotpotqa\": \"Answer the question based on the given passages. Only give me the answer and do not output any other words.\\n\\nThe following are given passages.\\n{context}\\n\\nAnswer the question based on the given passages. Only give me the answer and do not output any other words.\\n\\nQuestion: {input}\\nAnswer:\",\n",
    "    # \"2wikimqa\": \"Answer the question based on the given passages. Only give me the answer and do not output any other words.\\n\\nThe following are given passages.\\n{context}\\n\\nAnswer the question based on the given passages. Only give me the answer and do not output any other words.\\n\\nQuestion: {input}\\nAnswer:\",\n",
    "    # \"musique\": \"Answer the question based on the given passages. Only give me the answer and do not output any other words.\\n\\nThe following are given passages.\\n{context}\\n\\nAnswer the question based on the given passages. Only give me the answer and do not output any other words.\\n\\nQuestion: {input}\\nAnswer:\",\n",
    "    # \"dureader\": \"请基于给定的文章回答下述问题。\\n\\n文章：{context}\\n\\n请基于上述文章回答下面的问题。\\n\\n问题：{input}\\n回答：\",\n",
    "    \"gov_report\": \"You are given a report by a government agency and a chunk of text from the report. Decide whether this chunk should be included in an extractive summary.\\n\\nReport:\\n{context}\\n\\nNow, decide whether the following chunk should be included in an extractive summary. Only return \\\"Yes\\\" or \\\"No\\\" and do not provide any explanation.\\n\\nChunk: {chunk}\\n\\nAnswer:\",\n",
    "    \"qmsum\": \"You are given a meeting transcript, a chunk of text from the transcript and a query containing a question or instruction. Decide whether this chunk is relevant to the query. Do not provide any explanation.\\n\\nTranscript:\\n{context}\\n\\nNow, decide whether the following chunk is relevant to the query or not. Only return \\\"Yes\\\" or \\\"No\\\" and do not provide any explanation.\\n\\nChunk: {chunk}\\n\\nQuery: {input}\\n\\nAnswer:\",\n",
    "    # \"multi_news\": \"You are given several news passages. Write a one-page summary of all news. \\n\\nNews:\\n{context}\\n\\nNow, write a one-page summary of all the news.\\n\\nSummary:\",\n",
    "    # \"vcsum\": \"下面有一段会议记录，请你阅读后，写一段总结，总结会议的内容。\\n会议记录：\\n{context}\\n\\n会议总结：\",\n",
    "    # \"trec\": \"Please determine the type of the question below. Here are some examples of questions.\\n\\n{context}\\n{input}\",\n",
    "    # \"triviaqa\": \"Answer the question based on the given passage. Only give me the answer and do not output any other words. The following are some examples.\\n\\n{context}\\n\\n{input}\",\n",
    "    # \"samsum\": \"Summarize the dialogue into a few short sentences. The following are some examples.\\n\\n{context}\\n\\n{input}\",\n",
    "    # \"lsht\": \"请判断给定新闻的类别，下面是一些例子。\\n\\n{context}\\n{input}\",\n",
    "    # \"passage_count\": \"There are some paragraphs below sourced from Wikipedia. Some of them may be duplicates. Please carefully read these paragraphs and determine how many unique paragraphs there are after removing duplicates. In other words, how many non-repeating paragraphs are there in total?\\n\\n{context}\\n\\nPlease enter the final count of unique paragraphs after removing duplicates. The output format should only contain the number, such as 1, 2, 3, and so on.\\n\\nThe final answer is: \",\n",
    "    # \"passage_retrieval_en\": \"Here are 30 paragraphs from Wikipedia, along with an abstract. Please determine which paragraph the abstract is from.\\n\\n{context}\\n\\nThe following is an abstract.\\n\\n{input}\\n\\nPlease enter the number of the paragraph that the abstract is from. The answer format must be like \\\"Paragraph 1\\\", \\\"Paragraph 2\\\", etc.\\n\\nThe answer is: \",\n",
    "    # \"passage_retrieval_zh\": \"以下是若干段落文字，以及其中一个段落的摘要。请确定给定的摘要出自哪一段。\\n\\n{context}\\n\\n下面是一个摘要\\n\\n{input}\\n\\n请输入摘要所属段落的编号。答案格式必须是\\\"段落1\\\"，\\\"段落2\\\"等格式\\n\\n答案是：\",\n",
    "    # \"lcc\": \"Please complete the code given below. \\n{context}Next line of code:\\n\",\n",
    "    # \"repobench-p\": \"Please complete the code given below. \\n{context}{input}Next line of code:\\n\"\n",
    "}\n",
    "\n",
    "answers = defaultdict(list)\n",
    "for task in [\"narrativeqa\", \"qasper\", \n",
    "            #  \"multifieldqa_en\", \"hotpotqa\", \"2wikimqa\", \"musique\", \n",
    "             \"gov_report\", \"qmsum\"]:\n",
    "    dataset = []\n",
    "    for sample in tqdm(load_dataset('THUDM/LongBench', task, split='test')):\n",
    "        prompt = templates[task].format(context=sample['context']) if task == 'gov_report' else templates[task].format(context=sample['context'], input=sample['input'])\n",
    "        if len(tokenizer.encode(prompt)) < 32000 - 500:\n",
    "            chunks = f.split_text(sample['context'])\n",
    "            prompts = [relevant_templates[task].format(context=sample['context'], chunk=chunk) if task == 'gov_report' else relevant_templates[task].format(context=sample['context'], input=sample['input'], chunk=chunk) for chunk in chunks]\n",
    "            sample['chunk_relevant'] = [(chunk, gen[0].text) for chunk, gen in zip(chunks, f.llm.generate([[HumanMessage(content=prompt)] for prompt in prompts], max_tokens=5).generations)]\n",
    "            answers[task].append(sample)\n",
    "            \n",
    "write_json('relevant.json', answers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Non-context Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "templates = {\n",
    "    \"narrativeqa\": \"You are given a story, which can be either a novel or a movie script, and a question. Answer the question asconcisely as you can, using a single phrase if possible. Do not provide any explanation.\\n\\nStory: {context}\\n\\nNow, answer the question based on the story asconcisely as you can, using a single phrase if possible. Do not provide any explanation.\\n\\nQuestion: {input}\\n\\nAnswer:\",\n",
    "    \"qasper\": \"You are given a scientific article and a question. Answer the question as concisely as you can, using a single phrase or sentence if possible. If the question cannot be answered based on the information in the article, write \\\"unanswerable\\\". If the question is a yes/no question, answer \\\"yes\\\", \\\"no\\\", or \\\"unanswerable\\\". Do not provide any explanation.\\n\\nArticle: {context}\\n\\n Answer the question based on the above article as concisely as you can, using a single phrase or sentence if possible. If the question cannot be answered based on the information in the article, write \\\"unanswerable\\\". If the question is a yes/no question, answer \\\"yes\\\", \\\"no\\\", or \\\"unanswerable\\\". Do not provide any explanation.\\n\\nQuestion: {input}\\n\\nAnswer:\",\n",
    "    \"multifieldqa_en\": \"Read the following text and answer briefly.\\n\\n{context}\\n\\nNow, answer the following question based on the above text, only give me the answer and do not output any other words.\\n\\nQuestion: {input}\\nAnswer:\",\n",
    "    \"multifieldqa_zh\": \"阅读以下文字并用中文简短回答：\\n\\n{context}\\n\\n现在请基于上面的文章回答下面的问题，只告诉我答案，不要输出任何其他字词。\\n\\n问题：{input}\\n回答：\",\n",
    "    \"hotpotqa\": \"Answer the question based on the given passages. Only give me the answer and do not output any other words.\\n\\nThe following are given passages.\\n{context}\\n\\nAnswer the question based on the given passages. Only give me the answer and do not output any other words.\\n\\nQuestion: {input}\\nAnswer:\",\n",
    "    \"2wikimqa\": \"Answer the question based on the given passages. Only give me the answer and do not output any other words.\\n\\nThe following are given passages.\\n{context}\\n\\nAnswer the question based on the given passages. Only give me the answer and do not output any other words.\\n\\nQuestion: {input}\\nAnswer:\",\n",
    "    \"musique\": \"Answer the question based on the given passages. Only give me the answer and do not output any other words.\\n\\nThe following are given passages.\\n{context}\\n\\nAnswer the question based on the given passages. Only give me the answer and do not output any other words.\\n\\nQuestion: {input}\\nAnswer:\",\n",
    "    \"dureader\": \"请基于给定的文章回答下述问题。\\n\\n文章：{context}\\n\\n请基于上述文章回答下面的问题。\\n\\n问题：{input}\\n回答：\",\n",
    "    \"gov_report\": \"You are given a report by a government agency. Write a one-page summary of the report.\\n\\nReport:\\n{context}\\n\\nNow, write a one-page summary of the report.\\n\\nSummary:\",\n",
    "    \"qmsum\": \"You are given a meeting transcript and a query containing a question or instruction. Answer the query in one or more sentences.\\n\\nTranscript:\\n{context}\\n\\nNow, answer the query based on the above meeting transcript in one or more sentences.\\n\\nQuery: {input}\\nAnswer:\",\n",
    "    \"multi_news\": \"You are given several news passages. Write a one-page summary of all news. \\n\\nNews:\\n{context}\\n\\nNow, write a one-page summary of all the news.\\n\\nSummary:\",\n",
    "    \"vcsum\": \"下面有一段会议记录，请你阅读后，写一段总结，总结会议的内容。\\n会议记录：\\n{context}\\n\\n会议总结：\",\n",
    "    \"trec\": \"Please determine the type of the question below. Here are some examples of questions.\\n\\n{context}\\n{input}\",\n",
    "    \"triviaqa\": \"Answer the question based on the given passage. Only give me the answer and do not output any other words. The following are some examples.\\n\\n{context}\\n\\n{input}\",\n",
    "    \"samsum\": \"Summarize the dialogue into a few short sentences. The following are some examples.\\n\\n{context}\\n\\n{input}\",\n",
    "    \"lsht\": \"请判断给定新闻的类别，下面是一些例子。\\n\\n{context}\\n{input}\",\n",
    "    \"passage_count\": \"There are some paragraphs below sourced from Wikipedia. Some of them may be duplicates. Please carefully read these paragraphs and determine how many unique paragraphs there are after removing duplicates. In other words, how many non-repeating paragraphs are there in total?\\n\\n{context}\\n\\nPlease enter the final count of unique paragraphs after removing duplicates. The output format should only contain the number, such as 1, 2, 3, and so on.\\n\\nThe final answer is: \",\n",
    "    \"passage_retrieval_en\": \"Here are 30 paragraphs from Wikipedia, along with an abstract. Please determine which paragraph the abstract is from.\\n\\n{context}\\n\\nThe following is an abstract.\\n\\n{input}\\n\\nPlease enter the number of the paragraph that the abstract is from. The answer format must be like \\\"Paragraph 1\\\", \\\"Paragraph 2\\\", etc.\\n\\nThe answer is: \",\n",
    "    \"passage_retrieval_zh\": \"以下是若干段落文字，以及其中一个段落的摘要。请确定给定的摘要出自哪一段。\\n\\n{context}\\n\\n下面是一个摘要\\n\\n{input}\\n\\n请输入摘要所属段落的编号。答案格式必须是\\\"段落1\\\"，\\\"段落2\\\"等格式\\n\\n答案是：\",\n",
    "    \"lcc\": \"Please complete the code given below. \\n{context}Next line of code:\\n\",\n",
    "    \"repobench-p\": \"Please complete the code given below. \\n{context}{input}Next line of code:\\n\"\n",
    "}\n",
    "\n",
    "relevant_templates = {\n",
    "    \"narrativeqa\": 'You are given a chunk of text from a story and a question. Decide whether this chunk is relevant to the question or not. Only return \"Yes\" or \"No\" and do not provide any explanation.\\n\\nChunk: {chunk}\\n\\nQuestion: {input}\\n\\nAnswer:',\n",
    "    \"qasper\": \"You are given a chunk of text from an article and a question. Decide whether this chunk is relevant to the question or not. Only return \\\"Yes\\\" or \\\"No\\\" and do not provide any explanation.\\n\\nChunk: {chunk}\\n\\nQuestion: {input}\\n\\nAnswer:\",\n",
    "    # \"multifieldqa_en\": \"Read the following text and answer briefly.\\n\\n{context}\\n\\nNow, answer the following question based on the above text, only give me the answer and do not output any other words.\\n\\nQuestion: {input}\\nAnswer:\",\n",
    "    # \"multifieldqa_zh\": \"阅读以下文字并用中文简短回答：\\n\\n{context}\\n\\n现在请基于上面的文章回答下面的问题，只告诉我答案，不要输出任何其他字词。\\n\\n问题：{input}\\n回答：\",\n",
    "    # \"hotpotqa\": \"Answer the question based on the given passages. Only give me the answer and do not output any other words.\\n\\nThe following are given passages.\\n{context}\\n\\nAnswer the question based on the given passages. Only give me the answer and do not output any other words.\\n\\nQuestion: {input}\\nAnswer:\",\n",
    "    # \"2wikimqa\": \"Answer the question based on the given passages. Only give me the answer and do not output any other words.\\n\\nThe following are given passages.\\n{context}\\n\\nAnswer the question based on the given passages. Only give me the answer and do not output any other words.\\n\\nQuestion: {input}\\nAnswer:\",\n",
    "    # \"musique\": \"Answer the question based on the given passages. Only give me the answer and do not output any other words.\\n\\nThe following are given passages.\\n{context}\\n\\nAnswer the question based on the given passages. Only give me the answer and do not output any other words.\\n\\nQuestion: {input}\\nAnswer:\",\n",
    "    # \"dureader\": \"请基于给定的文章回答下述问题。\\n\\n文章：{context}\\n\\n请基于上述文章回答下面的问题。\\n\\n问题：{input}\\n回答：\",\n",
    "    # \"gov_report\": \"You are given a report by a government agency and a chunk of text from the report. Decide whether this chunk should be included in an extractive summary.\\n\\nReport:\\n{context}\\n\\nNow, decide whether the following chunk should be included in an extractive summary. Only return \\\"Yes\\\" or \\\"No\\\" and do not provide any explanation.\\n\\nChunk: {chunk}\\n\\nAnswer:\",\n",
    "    \"qmsum\": \"You are given a chunk of text from a transcript and a query containing a question or instruction. Decide whether this chunk is relevant to the query or not. Only return \\\"Yes\\\" or \\\"No\\\" and do not provide any explanation.\\n\\nChunk: {chunk}\\n\\nQuery: {input}\\n\\nAnswer:\",\n",
    "    # \"multi_news\": \"You are given several news passages. Write a one-page summary of all news. \\n\\nNews:\\n{context}\\n\\nNow, write a one-page summary of all the news.\\n\\nSummary:\",\n",
    "    # \"vcsum\": \"下面有一段会议记录，请你阅读后，写一段总结，总结会议的内容。\\n会议记录：\\n{context}\\n\\n会议总结：\",\n",
    "    # \"trec\": \"Please determine the type of the question below. Here are some examples of questions.\\n\\n{context}\\n{input}\",\n",
    "    # \"triviaqa\": \"Answer the question based on the given passage. Only give me the answer and do not output any other words. The following are some examples.\\n\\n{context}\\n\\n{input}\",\n",
    "    # \"samsum\": \"Summarize the dialogue into a few short sentences. The following are some examples.\\n\\n{context}\\n\\n{input}\",\n",
    "    # \"lsht\": \"请判断给定新闻的类别，下面是一些例子。\\n\\n{context}\\n{input}\",\n",
    "    # \"passage_count\": \"There are some paragraphs below sourced from Wikipedia. Some of them may be duplicates. Please carefully read these paragraphs and determine how many unique paragraphs there are after removing duplicates. In other words, how many non-repeating paragraphs are there in total?\\n\\n{context}\\n\\nPlease enter the final count of unique paragraphs after removing duplicates. The output format should only contain the number, such as 1, 2, 3, and so on.\\n\\nThe final answer is: \",\n",
    "    # \"passage_retrieval_en\": \"Here are 30 paragraphs from Wikipedia, along with an abstract. Please determine which paragraph the abstract is from.\\n\\n{context}\\n\\nThe following is an abstract.\\n\\n{input}\\n\\nPlease enter the number of the paragraph that the abstract is from. The answer format must be like \\\"Paragraph 1\\\", \\\"Paragraph 2\\\", etc.\\n\\nThe answer is: \",\n",
    "    # \"passage_retrieval_zh\": \"以下是若干段落文字，以及其中一个段落的摘要。请确定给定的摘要出自哪一段。\\n\\n{context}\\n\\n下面是一个摘要\\n\\n{input}\\n\\n请输入摘要所属段落的编号。答案格式必须是\\\"段落1\\\"，\\\"段落2\\\"等格式\\n\\n答案是：\",\n",
    "    # \"lcc\": \"Please complete the code given below. \\n{context}Next line of code:\\n\",\n",
    "    # \"repobench-p\": \"Please complete the code given below. \\n{context}{input}Next line of code:\\n\"\n",
    "}\n",
    "\n",
    "answers = defaultdict(list)\n",
    "for task in [\"narrativeqa\", \"qasper\", \n",
    "            #  \"multifieldqa_en\", \"hotpotqa\", \"2wikimqa\", \"musique\", \n",
    "            #  \"gov_report\", \n",
    "             \"qmsum\"]:\n",
    "    dataset = []\n",
    "    for sample in tqdm(load_dataset('THUDM/LongBench', task, split='test')):\n",
    "        prompt = templates[task].format(context=sample['context']) if task == 'gov_report' else templates[task].format(context=sample['context'], input=sample['input'])\n",
    "        if len(tokenizer.encode(prompt)) < 32000 - 500:\n",
    "            chunks = f.split_text(sample['context'])\n",
    "            prompts = [relevant_templates[task].format(input=sample['input'], chunk=chunk) for chunk in chunks]\n",
    "            sample['chunk_relevant'] = [(chunk, gen[0].text) for chunk, gen in zip(chunks, f.llm.generate([[HumanMessage(content=prompt)] for prompt in prompts], max_tokens=5).generations)]\n",
    "            answers[task].append(sample)\n",
    "            \n",
    "write_json('relevant_non_context.json', answers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer with Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "templates = {\n",
    "    \"narrativeqa\": \"You are given a story, which can be either a novel or a movie script, and a question. Answer the question asconcisely as you can, using a single phrase if possible. Do not provide any explanation.\\n\\nStory: {context}\\n\\nNow, answer the question based on the story asconcisely as you can, using a single phrase if possible. Do not provide any explanation.\\n\\nQuestion: {input}\\n\\nAnswer:\",\n",
    "    \"qasper\": \"You are given a scientific article and a question. Answer the question as concisely as you can, using a single phrase or sentence if possible. If the question cannot be answered based on the information in the article, write \\\"unanswerable\\\". If the question is a yes/no question, answer \\\"yes\\\", \\\"no\\\", or \\\"unanswerable\\\". Do not provide any explanation.\\n\\nArticle: {context}\\n\\n Answer the question based on the above article as concisely as you can, using a single phrase or sentence if possible. If the question cannot be answered based on the information in the article, write \\\"unanswerable\\\". If the question is a yes/no question, answer \\\"yes\\\", \\\"no\\\", or \\\"unanswerable\\\". Do not provide any explanation.\\n\\nQuestion: {input}\\n\\nAnswer:\",\n",
    "    \"multifieldqa_en\": \"Read the following text and answer briefly.\\n\\n{context}\\n\\nNow, answer the following question based on the above text, only give me the answer and do not output any other words.\\n\\nQuestion: {input}\\nAnswer:\",\n",
    "    \"multifieldqa_zh\": \"阅读以下文字并用中文简短回答：\\n\\n{context}\\n\\n现在请基于上面的文章回答下面的问题，只告诉我答案，不要输出任何其他字词。\\n\\n问题：{input}\\n回答：\",\n",
    "    \"hotpotqa\": \"Answer the question based on the given passages. Only give me the answer and do not output any other words.\\n\\nThe following are given passages.\\n{context}\\n\\nAnswer the question based on the given passages. Only give me the answer and do not output any other words.\\n\\nQuestion: {input}\\nAnswer:\",\n",
    "    \"2wikimqa\": \"Answer the question based on the given passages. Only give me the answer and do not output any other words.\\n\\nThe following are given passages.\\n{context}\\n\\nAnswer the question based on the given passages. Only give me the answer and do not output any other words.\\n\\nQuestion: {input}\\nAnswer:\",\n",
    "    \"musique\": \"Answer the question based on the given passages. Only give me the answer and do not output any other words.\\n\\nThe following are given passages.\\n{context}\\n\\nAnswer the question based on the given passages. Only give me the answer and do not output any other words.\\n\\nQuestion: {input}\\nAnswer:\",\n",
    "    \"dureader\": \"请基于给定的文章回答下述问题。\\n\\n文章：{context}\\n\\n请基于上述文章回答下面的问题。\\n\\n问题：{input}\\n回答：\",\n",
    "    \"gov_report\": \"You are given a report by a government agency. Write a one-page summary of the report.\\n\\nReport:\\n{context}\\n\\nNow, write a one-page summary of the report.\\n\\nSummary:\",\n",
    "    \"qmsum\": \"You are given a meeting transcript and a query containing a question or instruction. Answer the query in one or more sentences.\\n\\nTranscript:\\n{context}\\n\\nNow, answer the query based on the above meeting transcript in one or more sentences.\\n\\nQuery: {input}\\nAnswer:\",\n",
    "    \"multi_news\": \"You are given several news passages. Write a one-page summary of all news. \\n\\nNews:\\n{context}\\n\\nNow, write a one-page summary of all the news.\\n\\nSummary:\",\n",
    "    \"vcsum\": \"下面有一段会议记录，请你阅读后，写一段总结，总结会议的内容。\\n会议记录：\\n{context}\\n\\n会议总结：\",\n",
    "    \"trec\": \"Please determine the type of the question below. Here are some examples of questions.\\n\\n{context}\\n{input}\",\n",
    "    \"triviaqa\": \"Answer the question based on the given passage. Only give me the answer and do not output any other words. The following are some examples.\\n\\n{context}\\n\\n{input}\",\n",
    "    \"samsum\": \"Summarize the dialogue into a few short sentences. The following are some examples.\\n\\n{context}\\n\\n{input}\",\n",
    "    \"lsht\": \"请判断给定新闻的类别，下面是一些例子。\\n\\n{context}\\n{input}\",\n",
    "    \"passage_count\": \"There are some paragraphs below sourced from Wikipedia. Some of them may be duplicates. Please carefully read these paragraphs and determine how many unique paragraphs there are after removing duplicates. In other words, how many non-repeating paragraphs are there in total?\\n\\n{context}\\n\\nPlease enter the final count of unique paragraphs after removing duplicates. The output format should only contain the number, such as 1, 2, 3, and so on.\\n\\nThe final answer is: \",\n",
    "    \"passage_retrieval_en\": \"Here are 30 paragraphs from Wikipedia, along with an abstract. Please determine which paragraph the abstract is from.\\n\\n{context}\\n\\nThe following is an abstract.\\n\\n{input}\\n\\nPlease enter the number of the paragraph that the abstract is from. The answer format must be like \\\"Paragraph 1\\\", \\\"Paragraph 2\\\", etc.\\n\\nThe answer is: \",\n",
    "    \"passage_retrieval_zh\": \"以下是若干段落文字，以及其中一个段落的摘要。请确定给定的摘要出自哪一段。\\n\\n{context}\\n\\n下面是一个摘要\\n\\n{input}\\n\\n请输入摘要所属段落的编号。答案格式必须是\\\"段落1\\\"，\\\"段落2\\\"等格式\\n\\n答案是：\",\n",
    "    \"lcc\": \"Please complete the code given below. \\n{context}Next line of code:\\n\",\n",
    "    \"repobench-p\": \"Please complete the code given below. \\n{context}{input}Next line of code:\\n\"\n",
    "}\n",
    "\n",
    "answers = defaultdict(list)\n",
    "relevant_non_context:dict = read_json('relevant_non_context.json')\n",
    "for task, samples in relevant_non_context.items():\n",
    "    dataset = []\n",
    "    for sample in samples:\n",
    "        context = '\\n\\n'.join([f'Passage {pid + 1}: {p}' for pid, (p, y_o_n) in enumerate(sample['chunk_relevant']) if 'yes' in y_o_n.lower() and 'no' not in y_o_n.lower()])\n",
    "        prompt = templates[task].format(context=context) if task == 'gov_report' else templates[task].format(context=context, input=sample['input'])\n",
    "        sample['prompt'] = prompt\n",
    "        sample['retrieved_context'] = context\n",
    "        if context:\n",
    "            dataset.append(sample)\n",
    "        else:\n",
    "            sample['gen'] = 'unanswerable'\n",
    "        answers[task].append(sample)\n",
    "    for i in tqdm(range((len(dataset) + 1) // 5)):\n",
    "        batch_samples = dataset[i*5 : (i+1)*5]\n",
    "        for sample, gen in zip(batch_samples, f.llm.generate([[HumanMessage(content=sample['prompt'])] for sample in batch_samples]).generations):\n",
    "            sample['gen'] = gen[0].text\n",
    "            sample['token_usage'] = gen[0].message.response_metadata['token_usage']\n",
    "write_json('relevant_non_context_answers.json', answers)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# narrativeqa = load_dataset('THUDM/LongBench', 'narrativeqa', split='test')\n",
    "narrativeqa = load_dataset('deepmind/narrativeqa', split='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "narrativeqa[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text:str = narrativeqa[0]['document']['text']\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('article.txt', 'w') as f_out:\n",
    "    f_out.write(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "passages = [' '.join(p.strip().split()) for p in text.split('\\n\\n') if p.strip()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "passages[16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "passages = passages[17:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_switch_prompt = '''\n",
    "Identify the first sentence in the passages below that marks a turning point in the narrative focus. This sentence should act as a boundary, where the content before it maintains a consistent focus on one topic, and the content after it shifts to a different focus. In your explanation, use one or two sentences to briefly describe the narrative focus both before and immediately after this turning point.\n",
    "\n",
    "\n",
    "Passages:\n",
    "\n",
    "{passages}\n",
    "\n",
    "\n",
    "Now, generate your response, organizing it under the following headers: \"Turning Point\" for the first turning point sentence, \"Topic before\" and \"Topic after\" for the explanation of topic before and immediately after turning point sentence.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_switch_prompt = '''\n",
    "Identify the first sentence in the passages below that marks a turning point in the narrative focus. This sentence should act as a boundary, where the content before it maintains a consistent focus on one topic, and the content after it shifts to a different focus. In your response, first, briefly describe the narrative focus at the beginning, second, identify the turning point sentence and finally, briefly describe the narrative focus immediately after the turning point.\n",
    "\n",
    "\n",
    "Passages:\n",
    "\n",
    "{passages}\n",
    "\n",
    "\n",
    "Now, generate your response, organizing it under the following headers: \"Beginning Topic\" for the topic at the beginning, \"Turning Point\" for the first turning point sentence, and \"Topic after\" for the explanation of topic immediately after the turning point sentence.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_topic_prompt = '''\n",
    "What is the topic of the following passage?\n",
    "\n",
    "{passage}\n",
    "\n",
    "Now, generate your response with one statement starting with \"Current Topic: \".\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_topic_consist_prompt = '''\n",
    "Given the current topic, the most recent passage under this topic, and the next passage in the narrative, assess how the next passage impacts the current topic.\n",
    "\n",
    "Current Topic:\n",
    "{topic}\n",
    "\n",
    "Current Last Passage:\n",
    "{last_passage}\n",
    "\n",
    "Next Passage:\n",
    "{passage}\n",
    "\n",
    "Now, evaluate the influence of the next passage on the current topic, in relation to the last passage:\n",
    "\n",
    "If the next passage continues the current topic by expanding on specific details from the last passage, respond with \"Subtopic\" and provide a concise statement of the subtopic starting with \"Subtopic: \", ensuring the statement relates to the current topic.\n",
    "If the next passage remains within the current topic but introduces information from a different perspective than the last passage, respond with \"Same Topic\".\n",
    "If the next passage introduces new, unrelated information that diverges from the current topic, respond with \"New Topic\".\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# passages = [f.nlp(p, disable=['ner']) for p in passages[17:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Topic:\n",
    "    def __init__(self, topic:str):\n",
    "        self.topic = topic\n",
    "        self.passages: List[str] = []\n",
    "        self.subtopics: List[Topic] = []\n",
    "        self.parent: Topic = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks = List[str]()\n",
    "for end_p in range(len(passages)):\n",
    "    passage_text = '\\n\\n'.join(passages[start_p : end_p+1])\n",
    "    passage_len = len(tokenizer.encode(passage_text, add_special_tokens=False))\n",
    "    if passage_len < 300 and end_p+1 < len(passages):\n",
    "        continue\n",
    "    start_p = end_p+1\n",
    "    chunks.append(passage_text)\n",
    "    \n",
    "start_p, topics, last_passage, prompt_responses, topic2p = 0, List[Topic](), '', [], defaultdict(list)\n",
    "for chunk in tqdm(chunks):\n",
    "    if not topics:\n",
    "        prompt = query_topic_prompt.format(passage=chunk)\n",
    "        response = f.llm.generate([[HumanMessage(prompt)]]).generations[0][0].text\n",
    "        prompt_responses.append((prompt, response))\n",
    "        try:\n",
    "            current_topic = response[response.lower().index('current topic') + len('current topic') + 1:].strip()\n",
    "        except:\n",
    "            current_topic = response.strip()\n",
    "        new_topic_obj = Topic(topic=current_topic)\n",
    "        new_topic_obj.passages.append(passage_text)\n",
    "        topics.append(new_topic_obj)\n",
    "        current_topic_obj = new_topic_obj\n",
    "    else:\n",
    "        prompt = query_topic_consist_prompt.format(passage=passage_text, last_passage=last_passage, topic=current_topic_obj.topic)\n",
    "        response = f.llm.generate([[HumanMessage(prompt)]]).generations[0][0].text\n",
    "        prompt_responses.append((prompt, response))\n",
    "        if 'subtopic' in response.lower():\n",
    "            subtopic = response.split('Subtopic:')[1].strip()\n",
    "            subtopic_obj = Topic(topic=subtopic)\n",
    "            subtopic_obj.passages.append(passage_text)\n",
    "            current_topic_obj.subtopics.append(subtopic_obj)\n",
    "            subtopic_obj.parent = current_topic_obj\n",
    "            current_topic_obj = subtopic_obj\n",
    "        elif 'new topic' in response.lower():\n",
    "            position_located = False\n",
    "            while current_topic_obj.parent is not None:\n",
    "                current_topic_obj = current_topic_obj.parent\n",
    "                prompt = query_topic_consist_prompt.format(passage=passage_text, last_passage=last_passage, topic=current_topic_obj.topic)\n",
    "                response = f.llm.generate([[HumanMessage(prompt)]]).generations[0][0].text\n",
    "                prompt_responses.append((prompt, response))\n",
    "                if 'subtopic' in response.lower():\n",
    "                    subtopic = response.split('Subtopic:')[1].strip()\n",
    "                    subtopic_obj = Topic(topic=subtopic)\n",
    "                    subtopic_obj.passages.append(passage_text)\n",
    "                    current_topic_obj.subtopics.append(subtopic_obj)\n",
    "                    subtopic_obj.parent = current_topic_obj\n",
    "                    current_topic_obj = subtopic_obj\n",
    "                    position_located = True\n",
    "                    break\n",
    "                elif 'new topic' in response.lower():\n",
    "                    continue\n",
    "                elif 'same topic' in response.lower():\n",
    "                    current_topic_obj.passages.append(passage_text)\n",
    "                else:\n",
    "                    raise NotImplementedError\n",
    "            \n",
    "        elif 'same topic' in response.lower():\n",
    "            pass\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "        try:\n",
    "            new_topic = response[response.lower().index('new topic') + len('new topic') + 1:].strip()\n",
    "            if current_topic != new_topic:\n",
    "                current_topic = new_topic\n",
    "                topic_records.append(current_topic)\n",
    "        except:\n",
    "            pass\n",
    "    topic2p[current_topic].append(passage_text)\n",
    "    last_passage = passage_text\n",
    "    if len(topic_records) >= 20:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_responses[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for topic in topic_records:\n",
    "    print(topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for topic, ps in topic2p.items():\n",
    "    print('TOPIC:\\n', topic, '\\n')\n",
    "    print('PASSAGES:\\n', '\\n\\n'.join(ps), '\\n')\n",
    "    print('-----------------------------------------------------------\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_p, start_sent = 0, 0\n",
    "for end_p in range(len(passages)):\n",
    "    temp_passages = [p.text for p in passages[start_p : end_p+1]]\n",
    "    if start_sent > 0:\n",
    "        temp_passages = [''.join([sent.text_with_ws for sent in passages[start_p].sents])] + temp_passages[1:]\n",
    "    passage_text = '\\n\\n'.join(temp_passages)\n",
    "    passage_len = len(tokenizer.encode(passage_text, add_special_tokens=False))\n",
    "    if passage_len < 2000 and end_p+1 < len(passages):\n",
    "        continue\n",
    "    response = f.llm.generate([[HumanMessage(topic_switch_prompt.format(passages=temp_passages))]])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response.generations[0][0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response.generations[0][0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(passage_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\n\\n'.join(passages[0:5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sents = \n",
    "tokenized_sents = [[t.text for t in sent] for sent in sents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_sents[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "examine_passages = passages[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "background_event_cls_prompt = '''\n",
    "Given a piece of text, decide whether it is background knowledge or dynamic knowledge.\n",
    "\n",
    "Background knowledge describing facts that are true in most contexts.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.llm.generate([[HumanMessage()]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(doc.noun_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc.ents[0].label_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from metrics import (\n",
    "    qa_f1_score,\n",
    "    rouge_zh_score,\n",
    "    qa_f1_zh_score,\n",
    "    rouge_score,\n",
    "    classification_score,\n",
    "    retrieval_score,\n",
    "    retrieval_zh_score,\n",
    "    count_score,\n",
    "    code_sim_score,\n",
    ")\n",
    "\n",
    "dataset2metric = {\n",
    "    \"narrativeqa\": qa_f1_score,\n",
    "    \"qasper\": qa_f1_score,\n",
    "    \"multifieldqa_en\": qa_f1_score,\n",
    "    \"multifieldqa_zh\": qa_f1_zh_score,\n",
    "    \"hotpotqa\": qa_f1_score,\n",
    "    \"2wikimqa\": qa_f1_score,\n",
    "    \"musique\": qa_f1_score,\n",
    "    \"dureader\": rouge_zh_score,\n",
    "    \"gov_report\": rouge_score,\n",
    "    \"qmsum\": rouge_score,\n",
    "    \"multi_news\": rouge_score,\n",
    "    \"vcsum\": rouge_zh_score,\n",
    "    \"trec\": classification_score,\n",
    "    \"triviaqa\": qa_f1_score,\n",
    "    \"samsum\": rouge_score,\n",
    "    \"lsht\": classification_score,\n",
    "    \"passage_retrieval_en\": retrieval_score,\n",
    "    \"passage_count\": count_score,\n",
    "    \"passage_retrieval_zh\": retrieval_zh_score,\n",
    "    \"lcc\": code_sim_score,\n",
    "    \"repobench-p\": code_sim_score,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_samples = read_json('baseline.json')\n",
    "baseline_samples.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(baseline_samples['qmsum'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_samples = read_json('baseline.json')\n",
    "for task, samples in baseline_samples.items():\n",
    "    for sample in samples:\n",
    "        if 'Unanswerable' not in sample['answers']:\n",
    "            sample['score'] = max(dataset2metric[task](sample['gen'], ground_truth) for ground_truth in sample['answers'])\n",
    "        else:\n",
    "            sample['score'] = -1\n",
    "    print(task, np.mean([sample['score'] for sample in samples if sample['score'] != -1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[sample['answers'] for sample in baseline_samples['qasper']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relevant_non_context_samples = read_json('relevant_non_context_answers.json')\n",
    "for task, samples in relevant_non_context_samples.items():\n",
    "    for sample in samples:\n",
    "        if 'Unanswerable' not in sample['answers']:\n",
    "            sample['score'] = max(dataset2metric[task](sample['gen'], ground_truth) for ground_truth in sample['answers'])\n",
    "        else:\n",
    "            sample['score'] = -1\n",
    "    print(task, np.mean([sample['score'] for sample in samples if sample['score'] != -1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relevant_samples = read_json('relevant_answers.json')\n",
    "for task, samples in relevant_samples.items():\n",
    "    for sample in samples:\n",
    "        if 'Unanswerable' not in sample['answers']:\n",
    "            sample['score'] = max(dataset2metric[task](sample['gen'], ground_truth) for ground_truth in sample['answers'])\n",
    "        else:\n",
    "            sample['score'] = -1\n",
    "    print(task, np.mean([sample['score'] for sample in samples if sample['score'] != -1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_list = defaultdict(list)\n",
    "for task in ['narrativeqa', 'qasper', 'gov_report', 'qmsum']:\n",
    "    for sample_b in baseline_samples[task]:\n",
    "        for sample_r in relevant_samples[task]:\n",
    "            if sample_b['context'] == sample_r['context'] and sample_b['input'] == sample_r['input']:\n",
    "                compare_list[task].append({'base': sample_b, 'ret': sample_r})\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task = 'narrativeqa'\n",
    "bad_compare_list = [p for p in compare_list[task] if p['base']['score'] > p['ret']['score']]\n",
    "print('bad', len(bad_compare_list))\n",
    "good_compare_list = [p for p in compare_list[task] if p['base']['score'] < p['ret']['score']]\n",
    "print('good', len(good_compare_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "narrativeqa_check = [5,6,7,8,10,11,17,19,21]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_pair = bad_compare_list[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_pair['base']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_pair['ret']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(compare_pair['ret']['context'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_pair['ret'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(compare_pair['ret']['retrieved_context'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for chunk, r in compare_pair['ret']['chunk_relevant']:\n",
    "    print(chunk)\n",
    "    print('---------------------------')\n",
    "    print(r)\n",
    "    print('---------------------------')\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "longdoc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
