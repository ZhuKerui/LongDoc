{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../..')\n",
    "\n",
    "from src.index_files import *\n",
    "# from src.corenlp_base import Doc, Mention, Sentence\n",
    "# from huggingface_hub import login\n",
    "# login(os.environ['HF_TOKEN'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = QualityDataset(split='dev')\n",
    "f = Factory(chunk_size=300, llm_name='meta-llama/Llama-2-7b-chat-hf')\n",
    "tokenizer = AutoTokenizer.from_pretrained(f.llm_name)\n",
    "# article = dataset.get_article(dataset.data[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline 32k QA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "templates = {\n",
    "    \"narrativeqa\": \"You are given a story, which can be either a novel or a movie script, and a question. Answer the question asconcisely as you can, using a single phrase if possible. Do not provide any explanation.\\n\\nStory: {context}\\n\\nNow, answer the question based on the story asconcisely as you can, using a single phrase if possible. Do not provide any explanation.\\n\\nQuestion: {input}\\n\\nAnswer:\",\n",
    "    \"qasper\": \"You are given a scientific article and a question. Answer the question as concisely as you can, using a single phrase or sentence if possible. If the question cannot be answered based on the information in the article, write \\\"unanswerable\\\". If the question is a yes/no question, answer \\\"yes\\\", \\\"no\\\", or \\\"unanswerable\\\". Do not provide any explanation.\\n\\nArticle: {context}\\n\\n Answer the question based on the above article as concisely as you can, using a single phrase or sentence if possible. If the question cannot be answered based on the information in the article, write \\\"unanswerable\\\". If the question is a yes/no question, answer \\\"yes\\\", \\\"no\\\", or \\\"unanswerable\\\". Do not provide any explanation.\\n\\nQuestion: {input}\\n\\nAnswer:\",\n",
    "    \"multifieldqa_en\": \"Read the following text and answer briefly.\\n\\n{context}\\n\\nNow, answer the following question based on the above text, only give me the answer and do not output any other words.\\n\\nQuestion: {input}\\nAnswer:\",\n",
    "    \"multifieldqa_zh\": \"阅读以下文字并用中文简短回答：\\n\\n{context}\\n\\n现在请基于上面的文章回答下面的问题，只告诉我答案，不要输出任何其他字词。\\n\\n问题：{input}\\n回答：\",\n",
    "    \"hotpotqa\": \"Answer the question based on the given passages. Only give me the answer and do not output any other words.\\n\\nThe following are given passages.\\n{context}\\n\\nAnswer the question based on the given passages. Only give me the answer and do not output any other words.\\n\\nQuestion: {input}\\nAnswer:\",\n",
    "    \"2wikimqa\": \"Answer the question based on the given passages. Only give me the answer and do not output any other words.\\n\\nThe following are given passages.\\n{context}\\n\\nAnswer the question based on the given passages. Only give me the answer and do not output any other words.\\n\\nQuestion: {input}\\nAnswer:\",\n",
    "    \"musique\": \"Answer the question based on the given passages. Only give me the answer and do not output any other words.\\n\\nThe following are given passages.\\n{context}\\n\\nAnswer the question based on the given passages. Only give me the answer and do not output any other words.\\n\\nQuestion: {input}\\nAnswer:\",\n",
    "    \"dureader\": \"请基于给定的文章回答下述问题。\\n\\n文章：{context}\\n\\n请基于上述文章回答下面的问题。\\n\\n问题：{input}\\n回答：\",\n",
    "    \"gov_report\": \"You are given a report by a government agency. Write a one-page summary of the report.\\n\\nReport:\\n{context}\\n\\nNow, write a one-page summary of the report.\\n\\nSummary:\",\n",
    "    \"qmsum\": \"You are given a meeting transcript and a query containing a question or instruction. Answer the query in one or more sentences.\\n\\nTranscript:\\n{context}\\n\\nNow, answer the query based on the above meeting transcript in one or more sentences.\\n\\nQuery: {input}\\nAnswer:\",\n",
    "    \"multi_news\": \"You are given several news passages. Write a one-page summary of all news. \\n\\nNews:\\n{context}\\n\\nNow, write a one-page summary of all the news.\\n\\nSummary:\",\n",
    "    \"vcsum\": \"下面有一段会议记录，请你阅读后，写一段总结，总结会议的内容。\\n会议记录：\\n{context}\\n\\n会议总结：\",\n",
    "    \"trec\": \"Please determine the type of the question below. Here are some examples of questions.\\n\\n{context}\\n{input}\",\n",
    "    \"triviaqa\": \"Answer the question based on the given passage. Only give me the answer and do not output any other words. The following are some examples.\\n\\n{context}\\n\\n{input}\",\n",
    "    \"samsum\": \"Summarize the dialogue into a few short sentences. The following are some examples.\\n\\n{context}\\n\\n{input}\",\n",
    "    \"lsht\": \"请判断给定新闻的类别，下面是一些例子。\\n\\n{context}\\n{input}\",\n",
    "    \"passage_count\": \"There are some paragraphs below sourced from Wikipedia. Some of them may be duplicates. Please carefully read these paragraphs and determine how many unique paragraphs there are after removing duplicates. In other words, how many non-repeating paragraphs are there in total?\\n\\n{context}\\n\\nPlease enter the final count of unique paragraphs after removing duplicates. The output format should only contain the number, such as 1, 2, 3, and so on.\\n\\nThe final answer is: \",\n",
    "    \"passage_retrieval_en\": \"Here are 30 paragraphs from Wikipedia, along with an abstract. Please determine which paragraph the abstract is from.\\n\\n{context}\\n\\nThe following is an abstract.\\n\\n{input}\\n\\nPlease enter the number of the paragraph that the abstract is from. The answer format must be like \\\"Paragraph 1\\\", \\\"Paragraph 2\\\", etc.\\n\\nThe answer is: \",\n",
    "    \"passage_retrieval_zh\": \"以下是若干段落文字，以及其中一个段落的摘要。请确定给定的摘要出自哪一段。\\n\\n{context}\\n\\n下面是一个摘要\\n\\n{input}\\n\\n请输入摘要所属段落的编号。答案格式必须是\\\"段落1\\\"，\\\"段落2\\\"等格式\\n\\n答案是：\",\n",
    "    \"lcc\": \"Please complete the code given below. \\n{context}Next line of code:\\n\",\n",
    "    \"repobench-p\": \"Please complete the code given below. \\n{context}{input}Next line of code:\\n\"\n",
    "}\n",
    "\n",
    "# answers = defaultdict(list)\n",
    "# for task in [\"narrativeqa\", \"qasper\", \"multifieldqa_en\", \"hotpotqa\", \"2wikimqa\", \"musique\", \"gov_report\", \"qmsum\"]:\n",
    "#     dataset = []\n",
    "#     for sample in load_dataset('THUDM/LongBench', task, split='test'):\n",
    "#         prompt = templates[task].format(context=sample['context']) if task == 'gov_report' else templates[task].format(context=sample['context'], input=sample['input'])\n",
    "#         if len(tokenizer.encode(prompt)) < 32000 - 500:\n",
    "#             sample['prompt'] = prompt\n",
    "#             dataset.append(sample)\n",
    "#     for i in tqdm(range((len(dataset) + 1) // 5)):\n",
    "#         batch_samples = dataset[i*5 : (i+1)*5]\n",
    "#         for sample, gen in zip(batch_samples, f.llm.generate([[HumanMessage(content=sample['prompt'])] for sample in batch_samples]).generations):\n",
    "#             sample['gen'] = gen[0].text\n",
    "#             sample['token_usage'] = gen[0].message.response_metadata['token_usage']\n",
    "#             answers[task].append(sample)\n",
    "# write_json('baseline.json', answers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 32k Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "templates = {\n",
    "    \"narrativeqa\": \"You are given a story, which can be either a novel or a movie script, and a question. Answer the question asconcisely as you can, using a single phrase if possible. Do not provide any explanation.\\n\\nStory: {context}\\n\\nNow, answer the question based on the story asconcisely as you can, using a single phrase if possible. Do not provide any explanation.\\n\\nQuestion: {input}\\n\\nAnswer:\",\n",
    "    \"qasper\": \"You are given a scientific article and a question. Answer the question as concisely as you can, using a single phrase or sentence if possible. If the question cannot be answered based on the information in the article, write \\\"unanswerable\\\". If the question is a yes/no question, answer \\\"yes\\\", \\\"no\\\", or \\\"unanswerable\\\". Do not provide any explanation.\\n\\nArticle: {context}\\n\\n Answer the question based on the above article as concisely as you can, using a single phrase or sentence if possible. If the question cannot be answered based on the information in the article, write \\\"unanswerable\\\". If the question is a yes/no question, answer \\\"yes\\\", \\\"no\\\", or \\\"unanswerable\\\". Do not provide any explanation.\\n\\nQuestion: {input}\\n\\nAnswer:\",\n",
    "    \"multifieldqa_en\": \"Read the following text and answer briefly.\\n\\n{context}\\n\\nNow, answer the following question based on the above text, only give me the answer and do not output any other words.\\n\\nQuestion: {input}\\nAnswer:\",\n",
    "    \"multifieldqa_zh\": \"阅读以下文字并用中文简短回答：\\n\\n{context}\\n\\n现在请基于上面的文章回答下面的问题，只告诉我答案，不要输出任何其他字词。\\n\\n问题：{input}\\n回答：\",\n",
    "    \"hotpotqa\": \"Answer the question based on the given passages. Only give me the answer and do not output any other words.\\n\\nThe following are given passages.\\n{context}\\n\\nAnswer the question based on the given passages. Only give me the answer and do not output any other words.\\n\\nQuestion: {input}\\nAnswer:\",\n",
    "    \"2wikimqa\": \"Answer the question based on the given passages. Only give me the answer and do not output any other words.\\n\\nThe following are given passages.\\n{context}\\n\\nAnswer the question based on the given passages. Only give me the answer and do not output any other words.\\n\\nQuestion: {input}\\nAnswer:\",\n",
    "    \"musique\": \"Answer the question based on the given passages. Only give me the answer and do not output any other words.\\n\\nThe following are given passages.\\n{context}\\n\\nAnswer the question based on the given passages. Only give me the answer and do not output any other words.\\n\\nQuestion: {input}\\nAnswer:\",\n",
    "    \"dureader\": \"请基于给定的文章回答下述问题。\\n\\n文章：{context}\\n\\n请基于上述文章回答下面的问题。\\n\\n问题：{input}\\n回答：\",\n",
    "    \"gov_report\": \"You are given a report by a government agency. Write a one-page summary of the report.\\n\\nReport:\\n{context}\\n\\nNow, write a one-page summary of the report.\\n\\nSummary:\",\n",
    "    \"qmsum\": \"You are given a meeting transcript and a query containing a question or instruction. Answer the query in one or more sentences.\\n\\nTranscript:\\n{context}\\n\\nNow, answer the query based on the above meeting transcript in one or more sentences.\\n\\nQuery: {input}\\nAnswer:\",\n",
    "    \"multi_news\": \"You are given several news passages. Write a one-page summary of all news. \\n\\nNews:\\n{context}\\n\\nNow, write a one-page summary of all the news.\\n\\nSummary:\",\n",
    "    \"vcsum\": \"下面有一段会议记录，请你阅读后，写一段总结，总结会议的内容。\\n会议记录：\\n{context}\\n\\n会议总结：\",\n",
    "    \"trec\": \"Please determine the type of the question below. Here are some examples of questions.\\n\\n{context}\\n{input}\",\n",
    "    \"triviaqa\": \"Answer the question based on the given passage. Only give me the answer and do not output any other words. The following are some examples.\\n\\n{context}\\n\\n{input}\",\n",
    "    \"samsum\": \"Summarize the dialogue into a few short sentences. The following are some examples.\\n\\n{context}\\n\\n{input}\",\n",
    "    \"lsht\": \"请判断给定新闻的类别，下面是一些例子。\\n\\n{context}\\n{input}\",\n",
    "    \"passage_count\": \"There are some paragraphs below sourced from Wikipedia. Some of them may be duplicates. Please carefully read these paragraphs and determine how many unique paragraphs there are after removing duplicates. In other words, how many non-repeating paragraphs are there in total?\\n\\n{context}\\n\\nPlease enter the final count of unique paragraphs after removing duplicates. The output format should only contain the number, such as 1, 2, 3, and so on.\\n\\nThe final answer is: \",\n",
    "    \"passage_retrieval_en\": \"Here are 30 paragraphs from Wikipedia, along with an abstract. Please determine which paragraph the abstract is from.\\n\\n{context}\\n\\nThe following is an abstract.\\n\\n{input}\\n\\nPlease enter the number of the paragraph that the abstract is from. The answer format must be like \\\"Paragraph 1\\\", \\\"Paragraph 2\\\", etc.\\n\\nThe answer is: \",\n",
    "    \"passage_retrieval_zh\": \"以下是若干段落文字，以及其中一个段落的摘要。请确定给定的摘要出自哪一段。\\n\\n{context}\\n\\n下面是一个摘要\\n\\n{input}\\n\\n请输入摘要所属段落的编号。答案格式必须是\\\"段落1\\\"，\\\"段落2\\\"等格式\\n\\n答案是：\",\n",
    "    \"lcc\": \"Please complete the code given below. \\n{context}Next line of code:\\n\",\n",
    "    \"repobench-p\": \"Please complete the code given below. \\n{context}{input}Next line of code:\\n\"\n",
    "}\n",
    "\n",
    "relevant_templates = {\n",
    "    \"narrativeqa\": 'You are given a story, which can be either a novel or a movie script, a chunk of text from the story, and a question. Decide whether this chunk is relevant to the question. Do not provide any explanation.\\n\\nStory: {context}\\n\\nNow, decide whether the following chunk is relevant to the question or not. Only return \"Yes\" or \"No\" and do not provide any explanation.\\n\\nChunk: {chunk}\\n\\nQuestion: {input}\\n\\nAnswer:',\n",
    "    \"qasper\": \"You are given a scientific article, a chunk of text from the article and a question. Decide whether this chunk is relevant to the question. Do not provide any explanation.\\n\\nArticle: {context}\\n\\n Now, decide whether the following chunk is relevant to the question or not. Only return \\\"Yes\\\" or \\\"No\\\" and do not provide any explanation.\\n\\nChunk: {chunk}\\n\\nQuestion: {input}\\n\\nAnswer:\",\n",
    "    # \"multifieldqa_en\": \"Read the following text and answer briefly.\\n\\n{context}\\n\\nNow, answer the following question based on the above text, only give me the answer and do not output any other words.\\n\\nQuestion: {input}\\nAnswer:\",\n",
    "    # \"multifieldqa_zh\": \"阅读以下文字并用中文简短回答：\\n\\n{context}\\n\\n现在请基于上面的文章回答下面的问题，只告诉我答案，不要输出任何其他字词。\\n\\n问题：{input}\\n回答：\",\n",
    "    # \"hotpotqa\": \"Answer the question based on the given passages. Only give me the answer and do not output any other words.\\n\\nThe following are given passages.\\n{context}\\n\\nAnswer the question based on the given passages. Only give me the answer and do not output any other words.\\n\\nQuestion: {input}\\nAnswer:\",\n",
    "    # \"2wikimqa\": \"Answer the question based on the given passages. Only give me the answer and do not output any other words.\\n\\nThe following are given passages.\\n{context}\\n\\nAnswer the question based on the given passages. Only give me the answer and do not output any other words.\\n\\nQuestion: {input}\\nAnswer:\",\n",
    "    # \"musique\": \"Answer the question based on the given passages. Only give me the answer and do not output any other words.\\n\\nThe following are given passages.\\n{context}\\n\\nAnswer the question based on the given passages. Only give me the answer and do not output any other words.\\n\\nQuestion: {input}\\nAnswer:\",\n",
    "    # \"dureader\": \"请基于给定的文章回答下述问题。\\n\\n文章：{context}\\n\\n请基于上述文章回答下面的问题。\\n\\n问题：{input}\\n回答：\",\n",
    "    \"gov_report\": \"You are given a report by a government agency and a chunk of text from the report. Decide whether this chunk should be included in an extractive summary.\\n\\nReport:\\n{context}\\n\\nNow, decide whether the following chunk should be included in an extractive summary. Only return \\\"Yes\\\" or \\\"No\\\" and do not provide any explanation.\\n\\nChunk: {chunk}\\n\\nAnswer:\",\n",
    "    \"qmsum\": \"You are given a meeting transcript, a chunk of text from the transcript and a query containing a question or instruction. Decide whether this chunk is relevant to the query. Do not provide any explanation.\\n\\nTranscript:\\n{context}\\n\\nNow, decide whether the following chunk is relevant to the query or not. Only return \\\"Yes\\\" or \\\"No\\\" and do not provide any explanation.\\n\\nChunk: {chunk}\\n\\nQuery: {input}\\n\\nAnswer:\",\n",
    "    # \"multi_news\": \"You are given several news passages. Write a one-page summary of all news. \\n\\nNews:\\n{context}\\n\\nNow, write a one-page summary of all the news.\\n\\nSummary:\",\n",
    "    # \"vcsum\": \"下面有一段会议记录，请你阅读后，写一段总结，总结会议的内容。\\n会议记录：\\n{context}\\n\\n会议总结：\",\n",
    "    # \"trec\": \"Please determine the type of the question below. Here are some examples of questions.\\n\\n{context}\\n{input}\",\n",
    "    # \"triviaqa\": \"Answer the question based on the given passage. Only give me the answer and do not output any other words. The following are some examples.\\n\\n{context}\\n\\n{input}\",\n",
    "    # \"samsum\": \"Summarize the dialogue into a few short sentences. The following are some examples.\\n\\n{context}\\n\\n{input}\",\n",
    "    # \"lsht\": \"请判断给定新闻的类别，下面是一些例子。\\n\\n{context}\\n{input}\",\n",
    "    # \"passage_count\": \"There are some paragraphs below sourced from Wikipedia. Some of them may be duplicates. Please carefully read these paragraphs and determine how many unique paragraphs there are after removing duplicates. In other words, how many non-repeating paragraphs are there in total?\\n\\n{context}\\n\\nPlease enter the final count of unique paragraphs after removing duplicates. The output format should only contain the number, such as 1, 2, 3, and so on.\\n\\nThe final answer is: \",\n",
    "    # \"passage_retrieval_en\": \"Here are 30 paragraphs from Wikipedia, along with an abstract. Please determine which paragraph the abstract is from.\\n\\n{context}\\n\\nThe following is an abstract.\\n\\n{input}\\n\\nPlease enter the number of the paragraph that the abstract is from. The answer format must be like \\\"Paragraph 1\\\", \\\"Paragraph 2\\\", etc.\\n\\nThe answer is: \",\n",
    "    # \"passage_retrieval_zh\": \"以下是若干段落文字，以及其中一个段落的摘要。请确定给定的摘要出自哪一段。\\n\\n{context}\\n\\n下面是一个摘要\\n\\n{input}\\n\\n请输入摘要所属段落的编号。答案格式必须是\\\"段落1\\\"，\\\"段落2\\\"等格式\\n\\n答案是：\",\n",
    "    # \"lcc\": \"Please complete the code given below. \\n{context}Next line of code:\\n\",\n",
    "    # \"repobench-p\": \"Please complete the code given below. \\n{context}{input}Next line of code:\\n\"\n",
    "}\n",
    "\n",
    "answers = defaultdict(list)\n",
    "for task in [\"narrativeqa\", \"qasper\", \n",
    "            #  \"multifieldqa_en\", \"hotpotqa\", \"2wikimqa\", \"musique\", \n",
    "             \"gov_report\", \"qmsum\"]:\n",
    "    dataset = []\n",
    "    for sample in tqdm(load_dataset('THUDM/LongBench', task, split='test')):\n",
    "        prompt = templates[task].format(context=sample['context']) if task == 'gov_report' else templates[task].format(context=sample['context'], input=sample['input'])\n",
    "        if len(tokenizer.encode(prompt)) < 32000 - 500:\n",
    "            chunks = f.split_text(sample['context'])\n",
    "            prompts = [relevant_templates[task].format(context=sample['context'], chunk=chunk) if task == 'gov_report' else relevant_templates[task].format(context=sample['context'], input=sample['input'], chunk=chunk) for chunk in chunks]\n",
    "            sample['chunk_relevant'] = [(chunk, gen[0].text) for chunk, gen in zip(chunks, f.llm.generate([[HumanMessage(content=prompt)] for prompt in prompts], max_tokens=5).generations)]\n",
    "            answers[task].append(sample)\n",
    "            \n",
    "write_json('relevant.json', answers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Non-context Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "templates = {\n",
    "    \"narrativeqa\": \"You are given a story, which can be either a novel or a movie script, and a question. Answer the question asconcisely as you can, using a single phrase if possible. Do not provide any explanation.\\n\\nStory: {context}\\n\\nNow, answer the question based on the story asconcisely as you can, using a single phrase if possible. Do not provide any explanation.\\n\\nQuestion: {input}\\n\\nAnswer:\",\n",
    "    \"qasper\": \"You are given a scientific article and a question. Answer the question as concisely as you can, using a single phrase or sentence if possible. If the question cannot be answered based on the information in the article, write \\\"unanswerable\\\". If the question is a yes/no question, answer \\\"yes\\\", \\\"no\\\", or \\\"unanswerable\\\". Do not provide any explanation.\\n\\nArticle: {context}\\n\\n Answer the question based on the above article as concisely as you can, using a single phrase or sentence if possible. If the question cannot be answered based on the information in the article, write \\\"unanswerable\\\". If the question is a yes/no question, answer \\\"yes\\\", \\\"no\\\", or \\\"unanswerable\\\". Do not provide any explanation.\\n\\nQuestion: {input}\\n\\nAnswer:\",\n",
    "    \"multifieldqa_en\": \"Read the following text and answer briefly.\\n\\n{context}\\n\\nNow, answer the following question based on the above text, only give me the answer and do not output any other words.\\n\\nQuestion: {input}\\nAnswer:\",\n",
    "    \"multifieldqa_zh\": \"阅读以下文字并用中文简短回答：\\n\\n{context}\\n\\n现在请基于上面的文章回答下面的问题，只告诉我答案，不要输出任何其他字词。\\n\\n问题：{input}\\n回答：\",\n",
    "    \"hotpotqa\": \"Answer the question based on the given passages. Only give me the answer and do not output any other words.\\n\\nThe following are given passages.\\n{context}\\n\\nAnswer the question based on the given passages. Only give me the answer and do not output any other words.\\n\\nQuestion: {input}\\nAnswer:\",\n",
    "    \"2wikimqa\": \"Answer the question based on the given passages. Only give me the answer and do not output any other words.\\n\\nThe following are given passages.\\n{context}\\n\\nAnswer the question based on the given passages. Only give me the answer and do not output any other words.\\n\\nQuestion: {input}\\nAnswer:\",\n",
    "    \"musique\": \"Answer the question based on the given passages. Only give me the answer and do not output any other words.\\n\\nThe following are given passages.\\n{context}\\n\\nAnswer the question based on the given passages. Only give me the answer and do not output any other words.\\n\\nQuestion: {input}\\nAnswer:\",\n",
    "    \"dureader\": \"请基于给定的文章回答下述问题。\\n\\n文章：{context}\\n\\n请基于上述文章回答下面的问题。\\n\\n问题：{input}\\n回答：\",\n",
    "    \"gov_report\": \"You are given a report by a government agency. Write a one-page summary of the report.\\n\\nReport:\\n{context}\\n\\nNow, write a one-page summary of the report.\\n\\nSummary:\",\n",
    "    \"qmsum\": \"You are given a meeting transcript and a query containing a question or instruction. Answer the query in one or more sentences.\\n\\nTranscript:\\n{context}\\n\\nNow, answer the query based on the above meeting transcript in one or more sentences.\\n\\nQuery: {input}\\nAnswer:\",\n",
    "    \"multi_news\": \"You are given several news passages. Write a one-page summary of all news. \\n\\nNews:\\n{context}\\n\\nNow, write a one-page summary of all the news.\\n\\nSummary:\",\n",
    "    \"vcsum\": \"下面有一段会议记录，请你阅读后，写一段总结，总结会议的内容。\\n会议记录：\\n{context}\\n\\n会议总结：\",\n",
    "    \"trec\": \"Please determine the type of the question below. Here are some examples of questions.\\n\\n{context}\\n{input}\",\n",
    "    \"triviaqa\": \"Answer the question based on the given passage. Only give me the answer and do not output any other words. The following are some examples.\\n\\n{context}\\n\\n{input}\",\n",
    "    \"samsum\": \"Summarize the dialogue into a few short sentences. The following are some examples.\\n\\n{context}\\n\\n{input}\",\n",
    "    \"lsht\": \"请判断给定新闻的类别，下面是一些例子。\\n\\n{context}\\n{input}\",\n",
    "    \"passage_count\": \"There are some paragraphs below sourced from Wikipedia. Some of them may be duplicates. Please carefully read these paragraphs and determine how many unique paragraphs there are after removing duplicates. In other words, how many non-repeating paragraphs are there in total?\\n\\n{context}\\n\\nPlease enter the final count of unique paragraphs after removing duplicates. The output format should only contain the number, such as 1, 2, 3, and so on.\\n\\nThe final answer is: \",\n",
    "    \"passage_retrieval_en\": \"Here are 30 paragraphs from Wikipedia, along with an abstract. Please determine which paragraph the abstract is from.\\n\\n{context}\\n\\nThe following is an abstract.\\n\\n{input}\\n\\nPlease enter the number of the paragraph that the abstract is from. The answer format must be like \\\"Paragraph 1\\\", \\\"Paragraph 2\\\", etc.\\n\\nThe answer is: \",\n",
    "    \"passage_retrieval_zh\": \"以下是若干段落文字，以及其中一个段落的摘要。请确定给定的摘要出自哪一段。\\n\\n{context}\\n\\n下面是一个摘要\\n\\n{input}\\n\\n请输入摘要所属段落的编号。答案格式必须是\\\"段落1\\\"，\\\"段落2\\\"等格式\\n\\n答案是：\",\n",
    "    \"lcc\": \"Please complete the code given below. \\n{context}Next line of code:\\n\",\n",
    "    \"repobench-p\": \"Please complete the code given below. \\n{context}{input}Next line of code:\\n\"\n",
    "}\n",
    "\n",
    "relevant_templates = {\n",
    "    \"narrativeqa\": 'You are given a chunk of text from a story and a question. Decide whether this chunk is relevant to the question or not. Only return \"Yes\" or \"No\" and do not provide any explanation.\\n\\nChunk: {chunk}\\n\\nQuestion: {input}\\n\\nAnswer:',\n",
    "    \"qasper\": \"You are given a chunk of text from an article and a question. Decide whether this chunk is relevant to the question or not. Only return \\\"Yes\\\" or \\\"No\\\" and do not provide any explanation.\\n\\nChunk: {chunk}\\n\\nQuestion: {input}\\n\\nAnswer:\",\n",
    "    # \"multifieldqa_en\": \"Read the following text and answer briefly.\\n\\n{context}\\n\\nNow, answer the following question based on the above text, only give me the answer and do not output any other words.\\n\\nQuestion: {input}\\nAnswer:\",\n",
    "    # \"multifieldqa_zh\": \"阅读以下文字并用中文简短回答：\\n\\n{context}\\n\\n现在请基于上面的文章回答下面的问题，只告诉我答案，不要输出任何其他字词。\\n\\n问题：{input}\\n回答：\",\n",
    "    # \"hotpotqa\": \"Answer the question based on the given passages. Only give me the answer and do not output any other words.\\n\\nThe following are given passages.\\n{context}\\n\\nAnswer the question based on the given passages. Only give me the answer and do not output any other words.\\n\\nQuestion: {input}\\nAnswer:\",\n",
    "    # \"2wikimqa\": \"Answer the question based on the given passages. Only give me the answer and do not output any other words.\\n\\nThe following are given passages.\\n{context}\\n\\nAnswer the question based on the given passages. Only give me the answer and do not output any other words.\\n\\nQuestion: {input}\\nAnswer:\",\n",
    "    # \"musique\": \"Answer the question based on the given passages. Only give me the answer and do not output any other words.\\n\\nThe following are given passages.\\n{context}\\n\\nAnswer the question based on the given passages. Only give me the answer and do not output any other words.\\n\\nQuestion: {input}\\nAnswer:\",\n",
    "    # \"dureader\": \"请基于给定的文章回答下述问题。\\n\\n文章：{context}\\n\\n请基于上述文章回答下面的问题。\\n\\n问题：{input}\\n回答：\",\n",
    "    # \"gov_report\": \"You are given a report by a government agency and a chunk of text from the report. Decide whether this chunk should be included in an extractive summary.\\n\\nReport:\\n{context}\\n\\nNow, decide whether the following chunk should be included in an extractive summary. Only return \\\"Yes\\\" or \\\"No\\\" and do not provide any explanation.\\n\\nChunk: {chunk}\\n\\nAnswer:\",\n",
    "    \"qmsum\": \"You are given a chunk of text from a transcript and a query containing a question or instruction. Decide whether this chunk is relevant to the query or not. Only return \\\"Yes\\\" or \\\"No\\\" and do not provide any explanation.\\n\\nChunk: {chunk}\\n\\nQuery: {input}\\n\\nAnswer:\",\n",
    "    # \"multi_news\": \"You are given several news passages. Write a one-page summary of all news. \\n\\nNews:\\n{context}\\n\\nNow, write a one-page summary of all the news.\\n\\nSummary:\",\n",
    "    # \"vcsum\": \"下面有一段会议记录，请你阅读后，写一段总结，总结会议的内容。\\n会议记录：\\n{context}\\n\\n会议总结：\",\n",
    "    # \"trec\": \"Please determine the type of the question below. Here are some examples of questions.\\n\\n{context}\\n{input}\",\n",
    "    # \"triviaqa\": \"Answer the question based on the given passage. Only give me the answer and do not output any other words. The following are some examples.\\n\\n{context}\\n\\n{input}\",\n",
    "    # \"samsum\": \"Summarize the dialogue into a few short sentences. The following are some examples.\\n\\n{context}\\n\\n{input}\",\n",
    "    # \"lsht\": \"请判断给定新闻的类别，下面是一些例子。\\n\\n{context}\\n{input}\",\n",
    "    # \"passage_count\": \"There are some paragraphs below sourced from Wikipedia. Some of them may be duplicates. Please carefully read these paragraphs and determine how many unique paragraphs there are after removing duplicates. In other words, how many non-repeating paragraphs are there in total?\\n\\n{context}\\n\\nPlease enter the final count of unique paragraphs after removing duplicates. The output format should only contain the number, such as 1, 2, 3, and so on.\\n\\nThe final answer is: \",\n",
    "    # \"passage_retrieval_en\": \"Here are 30 paragraphs from Wikipedia, along with an abstract. Please determine which paragraph the abstract is from.\\n\\n{context}\\n\\nThe following is an abstract.\\n\\n{input}\\n\\nPlease enter the number of the paragraph that the abstract is from. The answer format must be like \\\"Paragraph 1\\\", \\\"Paragraph 2\\\", etc.\\n\\nThe answer is: \",\n",
    "    # \"passage_retrieval_zh\": \"以下是若干段落文字，以及其中一个段落的摘要。请确定给定的摘要出自哪一段。\\n\\n{context}\\n\\n下面是一个摘要\\n\\n{input}\\n\\n请输入摘要所属段落的编号。答案格式必须是\\\"段落1\\\"，\\\"段落2\\\"等格式\\n\\n答案是：\",\n",
    "    # \"lcc\": \"Please complete the code given below. \\n{context}Next line of code:\\n\",\n",
    "    # \"repobench-p\": \"Please complete the code given below. \\n{context}{input}Next line of code:\\n\"\n",
    "}\n",
    "\n",
    "answers = defaultdict(list)\n",
    "for task in [\"narrativeqa\", \"qasper\", \n",
    "            #  \"multifieldqa_en\", \"hotpotqa\", \"2wikimqa\", \"musique\", \n",
    "            #  \"gov_report\", \n",
    "             \"qmsum\"]:\n",
    "    dataset = []\n",
    "    for sample in tqdm(load_dataset('THUDM/LongBench', task, split='test')):\n",
    "        prompt = templates[task].format(context=sample['context']) if task == 'gov_report' else templates[task].format(context=sample['context'], input=sample['input'])\n",
    "        if len(tokenizer.encode(prompt)) < 32000 - 500:\n",
    "            chunks = f.split_text(sample['context'])\n",
    "            prompts = [relevant_templates[task].format(input=sample['input'], chunk=chunk) for chunk in chunks]\n",
    "            sample['chunk_relevant'] = [(chunk, gen[0].text) for chunk, gen in zip(chunks, f.llm.generate([[HumanMessage(content=prompt)] for prompt in prompts], max_tokens=5).generations)]\n",
    "            answers[task].append(sample)\n",
    "            \n",
    "write_json('relevant_non_context.json', answers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer with Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "templates = {\n",
    "    \"narrativeqa\": \"You are given a story, which can be either a novel or a movie script, and a question. Answer the question asconcisely as you can, using a single phrase if possible. Do not provide any explanation.\\n\\nStory: {context}\\n\\nNow, answer the question based on the story asconcisely as you can, using a single phrase if possible. Do not provide any explanation.\\n\\nQuestion: {input}\\n\\nAnswer:\",\n",
    "    \"qasper\": \"You are given a scientific article and a question. Answer the question as concisely as you can, using a single phrase or sentence if possible. If the question cannot be answered based on the information in the article, write \\\"unanswerable\\\". If the question is a yes/no question, answer \\\"yes\\\", \\\"no\\\", or \\\"unanswerable\\\". Do not provide any explanation.\\n\\nArticle: {context}\\n\\n Answer the question based on the above article as concisely as you can, using a single phrase or sentence if possible. If the question cannot be answered based on the information in the article, write \\\"unanswerable\\\". If the question is a yes/no question, answer \\\"yes\\\", \\\"no\\\", or \\\"unanswerable\\\". Do not provide any explanation.\\n\\nQuestion: {input}\\n\\nAnswer:\",\n",
    "    \"multifieldqa_en\": \"Read the following text and answer briefly.\\n\\n{context}\\n\\nNow, answer the following question based on the above text, only give me the answer and do not output any other words.\\n\\nQuestion: {input}\\nAnswer:\",\n",
    "    \"multifieldqa_zh\": \"阅读以下文字并用中文简短回答：\\n\\n{context}\\n\\n现在请基于上面的文章回答下面的问题，只告诉我答案，不要输出任何其他字词。\\n\\n问题：{input}\\n回答：\",\n",
    "    \"hotpotqa\": \"Answer the question based on the given passages. Only give me the answer and do not output any other words.\\n\\nThe following are given passages.\\n{context}\\n\\nAnswer the question based on the given passages. Only give me the answer and do not output any other words.\\n\\nQuestion: {input}\\nAnswer:\",\n",
    "    \"2wikimqa\": \"Answer the question based on the given passages. Only give me the answer and do not output any other words.\\n\\nThe following are given passages.\\n{context}\\n\\nAnswer the question based on the given passages. Only give me the answer and do not output any other words.\\n\\nQuestion: {input}\\nAnswer:\",\n",
    "    \"musique\": \"Answer the question based on the given passages. Only give me the answer and do not output any other words.\\n\\nThe following are given passages.\\n{context}\\n\\nAnswer the question based on the given passages. Only give me the answer and do not output any other words.\\n\\nQuestion: {input}\\nAnswer:\",\n",
    "    \"dureader\": \"请基于给定的文章回答下述问题。\\n\\n文章：{context}\\n\\n请基于上述文章回答下面的问题。\\n\\n问题：{input}\\n回答：\",\n",
    "    \"gov_report\": \"You are given a report by a government agency. Write a one-page summary of the report.\\n\\nReport:\\n{context}\\n\\nNow, write a one-page summary of the report.\\n\\nSummary:\",\n",
    "    \"qmsum\": \"You are given a meeting transcript and a query containing a question or instruction. Answer the query in one or more sentences.\\n\\nTranscript:\\n{context}\\n\\nNow, answer the query based on the above meeting transcript in one or more sentences.\\n\\nQuery: {input}\\nAnswer:\",\n",
    "    \"multi_news\": \"You are given several news passages. Write a one-page summary of all news. \\n\\nNews:\\n{context}\\n\\nNow, write a one-page summary of all the news.\\n\\nSummary:\",\n",
    "    \"vcsum\": \"下面有一段会议记录，请你阅读后，写一段总结，总结会议的内容。\\n会议记录：\\n{context}\\n\\n会议总结：\",\n",
    "    \"trec\": \"Please determine the type of the question below. Here are some examples of questions.\\n\\n{context}\\n{input}\",\n",
    "    \"triviaqa\": \"Answer the question based on the given passage. Only give me the answer and do not output any other words. The following are some examples.\\n\\n{context}\\n\\n{input}\",\n",
    "    \"samsum\": \"Summarize the dialogue into a few short sentences. The following are some examples.\\n\\n{context}\\n\\n{input}\",\n",
    "    \"lsht\": \"请判断给定新闻的类别，下面是一些例子。\\n\\n{context}\\n{input}\",\n",
    "    \"passage_count\": \"There are some paragraphs below sourced from Wikipedia. Some of them may be duplicates. Please carefully read these paragraphs and determine how many unique paragraphs there are after removing duplicates. In other words, how many non-repeating paragraphs are there in total?\\n\\n{context}\\n\\nPlease enter the final count of unique paragraphs after removing duplicates. The output format should only contain the number, such as 1, 2, 3, and so on.\\n\\nThe final answer is: \",\n",
    "    \"passage_retrieval_en\": \"Here are 30 paragraphs from Wikipedia, along with an abstract. Please determine which paragraph the abstract is from.\\n\\n{context}\\n\\nThe following is an abstract.\\n\\n{input}\\n\\nPlease enter the number of the paragraph that the abstract is from. The answer format must be like \\\"Paragraph 1\\\", \\\"Paragraph 2\\\", etc.\\n\\nThe answer is: \",\n",
    "    \"passage_retrieval_zh\": \"以下是若干段落文字，以及其中一个段落的摘要。请确定给定的摘要出自哪一段。\\n\\n{context}\\n\\n下面是一个摘要\\n\\n{input}\\n\\n请输入摘要所属段落的编号。答案格式必须是\\\"段落1\\\"，\\\"段落2\\\"等格式\\n\\n答案是：\",\n",
    "    \"lcc\": \"Please complete the code given below. \\n{context}Next line of code:\\n\",\n",
    "    \"repobench-p\": \"Please complete the code given below. \\n{context}{input}Next line of code:\\n\"\n",
    "}\n",
    "\n",
    "answers = defaultdict(list)\n",
    "relevant_non_context:dict = read_json('relevant_non_context.json')\n",
    "for task, samples in relevant_non_context.items():\n",
    "    dataset = []\n",
    "    for sample in samples:\n",
    "        context = '\\n\\n'.join([f'Passage {pid + 1}: {p}' for pid, (p, y_o_n) in enumerate(sample['chunk_relevant']) if 'yes' in y_o_n.lower() and 'no' not in y_o_n.lower()])\n",
    "        prompt = templates[task].format(context=context) if task == 'gov_report' else templates[task].format(context=context, input=sample['input'])\n",
    "        sample['prompt'] = prompt\n",
    "        sample['retrieved_context'] = context\n",
    "        if context:\n",
    "            dataset.append(sample)\n",
    "        else:\n",
    "            sample['gen'] = 'unanswerable'\n",
    "        answers[task].append(sample)\n",
    "    for i in tqdm(range((len(dataset) + 1) // 5)):\n",
    "        batch_samples = dataset[i*5 : (i+1)*5]\n",
    "        for sample, gen in zip(batch_samples, f.llm.generate([[HumanMessage(content=sample['prompt'])] for sample in batch_samples]).generations):\n",
    "            sample['gen'] = gen[0].text\n",
    "            sample['token_usage'] = gen[0].message.response_metadata['token_usage']\n",
    "write_json('relevant_non_context_answers.json', answers)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# narrativeqa = load_dataset('THUDM/LongBench', 'narrativeqa', split='test')\n",
    "# narrativeqa = load_dataset('deepmind/narrativeqa', split='train')\n",
    "qasper = load_dataset('THUDM/LongBench', 'qasper', split='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "narrativeqa[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text:str = narrativeqa[0]['document']['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text:str = qasper[0]['context']\n",
    "passages = [' '.join(p.strip().split()) for p in text.split('\\n') if p.strip()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('article.txt', 'w') as f_out:\n",
    "    f_out.write(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('article.txt') as f_in:\n",
    "    text = f_in.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wikipediaapi import Wikipedia\n",
    "wiki_wiki = Wikipedia('MyProjectName (merlin@example.com)', 'en')\n",
    "page_py = wiki_wiki.page('Python_(programming_language)')\n",
    "text = '\\n\\n'.join([passage.strip() for sec_text in page_py.sections for passage in sec_text.full_text().splitlines()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "passages = [' '.join(p.strip().split()) for p in text.split('\\n\\n') if p.strip()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "passages[16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.nlp.pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# passages = passages[17:]\n",
    "chunks, start_p = list[str](), 0\n",
    "for end_p in range(len(passages)):\n",
    "    passage_text = '\\n\\n'.join(passages[start_p : end_p+1])\n",
    "    # passage_len = len(tokenizer.encode(passage_text, add_special_tokens=False))\n",
    "    passage_len = len(list(f.nlp(passage_text, disable=['lemmatizer', 'ner']).sents))\n",
    "    if passage_len < 3 and end_p+1 < len(passages):\n",
    "        continue\n",
    "    start_p = end_p+1\n",
    "    chunks.append(passage_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_switch_prompt = '''\n",
    "Identify the first sentence in the passages below that marks a turning point in the narrative focus. This sentence should act as a boundary, where the content before it maintains a consistent focus on one topic, and the content after it shifts to a different focus. In your explanation, use one or two sentences to briefly describe the narrative focus both before and immediately after this turning point.\n",
    "\n",
    "\n",
    "Passages:\n",
    "\n",
    "{passages}\n",
    "\n",
    "\n",
    "Now, generate your response, organizing it under the following headers: \"Turning Point\" for the first turning point sentence, \"Topic before\" and \"Topic after\" for the explanation of topic before and immediately after turning point sentence.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_switch_prompt = '''\n",
    "Identify the first sentence in the passages below that marks a turning point in the narrative focus. This sentence should act as a boundary, where the content before it maintains a consistent focus on one topic, and the content after it shifts to a different focus. In your response, first, briefly describe the narrative focus at the beginning, second, identify the turning point sentence and finally, briefly describe the narrative focus immediately after the turning point.\n",
    "\n",
    "\n",
    "Passages:\n",
    "\n",
    "{passages}\n",
    "\n",
    "\n",
    "Now, generate your response, organizing it under the following headers: \"Beginning Topic\" for the topic at the beginning, \"Turning Point\" for the first turning point sentence, and \"Topic after\" for the explanation of topic immediately after the turning point sentence.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_topic_prompt = '''\n",
    "What is the topic of the following passage?\n",
    "\n",
    "{passage}\n",
    "\n",
    "Now, generate your response with one statement starting with \"Current Topic: \".\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_topic_consist_prompt = '''\n",
    "Using the provided background context, current topic, recent passages under the current topic, and the next passage in the narrative, evaluate how the next passage influences the current topic. Leverage the background context to deepen your understanding of the topics and passage content.\n",
    "\n",
    "Background Context:\n",
    "{context}\n",
    "\n",
    "Current Topic:\n",
    "{topic}\n",
    "\n",
    "Recent Passages:\n",
    "{last_passage}\n",
    "\n",
    "You will now receive the next passage. Assess its impact on the current topic in relation to the recent passages and choose the condition that best describes the effect:\n",
    "\n",
    "If the next passage stays within the current topic and adds further information, respond with \"Same Topic\".\n",
    "If the next passage introduces new information that shifts away from the current topic, respond with a concise statement of the new topic starting with \"New Topic: \".\n",
    "If the next passage explores a specific aspect in greater detail to enhance understanding of the current topic, respond with a concise statement of the subtopic starting with \"Subtopic: \".\n",
    "\n",
    "Next Passage:\n",
    "{passage}\n",
    "\n",
    "Briefly explain your thought first and finally give me your response as described above.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_topic_consist_prompt = '''\n",
    "Using the provided background context, current topic, recent passages under the current topic, and the next passage in the narrative, evaluate how the next passage influences the current topic. Leverage the background context to deepen your understanding of the topics and passage content.\n",
    "\n",
    "Background Context:\n",
    "{context}\n",
    "\n",
    "Current Topic:\n",
    "{topic}\n",
    "\n",
    "Recent Passages:\n",
    "{last_passage}\n",
    "\n",
    "You will now receive the next passage. Assess its impact on the current topic in relation to the recent passages using the following guidelines:\n",
    "\n",
    "1.\tCompare Keywords and Main Ideas:\n",
    "    If keywords and main ideas are similar, the passages likely share the same topic or a subtopic.\n",
    "    If they differ significantly, the next passage may introduce a new topic.\n",
    "2.\tCheck Transitional Words and Topic Sentences:\n",
    "    Look for transitions like “however” or “meanwhile,” which might signal a shift.\n",
    "    The first sentence of the next passage can indicate if it's continuing the previous topic or introducing something new.\n",
    "3.\tExamine Narrative Flow and Context:\n",
    "    If the characters or setting change, it might indicate a new topic.\n",
    "    Consistent elements usually suggest the same topic or a subtopic.\n",
    "4.\tIdentify the Author's Purpose:\n",
    "    A shift in the author's focus or purpose often signals a new topic.\n",
    "    A deeper exploration of the same idea usually indicates a subtopic.\n",
    "5.\tLook at Structural Cues:\n",
    "    A new paragraph with a different focus may introduce a new topic.\n",
    "    Continuation within the same context suggests the same topic or a subtopic.\n",
    "\n",
    "Next Passage:\n",
    "{passage}\n",
    "\n",
    "If the next passage stays with the same topic, respond with \"Same Topic\".\n",
    "If the next passage introduces a new topic, respond with a concise statement of the new topic starting with \"New Topic: \".\n",
    "If the next passage explores a subtopic of the current topic, respond with a concise statement of the subtopic starting with \"Subtopic: \".\n",
    "Briefly explain your thought first and finally give me your response as described above.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# passages = [f.nlp(p, disable=['ner']) for p in passages[17:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Topic:\n",
    "    def __init__(self, tid:int, parent_pid:int, topic:str, passage:str):\n",
    "        self.tid = tid\n",
    "        self.parent_pid = parent_pid\n",
    "        self.topic = topic\n",
    "        self.passages = list[str]()\n",
    "        self.structure = list[str|Topic]()\n",
    "        self.passages.append(passage)\n",
    "        self.structure.append(passage)\n",
    "        self.parent: Topic = None\n",
    "    \n",
    "    def add_subtopic(self, subtopic:str, passage:str):\n",
    "        subtopic_cnt = 0\n",
    "        for p in self.structure:\n",
    "            if isinstance(p, Topic):\n",
    "                subtopic_cnt += 1\n",
    "                \n",
    "        subtopic_obj = Topic(tid=subtopic_cnt, parent_pid=len(self.passages)-1, topic=subtopic, passage=passage)\n",
    "        subtopic_obj.parent = self\n",
    "        self.structure.append(subtopic_obj)\n",
    "        return subtopic_obj\n",
    "    \n",
    "    def append_passage(self, passage:str):\n",
    "        self.passages.append(passage)\n",
    "        self.structure.append(passage)\n",
    "        \n",
    "    def get_context(self, n:int=3, context_width:int=1):\n",
    "        current_topic = self\n",
    "        context = []\n",
    "        layer_cnt = 0\n",
    "        while current_topic.parent is not None and layer_cnt < n:\n",
    "            # context.insert(0, f'{current_topic.parent.get_formated_topic()}\\n\\n{current_topic.parent.passages[current_topic.parent_pid]}')\n",
    "            # context = current_topic.parent.passages[max(0, current_topic.parent_pid + 1 - context_width) : current_topic.parent_pid + 1] + context\n",
    "            context.insert(0, current_topic.parent.passages[current_topic.parent_pid])\n",
    "            current_topic = current_topic.parent\n",
    "            layer_cnt += 1\n",
    "        return '\\n\\n'.join(context)\n",
    "    \n",
    "    def get_formated_topic(self):\n",
    "        accumulated_tid_str = '.'.join([str(tid + 1) for tid in self.get_accumulated_tid()])\n",
    "        return f'Topic {accumulated_tid_str}. {self.topic}'\n",
    "    \n",
    "    def get_accumulated_tid(self):\n",
    "        tids = list[int]()\n",
    "        current_topic = self\n",
    "        while current_topic is not None:\n",
    "            tids.insert(0, current_topic.tid)\n",
    "            current_topic = current_topic.parent\n",
    "        return tids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_topic(passage:str):\n",
    "    prompt = query_topic_prompt.format(passage=passage)\n",
    "    response = f.llm.generate([[HumanMessage(prompt)]]).generations[0][0].text\n",
    "    \n",
    "    start_topic = response.split('Current Topic: ')[-1].strip()\n",
    "    current_topic_obj = Topic(tid=0, parent_pid=-1, topic=start_topic, passage=passage)\n",
    "    return current_topic_obj, [(prompt, response)]\n",
    "        \n",
    "def query_topic_consist(current_topic_obj:Topic, passage:str):\n",
    "    prompt_responses = list[tuple[str, str]]()\n",
    "    \n",
    "    prompt = query_topic_consist_prompt.format(context=current_topic_obj.get_context(), topic=current_topic_obj.get_formated_topic(), last_passage=current_topic_obj.passages[-1], passage=passage)\n",
    "    response = f.llm.generate([[HumanMessage(prompt)]]).generations[0][0].text\n",
    "    prompt_responses.append((prompt, response))\n",
    "    \n",
    "    if 'Same Topic' in response:\n",
    "        current_topic_obj.append_passage(passage)\n",
    "    elif 'New Topic:' in response:\n",
    "        if current_topic_obj.parent_pid < 0:\n",
    "            new_topic = sent_tokenize([line for line in response.split('New Topic:')[-1].strip().splitlines() if line][0])[0]\n",
    "            current_topic_obj = Topic(tid=current_topic_obj.tid + 1, parent_pid=-1, topic=new_topic, passage=passage)\n",
    "        else:\n",
    "            current_topic_obj, temp_prompt_responses = query_topic_consist(current_topic_obj.parent, passage)\n",
    "            prompt_responses.extend(temp_prompt_responses)\n",
    "    elif 'Subtopic:' in response:\n",
    "        subtopic = sent_tokenize([line for line in response.split('Subtopic:')[-1].strip().splitlines() if line][0])[0]\n",
    "        current_topic_obj = current_topic_obj.add_subtopic(subtopic, passage)\n",
    "    else:\n",
    "        print(prompt)\n",
    "        print('----------------------------------------------')\n",
    "        print(response)\n",
    "        raise NotImplementedError\n",
    "    return current_topic_obj, prompt_responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics, prompt_responses = list[Topic](), []\n",
    "for cid, chunk in enumerate(tqdm(chunks)):\n",
    "    if not topics:\n",
    "        current_topic_obj, temp_prompt_responses = query_topic(chunk)\n",
    "        topics.append(current_topic_obj)\n",
    "    else:\n",
    "        current_topic_obj, temp_prompt_responses = query_topic_consist(current_topic_obj, chunk)\n",
    "        if current_topic_obj.parent_pid < 0 and current_topic_obj.tid != topics[-1].tid:\n",
    "            topics.append(current_topic_obj)\n",
    "    prompt_responses.extend(temp_prompt_responses)\n",
    "    last_passage = passage_text\n",
    "    # if cid >= 30:\n",
    "    #     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('article.pickle', 'wb') as f_out:\n",
    "    pickle.dump(topics, f_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_id = 3\n",
    "print(prompt_responses[test_id][0])\n",
    "print('----------------------------------------------')\n",
    "print(prompt_responses[test_id][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_menu(structure:List[str|Topic], expand_subtopics:List[str]=[]):\n",
    "    menu, topic_mask = list[str](), list[bool]()\n",
    "    for p in structure:\n",
    "        if isinstance(p, str):\n",
    "            menu.append(p)\n",
    "            topic_mask.append(False)\n",
    "        else:\n",
    "            formated_topic = p.get_formated_topic()\n",
    "            menu.append(formated_topic)\n",
    "            topic_mask.append(True)\n",
    "            if any([formated_topic.startswith(expand_subtopic) for expand_subtopic in expand_subtopics]):\n",
    "                temp_menu, temp_topic_mask = get_menu(p.structure, expand_subtopics)\n",
    "                menu.extend(temp_menu)\n",
    "                topic_mask.extend(temp_topic_mask)\n",
    "    return menu, topic_mask\n",
    "\n",
    "def plot_menu(menu:List[str], topic_mask:List[bool]):\n",
    "    for p, is_topic in zip(menu, topic_mask):\n",
    "        if is_topic:\n",
    "            print('------------------------------------------')\n",
    "        print(p, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('python.pickle', 'rb') as f_in:\n",
    "    topics:List[Topic] = pickle.load(f_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_menu(*get_menu(topics, [\n",
    "    # 'Topic 2. ',\n",
    "    # 'Topic 1. ',\n",
    "    # 'Topic 3. ',\n",
    "    # 'Topic 4. ',\n",
    "    # 'Topic 5. ',\n",
    "    # 'Topic 8. '\n",
    "]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\n'.join([f'Section {tid+1}. {t.topic}' for tid, t in enumerate(topics)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics[2].topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics[2].structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_p, start_sent = 0, 0\n",
    "for end_p in range(len(passages)):\n",
    "    temp_passages = [p.text for p in passages[start_p : end_p+1]]\n",
    "    if start_sent > 0:\n",
    "        temp_passages = [''.join([sent.text_with_ws for sent in passages[start_p].sents])] + temp_passages[1:]\n",
    "    passage_text = '\\n\\n'.join(temp_passages)\n",
    "    passage_len = len(tokenizer.encode(passage_text, add_special_tokens=False))\n",
    "    if passage_len < 2000 and end_p+1 < len(passages):\n",
    "        continue\n",
    "    response = f.llm.generate([[HumanMessage(topic_switch_prompt.format(passages=temp_passages))]])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response.generations[0][0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response.generations[0][0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(passage_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\n\\n'.join(passages[0:5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "examine_passages = passages[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "background_event_cls_prompt = '''\n",
    "Given a piece of text, decide whether it is background knowledge or dynamic knowledge.\n",
    "\n",
    "Background knowledge describing facts that are true in most contexts.'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from metrics import (\n",
    "    qa_f1_score,\n",
    "    rouge_zh_score,\n",
    "    qa_f1_zh_score,\n",
    "    rouge_score,\n",
    "    classification_score,\n",
    "    retrieval_score,\n",
    "    retrieval_zh_score,\n",
    "    count_score,\n",
    "    code_sim_score,\n",
    ")\n",
    "\n",
    "dataset2metric = {\n",
    "    \"narrativeqa\": qa_f1_score,\n",
    "    \"qasper\": qa_f1_score,\n",
    "    \"multifieldqa_en\": qa_f1_score,\n",
    "    \"multifieldqa_zh\": qa_f1_zh_score,\n",
    "    \"hotpotqa\": qa_f1_score,\n",
    "    \"2wikimqa\": qa_f1_score,\n",
    "    \"musique\": qa_f1_score,\n",
    "    \"dureader\": rouge_zh_score,\n",
    "    \"gov_report\": rouge_score,\n",
    "    \"qmsum\": rouge_score,\n",
    "    \"multi_news\": rouge_score,\n",
    "    \"vcsum\": rouge_zh_score,\n",
    "    \"trec\": classification_score,\n",
    "    \"triviaqa\": qa_f1_score,\n",
    "    \"samsum\": rouge_score,\n",
    "    \"lsht\": classification_score,\n",
    "    \"passage_retrieval_en\": retrieval_score,\n",
    "    \"passage_count\": count_score,\n",
    "    \"passage_retrieval_zh\": retrieval_zh_score,\n",
    "    \"lcc\": code_sim_score,\n",
    "    \"repobench-p\": code_sim_score,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_samples = read_json('baseline.json')\n",
    "baseline_samples.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(baseline_samples['qmsum'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_samples = read_json('baseline.json')\n",
    "for task, samples in baseline_samples.items():\n",
    "    for sample in samples:\n",
    "        if 'Unanswerable' not in sample['answers']:\n",
    "            sample['score'] = max(dataset2metric[task](sample['gen'], ground_truth) for ground_truth in sample['answers'])\n",
    "        else:\n",
    "            sample['score'] = -1\n",
    "    print(task, np.mean([sample['score'] for sample in samples if sample['score'] != -1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[sample['answers'] for sample in baseline_samples['qasper']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relevant_non_context_samples = read_json('relevant_non_context_answers.json')\n",
    "for task, samples in relevant_non_context_samples.items():\n",
    "    for sample in samples:\n",
    "        if 'Unanswerable' not in sample['answers']:\n",
    "            sample['score'] = max(dataset2metric[task](sample['gen'], ground_truth) for ground_truth in sample['answers'])\n",
    "        else:\n",
    "            sample['score'] = -1\n",
    "    print(task, np.mean([sample['score'] for sample in samples if sample['score'] != -1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relevant_samples = read_json('relevant_answers.json')\n",
    "for task, samples in relevant_samples.items():\n",
    "    for sample in samples:\n",
    "        if 'Unanswerable' not in sample['answers']:\n",
    "            sample['score'] = max(dataset2metric[task](sample['gen'], ground_truth) for ground_truth in sample['answers'])\n",
    "        else:\n",
    "            sample['score'] = -1\n",
    "    print(task, np.mean([sample['score'] for sample in samples if sample['score'] != -1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_list = defaultdict(list)\n",
    "for task in ['narrativeqa', 'qasper', 'gov_report', 'qmsum']:\n",
    "    for sample_b in baseline_samples[task]:\n",
    "        for sample_r in relevant_samples[task]:\n",
    "            if sample_b['context'] == sample_r['context'] and sample_b['input'] == sample_r['input']:\n",
    "                compare_list[task].append({'base': sample_b, 'ret': sample_r})\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task = 'narrativeqa'\n",
    "bad_compare_list = [p for p in compare_list[task] if p['base']['score'] > p['ret']['score']]\n",
    "print('bad', len(bad_compare_list))\n",
    "good_compare_list = [p for p in compare_list[task] if p['base']['score'] < p['ret']['score']]\n",
    "print('good', len(good_compare_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "narrativeqa_check = [5,6,7,8,10,11,17,19,21]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_pair = bad_compare_list[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_pair['base']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_pair['ret']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(compare_pair['ret']['context'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_pair['ret'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(compare_pair['ret']['retrieved_context'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for chunk, r in compare_pair['ret']['chunk_relevant']:\n",
    "    print(chunk)\n",
    "    print('---------------------------')\n",
    "    print(r)\n",
    "    print('---------------------------')\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "longdoc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
