{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MYOnCMh83ZRE"
      },
      "outputs": [],
      "source": [
        "import time, datetime, json, os\n",
        "from tqdm.notebook import tqdm\n",
        "from collections import defaultdict, Counter\n",
        "import numpy as np\n",
        "\n",
        "from index_files import LongDoc, write_json, QualityDataset, NarrativeQADataset, ReadingAgent, read_json, read_jsonline, LLM, Retriever"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "retriever = Retriever()\n",
        "llm = LLM()\n",
        "# llm = 'mistralai/Mistral-7B-Instruct-v0.2'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Experiment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dataset = NarrativeQADataset(llm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dataset = QualityDataset(llm, split='dev')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8YKNTyDsXNIn"
      },
      "outputs": [],
      "source": [
        "reading_agent = ReadingAgent(dataset, llm)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Index passages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "from typing import List, Tuple, Set, Dict\n",
        "import re\n",
        "import itertools\n",
        "import networkx as nx\n",
        "from prompt import prompt_shorten_template, prompt_ent_description_template, \\\n",
        "    prompt_relation_description_template, prompt_shorten_w_note_template, \\\n",
        "    prompt_ent_description_w_note_template, prompt_relation_description_w_note_template\n",
        "\n",
        "def match_entities(target_ents:List[str], refer_ents:List[str]):\n",
        "    target_ents_emb = retriever.embed_paragraphs(target_ents, True)\n",
        "    refer_ents_emb = retriever.embed_paragraphs(refer_ents, True)\n",
        "    sim_mat:np.ndarray = np.matmul(target_ents_emb, refer_ents_emb.T)\n",
        "    ent_map:Dict[str, str] = {}\n",
        "    for eid, ent in enumerate(target_ents):\n",
        "        max_idx = sim_mat[eid].argmax()\n",
        "        if sim_mat[eid, max_idx] > 0.8:\n",
        "            ent_map[ent] = refer_ents[max_idx]\n",
        "    return ent_map\n",
        "\n",
        "def remove_citation(text:str):\n",
        "    # if 'source passage' in text.lower():\n",
        "    #     text = text[:text.lower().index('source passage')]\n",
        "    #     return text.strip('( )')\n",
        "    # else:\n",
        "    #     return text\n",
        "    return re.sub(\"[\\(\\[].*?[\\)\\]]\", \"\", text).strip()\n",
        "\n",
        "def index_text(paragraphs:List[str], recap_num:int=2, context_type:str='novel'):\n",
        "    results = []\n",
        "    test_results = []\n",
        "    for paragraph in tqdm(paragraphs):\n",
        "        \n",
        "        # Extract important entities\n",
        "        list_entity_prompt = f'''Context:\\n\\n{paragraph}\\n\\nAbove is part of a {context_type}. List the important named entities in the above context that are relevant to most of its content. Don't give any explanation. Generate your response in the following format: \"Important entities:\\n1. Entity 1\\n2. Entity 2\\n3. Entity 3\\n...\"'''\n",
        "        chat_response = llm(list_entity_prompt, 5, 0.7)[0]\n",
        "        ent_lists:List[str] = []\n",
        "        ent_cnt = Counter()\n",
        "        for response in chat_response:\n",
        "            i = 1\n",
        "            temp_ents = []\n",
        "            for line in response.splitlines():\n",
        "                if line.startswith(f'{i}. '):\n",
        "                    temp_ents.append(line.split(' ', 1)[1].strip().strip('.'))\n",
        "                    i += 1\n",
        "            ent_lists.append(temp_ents)\n",
        "            ent_cnt.update(temp_ents)\n",
        "        g = nx.Graph()\n",
        "        for list1, list2 in itertools.combinations(ent_lists, 2):\n",
        "            g.add_edges_from(match_entities(list1, list2).items())\n",
        "        ent_cluster:Set[str]\n",
        "        rep_cnt = {}\n",
        "        for ent_cluster in nx.connected_components(g):\n",
        "            cnts = [(ent_cnt[ent], ent) for ent in ent_cluster]\n",
        "            cnts.sort(key=lambda x: x[0], reverse=True)\n",
        "            rep_cnt[cnts[0][1]] = sum([cnt for cnt, _ in cnts])\n",
        "        important_ents = [rep for rep, cnt in rep_cnt.items() if cnt >= 3]\n",
        "        \n",
        "        # Generate entity description, summary, relation description\n",
        "        important_ents_str = '\\n'.join(important_ents)\n",
        "        prompt_ent_description = prompt_ent_description_template.format(paragraph=paragraph, context_type=context_type, important_ents_str=important_ents_str, important_ents_0=important_ents[0], important_ents_1=important_ents[1])\n",
        "        prompt_shorten = prompt_shorten_template.format(paragraph)\n",
        "        # prompt_relation_description = prompt_relation_description_template.format(paragraph=paragraph, context_type=context_type, important_ents_str=important_ents_str)\n",
        "        \n",
        "        ent_description, shorten = llm([prompt_ent_description, prompt_shorten])\n",
        "        ent_description, shorten = ent_description[0], shorten[0]\n",
        "        description_dict = {}\n",
        "        for line in ent_description.splitlines():\n",
        "            if line:\n",
        "                ent, description = line.split(': ', 1)\n",
        "                ent = ent.strip()\n",
        "                description = description.strip()\n",
        "                if ent in important_ents:\n",
        "                    description_dict[ent] = description\n",
        "        test_results.append({\n",
        "            'paragraph': paragraph, \n",
        "            'important_ents': important_ents, \n",
        "            'description_dict': description_dict, \n",
        "            'shorten': shorten, \n",
        "            # 'relation_description': relation_description,\n",
        "            'prompt_ent_description': prompt_ent_description,\n",
        "            'prompt_shorten': prompt_shorten,\n",
        "            # 'prompt_relation_description': prompt_relation_description\n",
        "        })\n",
        "        \n",
        "        if len(results):\n",
        "            recaps = []\n",
        "            for rid, result in enumerate(results[-recap_num:]):\n",
        "                prev_description_dict:Dict[str, str] = result['description_dict']\n",
        "                match_dict = match_entities(important_ents, list(prev_description_dict.keys()))\n",
        "                prev_description = '\\n'.join([f'{ent}: {remove_citation(prev_description_dict[ent])}' for _, ent in match_dict.items()])\n",
        "                recap = f'Passage {rid - recap_num}:\\nEntity descriptions:\\n{prev_description}\\nSummary:\\n{result[\"shorten\"]}'\n",
        "                recaps.append(recap)\n",
        "            recap_str = '\\n\\n'.join(recaps)\n",
        "            prompt_ent_description = prompt_ent_description_w_note_template.format(recap=recap_str, paragraph=paragraph, context_type=context_type, important_ents_str=important_ents_str, important_ents_0=important_ents[0], important_ents_1=important_ents[1])\n",
        "            prompt_shorten = prompt_shorten_w_note_template.format(recap_str, paragraph)\n",
        "            # prompt_relation_description = prompt_relation_description_w_note_template.format(recap=recap_str, paragraph=paragraph, context_type=context_type, important_ents_str=important_ents_str)\n",
        "            \n",
        "            ent_description, shorten = llm([prompt_ent_description, prompt_shorten])\n",
        "            ent_description, shorten = ent_description[0], shorten[0]\n",
        "            description_dict = {}\n",
        "            for line in ent_description.splitlines():\n",
        "                if ': ' in line:\n",
        "                    ent, description = line.split(': ', 1)\n",
        "                    ent = ent.strip()\n",
        "                    description = description.strip()\n",
        "                    if ent in important_ents:\n",
        "                        description_dict[ent] = description\n",
        "        \n",
        "            results.append({\n",
        "                'paragraph': paragraph, \n",
        "                'important_ents': important_ents, \n",
        "                'description_dict': description_dict, \n",
        "                'shorten': shorten, \n",
        "                # 'relation_description': relation_description,\n",
        "                'prompt_ent_description': prompt_ent_description,\n",
        "                'prompt_shorten': prompt_shorten,\n",
        "                # 'prompt_relation_description': prompt_relation_description\n",
        "            })\n",
        "        else:\n",
        "            results.append({\n",
        "                'paragraph': paragraph, \n",
        "                'important_ents': important_ents, \n",
        "                'description_dict': description_dict, \n",
        "                'shorten': shorten, \n",
        "                # 'relation_description': relation_description,\n",
        "                'prompt_ent_description': prompt_ent_description,\n",
        "                'prompt_shorten': prompt_shorten,\n",
        "                # 'prompt_relation_description': prompt_relation_description\n",
        "            })\n",
        "    return test_results, results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "paragraphs = ['\\n'.join(p) for p in read_json(os.path.join(dataset.data_dir, f'pages_{1}.json'))]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_results, results = index_text(paragraphs, 3)\n",
        "write_json('results3.json', results)\n",
        "write_json('test_results3.json', test_results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Analyze results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "results = dataset.load_and_eval_result(0, 10, {'gist': 'wo_c_', 'dpr': 'wo_c_'})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "examples = []\n",
        "for i in range(len(results['gist'])):\n",
        "    # if not results['dpr'][i]['acc'] and results['gist'][i]['acc']:\n",
        "    #     examples.append({'index': results['index'][i], 'gist': results['gist'][i], 'dpr': results['dpr'][i], 'i': i})\n",
        "        examples.append({'gist': results['gist'][i], 'dpr': results['dpr'][i], 'i': i})\n",
        "print(len(examples))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "examples[0]['gist'].keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "eid = 6\n",
        "paragraphs = ['\\n'.join(page) for page in read_json(os.path.join(dataset.data_dir, f\"pages_{examples[eid]['gist']['task_i']}.json\"))]\n",
        "print(f'''\n",
        "Task id: {examples[eid]['gist']['task_i']}\n",
        "Question id: {examples[eid]['gist']['q_i']}\n",
        "\n",
        "Question: {examples[eid]['gist']['query']}\n",
        "\n",
        "Gold answer: {examples[eid]['gist']['gold']}\n",
        "\n",
        "\n",
        "DPR result:\n",
        "\n",
        "{examples[eid]['dpr']['predict']}\n",
        "\n",
        "{examples[eid]['dpr']['acc']}\n",
        "\n",
        "{examples[eid]['dpr']['generation']}\n",
        "\n",
        "\n",
        "\n",
        "GIST result:\n",
        "\n",
        "{examples[eid]['gist']['predict']}\n",
        "\n",
        "{examples[eid]['gist']['acc']}\n",
        "\n",
        "{examples[eid]['gist']['generation']}\n",
        "''')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "examples[eid]['gist']['steps']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(examples[eid]['gist']['steps'][0][1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "examples[eid]['dpr']['steps']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "len(paragraphs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(paragraphs[11])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for pid, p in enumerate(paragraphs):\n",
        "    if 'gold' in p.lower():\n",
        "        print(f'Passage {pid}:\\n' + p)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "longdoc = LongDoc(dataset, llm=llm, device='cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "longdoc.index_text(paragraphs[14:15])"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
