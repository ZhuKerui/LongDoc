{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieval observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel, AutoModelForSeq2SeqLM\n",
    "from typing import List, Tuple\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "from nltk import sent_tokenize\n",
    "from openai import OpenAI\n",
    "import networkx as nx\n",
    "from collections import defaultdict, Counter\n",
    "import itertools\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import pickle\n",
    "from rouge_metric import PyRouge\n",
    "import spacy\n",
    "import numpy as np\n",
    "import fastcoref.spacy_component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = [\n",
    "    \"narrativeqa\", \n",
    "    # \"qasper\", \n",
    "    # \"multifieldqa_en\", \n",
    "    # \"multifieldqa_zh\", \n",
    "    # \"hotpotqa\", \n",
    "    # \"2wikimqa\", \n",
    "    # \"musique\", \n",
    "    # \"dureader\", \n",
    "    # \"gov_report\", \n",
    "    # \"qmsum\", \n",
    "    # \"multi_news\", \n",
    "    # \"vcsum\", \n",
    "    # \"trec\", \n",
    "    # \"triviaqa\", \n",
    "    # \"samsum\", \n",
    "    # \"lsht\", \n",
    "    # \"passage_count\", \n",
    "    # \"passage_retrieval_en\", \n",
    "    # \"passage_retrieval_zh\", \n",
    "    # \"lcc\", \n",
    "    # \"repobench-p\"\n",
    "]\n",
    "task_name = datasets[0]\n",
    "\n",
    "dataset_dict = {task_name: load_dataset('THUDM/LongBench', task_name, split='test')}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_trec(text:str):\n",
    "    lines = text.splitlines()\n",
    "    return ['\\n'.join(lines[i * 2 : i * 2 + 1]) for i in range(len(lines) // 2)]\n",
    "\n",
    "def split_triviaqa(text:str):\n",
    "    lines = text.splitlines()\n",
    "    paragraphs = []\n",
    "    paragraph = []\n",
    "    lid = 0\n",
    "    while lid < len(lines):\n",
    "        paragraph.append(lines[lid])\n",
    "        if lines[lid] == 'Answer:':\n",
    "            lid += 1\n",
    "            paragraph.append(lines[lid])\n",
    "            paragraphs.append('\\n'.join(paragraph))\n",
    "            paragraph.clear()\n",
    "        lid += 1\n",
    "    return paragraphs\n",
    "\n",
    "def split_samsum(text:str):\n",
    "    paragraphs = []\n",
    "    paragraph = []\n",
    "    for line in text.splitlines():\n",
    "        paragraph.append(line)\n",
    "        if line.startswith('Summary: '):\n",
    "            paragraphs.append('\\n'.join(paragraph))\n",
    "            paragraph.clear()\n",
    "    return paragraphs\n",
    "\n",
    "class LongDoc:\n",
    "    paragraph_sep_map = {\n",
    "        'qasper': '\\n', \n",
    "        'multifieldqa_zh': '\\n', \n",
    "        'qmsum': '\\n', \n",
    "        'multi_news': '\\n', \n",
    "        'vcsum': '\\n', \n",
    "        'trec': (split_trec, '\\n'), \n",
    "        'triviaqa': (split_triviaqa, '\\n'), \n",
    "        'samsum': (split_samsum, '\\n'), \n",
    "    }\n",
    "    \n",
    "    def __init__(self, retriever_model_name:str='facebook/contriever', llm_name:str='meta-llama/Llama-2-7b-hf') -> None:\n",
    "        self.device = torch.device('cuda:0')\n",
    "        self.llm_tokenizer = AutoTokenizer.from_pretrained(llm_name)\n",
    "        # self.nlp = spacy.load('en_core_web_lg')#, disable=['attribute_ruler', 'lemmatizer', 'ner'])\n",
    "        # self.nlp.add_pipe('coreferee')\n",
    "        # self.nlp = spacy.load(\"en_core_web_lg\")\n",
    "        # self.nlp.add_pipe(\"fastcoref\", \n",
    "        #      config={'model_architecture': 'LingMessCoref', 'model_path': 'biu-nlp/lingmess-coref', 'device': 'cuda:1', 'enable_progress_bar': False}\n",
    "        # )\n",
    "        self.retriever_tokenizer = AutoTokenizer.from_pretrained(retriever_model_name)\n",
    "        self.retriever_model = AutoModel.from_pretrained(retriever_model_name)\n",
    "        self.retriever_model.cuda(device=self.device)\n",
    "        \n",
    "    def get_task_paragraph_sep(self, task_name:str):\n",
    "        sep = self.paragraph_sep_map.get(task_name, '\\n\\n')\n",
    "        if not isinstance(sep, str):\n",
    "            func, sep = sep\n",
    "        return sep\n",
    "    \n",
    "    def split_context_to_paragraphs(self, context:str, task_name:str):\n",
    "        sep = self.paragraph_sep_map.get(task_name, '\\n\\n')\n",
    "        if isinstance(sep, str):\n",
    "            return context.split(sep)\n",
    "        else:\n",
    "            func, sep = self.paragraph_sep_map[task_name]\n",
    "            return func(context)\n",
    "    \n",
    "    # Mean pooling\n",
    "    @staticmethod\n",
    "    def _mean_pooling(token_embeddings:torch.Tensor, mask):\n",
    "        token_embeddings = token_embeddings.masked_fill(~mask[..., None].bool(), 0.)\n",
    "        sentence_embeddings:torch.Tensor  = token_embeddings.sum(dim=1) / mask.sum(dim=1)[..., None]\n",
    "        return sentence_embeddings\n",
    "\n",
    "    def _append_paragraph(self, paragraphs:list, tokenized_p:List[str]):\n",
    "        paragraph = self.llm_tokenizer.decode(tokenized_p)\n",
    "        paragraphs.append(paragraph)\n",
    "        tokenized_p.clear()\n",
    "    \n",
    "    def split_single_paragraph(self, text:str, paragraph_size:int=300, is_natural_language:bool=True):\n",
    "        splited_paragraphs:List[str] = []\n",
    "        splited_paragraph = []\n",
    "        sentences:List[str] = sent_tokenize(text) if is_natural_language else text.split('\\n')\n",
    "        for sent in sentences:\n",
    "            tokenized_s = self.llm_tokenizer.encode(sent)[1:]\n",
    "            if len(tokenized_s) <= paragraph_size:\n",
    "                if len(splited_paragraph) + len(tokenized_s) > paragraph_size:\n",
    "                    self._append_paragraph(splited_paragraphs, splited_paragraph)\n",
    "                splited_paragraph.extend(tokenized_s)\n",
    "            else:\n",
    "                if splited_paragraph:\n",
    "                    self._append_paragraph(splited_paragraphs, splited_paragraph)\n",
    "                chunk_size = (len(tokenized_s) - 1) // paragraph_size + 1\n",
    "                for i in range(chunk_size - 1):\n",
    "                    self._append_paragraph(splited_paragraphs, tokenized_s[i * paragraph_size: (i+1) * paragraph_size])\n",
    "                splited_paragraph = tokenized_s[(chunk_size - 1) * paragraph_size:]\n",
    "        \n",
    "        return splited_paragraphs, splited_paragraph\n",
    "            \n",
    "        \n",
    "    def split_paragraphs(self, text:str, task_name:str, paragraph_size:int=300):\n",
    "        reformated_paragraphs:List[str] = []\n",
    "        completion_labels:List[bool] = []\n",
    "        reformated_paragraph = []\n",
    "        \n",
    "        paragraph_sep = self.get_task_paragraph_sep(task_name)\n",
    "        paragraphs = text.split(paragraph_sep)\n",
    "        for p in paragraphs:\n",
    "            tokenized_p = self.llm_tokenizer.encode(p + paragraph_sep)[1:]\n",
    "            if len(tokenized_p) <= paragraph_size:\n",
    "                if len(reformated_paragraph) + len(tokenized_p) > paragraph_size:\n",
    "                    self._append_paragraph(reformated_paragraphs, reformated_paragraph)\n",
    "                    completion_labels.append(True)\n",
    "                reformated_paragraph.extend(tokenized_p)\n",
    "            else:\n",
    "                if reformated_paragraph:\n",
    "                    self._append_paragraph(reformated_paragraphs, reformated_paragraph)\n",
    "                    completion_labels.append(True)\n",
    "                splited_paragraphs, splited_paragraph = self.split_single_paragraph(p, paragraph_size)\n",
    "                reformated_paragraphs.extend(splited_paragraphs)\n",
    "                completion_labels.extend([False] * len(splited_paragraphs))\n",
    "                reformated_paragraph = splited_paragraph\n",
    "                \n",
    "        if reformated_paragraph:\n",
    "            self._append_paragraph(reformated_paragraphs, reformated_paragraph)\n",
    "            completion_labels.append(True)\n",
    "        \n",
    "        return reformated_paragraphs, completion_labels\n",
    "    \n",
    "    def embed_paragraphs(self, paragraphs:List[str]):\n",
    "        retriever_input = self.retriever_tokenizer.batch_encode_plus(paragraphs, padding=True, truncation=True, return_tensors='pt').to(self.device)\n",
    "        with torch.no_grad():\n",
    "            retriever_output = self.retriever_model(**retriever_input)\n",
    "            paragraph_embeddings= self._mean_pooling(retriever_output[0], retriever_input['attention_mask'])\n",
    "        return paragraph_embeddings\n",
    "    \n",
    "    def retrieve_paragraphs(self, question:str, paragraphs:List[str], paragraph_embeddings:torch.Tensor, k:int=5, order_by_rank:bool=True):\n",
    "        question_embeddings = self.embed_paragraphs([question])\n",
    "        with torch.no_grad():\n",
    "            ranks = torch.matmul(paragraph_embeddings, question_embeddings.T).squeeze()\n",
    "            indices = torch.topk(ranks, k).indices.tolist()\n",
    "            if not order_by_rank:\n",
    "                indices.sort()\n",
    "        return [paragraphs[idx] for idx in indices], indices\n",
    "    \n",
    "    def parse_to_graph(self, response:str):\n",
    "        start_ents = False\n",
    "        start_summary = False\n",
    "        summary:List[str] = []\n",
    "        line:str\n",
    "        temp_graph = nx.DiGraph()\n",
    "        for line in response.splitlines():\n",
    "            if line.strip().startswith('Important ent'):\n",
    "                start_ents = True\n",
    "            elif line.strip().startswith('Entity summary'):\n",
    "                start_summary = True\n",
    "            else:\n",
    "                if start_summary and line and ':' in line:\n",
    "                    summary.append(line.strip('*+ '))\n",
    "\n",
    "        summary = [sum.split('. ', 1)[1] if sum.startswith(f'{sid+1}.') else sum for sid, sum in enumerate(summary)]\n",
    "        for sum in summary:\n",
    "            ent, rel = sum.split(':', 1)\n",
    "            temp_graph.add_node(ent.strip())\n",
    "\n",
    "        for sid, sum in enumerate(summary):\n",
    "            ent, rel = sum.split(':', 1)\n",
    "            rel = rel.lower()\n",
    "            ent = ent.strip()\n",
    "            for other_ent in temp_graph.nodes:\n",
    "                other_ent_mention = other_ent\n",
    "                if '(' in other_ent_mention:\n",
    "                    other_ent_mention = other_ent_mention.split('(')[0].strip()\n",
    "                if ',' in other_ent_mention:\n",
    "                    other_ent_mention = other_ent_mention.split(',')[0].strip()\n",
    "                if other_ent != ent and other_ent_mention.lower() in rel:\n",
    "                    if not temp_graph.has_edge(ent, other_ent):\n",
    "                        temp_graph.add_edge(ent, other_ent, sum=[])\n",
    "                    temp_graph.get_edge_data(ent, other_ent)['sum'].append(sid)\n",
    "        return temp_graph, summary\n",
    "    \n",
    "    def retrieve_node(self, all_graph:nx.DiGraph, targets:List[str], k:int=5):\n",
    "        nodes = list(all_graph.nodes)\n",
    "        nodes.sort()\n",
    "        ret:List[List[str]] = []\n",
    "        node_embeds = self.embed_paragraphs(nodes).cpu().numpy()\n",
    "        for target in targets:\n",
    "            ent_embed = self.embed_paragraphs([target]).cpu().numpy()\n",
    "            scores = node_embeds.dot(ent_embed.squeeze())\n",
    "            # scores = np.array([cal_rouge(node, target)['rouge-l']['f'] for node in nodes])\n",
    "            max_indices = np.argsort(scores)[::-1][:k]\n",
    "            # max_indices = max_indices[scores[max_indices] > 0]\n",
    "            ret.append([nodes[i] for i in max_indices])\n",
    "        return ret\n",
    "    \n",
    "    # def retrieve_paragraphs(self, task_name:str, question:str, paragraphs:List[str], completion_labels:List[bool], paragraph_embeddings:torch.Tensor, k:int=5, order_by_rank:bool=True):\n",
    "    #     question_input = self.retriever_tokenizer.batch_encode_plus([question], truncation=True, return_tensors='pt').to(self.device)\n",
    "    #     with torch.no_grad():\n",
    "    #         question_output = self.retriever_model(**question_input)\n",
    "    #         question_embeddings = self._mean_pooling(question_output[0], question_input['attention_mask'])\n",
    "    #         ranks = torch.matmul(paragraph_embeddings, question_embeddings.T).squeeze()\n",
    "    #         indices = torch.topk(ranks, k).indices.tolist()\n",
    "    #         if not order_by_rank:\n",
    "    #             indices.sort()\n",
    "    #         paragraph_sep = self.get_task_paragraph_sep(task_name)\n",
    "    #         retrieved_text = ''\n",
    "    #         for i, idx in enumerate(indices):\n",
    "    #             retrieved_text += paragraphs[idx]\n",
    "    #             if idx == len(indices) - 1:\n",
    "    #                 break\n",
    "    #             if not completion_labels[idx]:\n",
    "    #                 if indices[i+1] == idx + 1:\n",
    "    #                     retrieved_text += ' '\n",
    "    #                 else:\n",
    "    #                     retrieved_text += paragraph_sep\n",
    "    #     return retrieved_text, indices\n",
    "    \n",
    "    # def index_paragraph(self, paragraph:str):\n",
    "    #     doc = self.nlp(paragraph)\n",
    "    #     g = nx.DiGraph()\n",
    "    #     for i in range(len(doc)):\n",
    "    #         for child in doc[i].children:\n",
    "    #             g.add_edge(i, child.i, type=child.dep_)\n",
    "    #     ug = g.to_undirected()\n",
    "    #     doc_ncs = list(doc.noun_chunks) + list(doc.ents)\n",
    "    #     root_id_to_nc = {nc.root.i: nc for nc in doc_ncs}\n",
    "    #     results = []\n",
    "    #     sents = list(doc.sents)\n",
    "    #     s_start2sid = {sent.start: sid for sid, sent in enumerate(sents)}\n",
    "    #     for sid, sent in enumerate(sents):\n",
    "    #         if not sent.text.strip():\n",
    "    #             continue\n",
    "    #         sent_ncs = list(sent.noun_chunks)\n",
    "    #         for pair in combinations(sent_ncs, 2):\n",
    "    #             if sum([pair[0].root.dep_.startswith('nsubj'), pair[1].root.dep_.startswith('nsubj')]) != 1:\n",
    "    #                 continue\n",
    "    #             paths:List[List[int]] = nx.simple_paths.shortest_simple_paths(ug, pair[0].root.i, pair[1].root.i) if pair[0].root.dep_.startswith('nsubj') else nx.simple_paths.shortest_simple_paths(ug, pair[1].root.i, pair[0].root.i)\n",
    "    #             for path in paths:\n",
    "    #                 results.append((path[0], sid, path[-1]))\n",
    "        \n",
    "    #     appos_to_ref = defaultdict(set)\n",
    "        \n",
    "    #     for head, tail, dep in g.edges.data('type'):\n",
    "    #         if dep == 'appos' and doc[tail].pos_ in ['NOUN', 'PROPN', 'NUM']:\n",
    "    #             # if head in root_id_to_nc and tail in root_id_to_nc:\n",
    "    #             appos_to_ref[head].add(tail)\n",
    "        \n",
    "    #     head2sids = defaultdict(set)\n",
    "    #     tail2sids = defaultdict(set)\n",
    "    #     nc2sids = defaultdict(set)\n",
    "    #     for head, sid, tail in results:\n",
    "    #         pair_ref = []\n",
    "    #         for node, node2sids in [(head, head2sids), (tail, tail2sids)]:\n",
    "    #             if doc[node].pos_ == 'PRON':\n",
    "    #                 refs = doc._.coref_chains.resolve(doc[node])\n",
    "    #                 if refs is not None:\n",
    "    #                     for ref in refs:\n",
    "    #                         if ref.i not in root_id_to_nc:\n",
    "    #                             root_id_to_nc[ref.i] = doc[ref.i : ref.i + 1]\n",
    "    #                     nodes = [ref.i for ref in refs]\n",
    "    #                 else:\n",
    "    #                     nodes = [node]\n",
    "    #             elif head in appos_to_ref:\n",
    "    #                 nodes = list(appos_to_ref[node]) + [node]\n",
    "    #             else:\n",
    "    #                 nodes = [node]\n",
    "    #             pair_ref.append(nodes)\n",
    "    #             for n in nodes:\n",
    "    #                 nc = root_id_to_nc[n].text\n",
    "    #                 nc_sid = s_start2sid[doc[n].sent.start]\n",
    "    #                 if nc_sid != sid:\n",
    "    #                     node2sids[nc].add((nc_sid, sid))\n",
    "    #                     nc2sids[nc].add((nc_sid, sid))\n",
    "    #                 else:\n",
    "    #                     node2sids[nc].add(sid)\n",
    "    #                     nc2sids[nc].add(sid)\n",
    "    #         # heads, tails = pair_ref\n",
    "            \n",
    "    #         # for h, t in product(heads, tails):\n",
    "    #         #     index_graph.append((root_id_to_nc[h].text, sid, root_id_to_nc[t].text))\n",
    "\n",
    "    #     # return index_graph\n",
    "    #     return nc2sids, head2sids, tail2sids, sents\n",
    "                \n",
    "longdoc = LongDoc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_rouge(hp, ref):\n",
    "    return PyRouge().evaluate([hp], [[ref]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LLM inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_name = 'narrativeqa'\n",
    "test_i = 2\n",
    "paragraphs, completion_labels = longdoc.split_paragraphs(dataset_dict[task_name][test_i]['context'], task_name, 400)\n",
    "# retrieved_text, indices = longdoc.retrieve_paragraphs(task_name, dataset_dict['narrativeqa'][0]['input'], paragraphs, completion_labels, embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coreference Resolution (Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "02/28/2024 06:23:15 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a553ccc428d0473d99202889f67dea20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "02/28/2024 06:23:18 - INFO - \t ***** Running Inference on 1 texts *****\n",
      " 33%|███▎      | 1/3 [00:03<00:07,  3.82s/it]02/28/2024 06:23:19 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ba01e3afecf43d29559f25c0c1e936a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "02/28/2024 06:23:22 - INFO - \t ***** Running Inference on 1 texts *****\n",
      " 67%|██████▋   | 2/3 [00:08<00:04,  4.16s/it]02/28/2024 06:23:23 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9dfffdfad31b408caba18a749b1708ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "02/28/2024 06:23:26 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "100%|██████████| 3/3 [00:12<00:00,  4.12s/it]\n"
     ]
    }
   ],
   "source": [
    "coref_batch = 4\n",
    "coref_resolver:fastcoref.spacy_component.FastCorefResolver = longdoc.nlp.get_pipe('fastcoref')\n",
    "coref_resolved_paragraphs = []\n",
    "for bid in tqdm(range((len(paragraphs[:10]) - 1) // coref_batch + 1)):\n",
    "    if bid == 0:\n",
    "        frozen_paragraphs = []\n",
    "        update_paragraphs = paragraphs[:coref_batch]\n",
    "    else:\n",
    "        frozen_paragraphs = coref_resolved_paragraphs[-1:]\n",
    "        update_paragraphs = paragraphs[bid * coref_batch : (bid + 1) * coref_batch]\n",
    "    \n",
    "    batch_paragraphs = frozen_paragraphs + update_paragraphs\n",
    "    doc = longdoc.nlp(''.join(batch_paragraphs))\n",
    "    prev_char_num = 0\n",
    "    paragraph_char_seps = []\n",
    "    for paragraph in batch_paragraphs:\n",
    "        paragraph_char_seps.append((prev_char_num, prev_char_num + len(paragraph)))\n",
    "        prev_char_num = paragraph_char_seps[-1][1]\n",
    "    \n",
    "    clusters:List[List[Tuple[int, int]]] = doc._.coref_clusters\n",
    "    \n",
    "    # Normalize the referred entities\n",
    "    idx2nc = {nc.root.i: nc for nc in doc.ents if '\\n\\n' not in nc.text}\n",
    "    new_clusters = []\n",
    "    for cluster in clusters:\n",
    "        indices = coref_resolver._get_span_noun_indices(doc, cluster)\n",
    "        if indices:\n",
    "            new_cluster = []\n",
    "            for sid, span in enumerate(cluster):\n",
    "                if sid in indices:\n",
    "                    doc_span = doc.char_span(span[0], span[1])\n",
    "                    if ',' in doc_span.text:\n",
    "                        root_i = doc_span.root.i\n",
    "                        if root_i in idx2nc:\n",
    "                            new_cluster.append((idx2nc[root_i].start_char, idx2nc[root_i].end_char))\n",
    "                        continue\n",
    "                new_cluster.append(span)\n",
    "            new_clusters.append(new_cluster)\n",
    "    clusters = new_clusters\n",
    "    \n",
    "    # Resolve part of prons\n",
    "    resolved = list(tok.text_with_ws for tok in doc)\n",
    "    all_spans = [span for cluster in clusters for span in cluster]\n",
    "    for cluster in clusters:\n",
    "        indices = coref_resolver._get_span_noun_indices(doc, cluster)\n",
    "        if indices and doc.char_span(cluster[indices[0]][0], cluster[indices[0]][1]).root.i in idx2nc:\n",
    "            mention_span, mention = coref_resolver._get_cluster_head(doc, cluster, indices)\n",
    "            marked = ([True] * len(frozen_paragraphs)) + ([False] * len(update_paragraphs))\n",
    "            pid = 0\n",
    "            for pid, (p_start, p_end) in enumerate(paragraph_char_seps):\n",
    "                if mention[0] >= p_start and mention[0] < p_end:\n",
    "                    marked[pid] = True\n",
    "                    break\n",
    "            for coref in cluster:\n",
    "                if coref != mention and not coref_resolver._is_containing_other_spans(coref, all_spans):\n",
    "                    while pid < len(marked) and marked[pid]:\n",
    "                        pid += 1\n",
    "                    if pid == len(marked):\n",
    "                        break\n",
    "                    if coref[0] >= paragraph_char_seps[pid][0] and coref[0] < paragraph_char_seps[pid][1]:\n",
    "                        marked[pid] = True\n",
    "                        coref_resolver._core_logic_part(doc, coref, resolved, mention_span)\n",
    "    coref_resolved_paragraphs.append(\"\".join(resolved)[sum([len(p) for p in frozen_paragraphs]):])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E-text prepared by Jonathan Ingram, Janet Blenkinship, and the Project\n",
      "Gutenberg Online Distributed Proofreading Team (https://www.pgdp.net/)\n",
      "\n",
      " \n",
      "\n",
      " Transcriber's note: The author is Mary Wollstonecraft (1759-1797).\n",
      "\n",
      " \n",
      "\n",
      " \n",
      "\n",
      " MARY,\n",
      "\n",
      " A Fiction\n",
      "\n",
      " L'exercice des plus sublimes vertus éleve et nourrit le génie.\n",
      "                                                     ROUSSEAU.\n",
      "\n",
      " London,\n",
      "Printed for J. Johnson, St. Paul's Church-Yard.\n",
      "\n",
      " MDCCLXXXVIII\n",
      "\n",
      " \n",
      "\n",
      " \n",
      "\n",
      " \n",
      "\n",
      " ADVERTISEMENT.\n",
      "\n",
      " \n",
      "In delineating the Heroine of this Fiction, the Author attempts to\n",
      "develop a character different from those generally portrayed. This woman\n",
      "is neither a Clarissa, a Lady G----, nor a[A] Sophie.--It would be vain\n",
      "to mention the various modifications of these models, as it would to\n",
      "remark, how widely artists wander from nature, when they copy the\n",
      "originals of great masters. They catch the gross parts; but the subtile\n",
      "spirit evaporates; and not having the just ties, affectation disgusts,\n",
      "when grace was expected to charm.\n",
      "\n",
      " Those compositions only have power to delight, and carry us willing\n",
      "captives, where the soul of the author is exhibited, and animates the\n",
      "hidden springs. Lost in a pleasing enthusiasm, they live in the scenes\n",
      "they represent; and do not measure their steps in a beaten track,\n",
      "solicitous to gather expected flowers, and bind them in a wreath,\n",
      "according to the prescribed rules of art.\n",
      "\n",
      " These chosen few, wish to speak for themselves, and not to be an\n",
      "echo--even of the sweetest sounds--or the reflector of the most sublime\n",
      "beams. The[B] paradise they ramble in, must be of their own creating--or\n",
      "the prospect soon grows insipid, and not varied by a vivifying\n",
      "principle, fades and dies.\n",
      "\n",
      "In an artless tale, without episodes, the mind of a woman, who has\n",
      "thinking powers is displayed. The female organs have been thought too\n",
      "weak for this arduous employment; and experience seems to justify the\n",
      "assertion. Without arguing physically about _possibilities_--in a\n",
      "fiction, such a being may be allowed to exist; whose grandeur is derived\n",
      "from the operations of its own faculties, not subjugated to opinion; but\n",
      "drawn by the individual from the original source.\n",
      "\n",
      " FOOTNOTES:\n",
      "\n",
      " [Footnote A: Rousseau.]\n",
      "\n",
      " [Footnote B: I here give the Reviewers an opportunity of being very\n",
      "witty about the Paradise of Fools, &c.]\n",
      "\n",
      " \n",
      "\n",
      " \n",
      "MARY\n",
      "\n",
      " \n",
      "\n",
      " \n",
      "CHAP. I.\n",
      "\n",
      " \n",
      "Mary, the heroine of this fiction, was the daughter of Edward, who\n",
      "married Eliza, a gentle, fashionable girl, with a kind of indolence in\n",
      "her temper, which might be termed negative good-nature: her virtues,\n",
      "indeed, were all of that stamp. She carefully attended to the _shews_ of\n",
      "things, and her opinions, I should have said prejudices, were such as\n",
      "the generality approved of. She was educated with the expectation of a\n",
      "large fortune, of course became a mere machine: the homage of her\n",
      "attendants made a great part of her puerile amusements, and she never\n",
      "imagined there were any relative duties for her to fulfil: notions of\n",
      "her own consequence, by these means, were interwoven in her mind, and\n",
      "the years of youth spent in acquiring a few superficial accomplishments,\n",
      "without having any taste for them. When she was first introduced into\n",
      "the polite circle, she danced with an officer, whom she faintly wished\n",
      "to be united to; but her father soon after recommending another in a\n",
      "more distinguished rank of life, she readily submitted to his will, and\n",
      "promised to love, honour, and obey, (a vicious fool,) as in duty bound.\n",
      "\n",
      "While they resided in London, they lived in the usual fashionable style,\n",
      "and seldom saw each other; nor were they much more sociable when they\n",
      "wooed rural felicity for more than half the year, in a delightful\n",
      "country, where Nature, with lavish hand, had scattered beauties around;\n",
      "for the master, with brute, unconscious gaze, passed them by unobserved,\n",
      "and sought amusement in country sports. He hunted in the morning, and\n",
      "after eating an immoderate dinner, generally fell asleep: this\n",
      "seasonable rest enabled him to digest the cumbrous load; he would then\n",
      "visit some of his pretty tenants; and when he compared their ruddy glow\n",
      "of health with his wife's countenance, which even rouge could not\n",
      "enliven, it is not necessary to say which a _gourmand_ would give the\n",
      "preference to. Their vulgar dance of spirits were infinitely more\n",
      "agreeable to his fancy than her sickly, die-away languor. Her voice was\n",
      "but the shadow of a sound, and she had, to complete her delicacy, so\n",
      "relaxed her nerves, that she became a mere nothing.\n",
      "\n",
      " Many such noughts are there in the female world! yet she had a good\n",
      "opinion of her own merit,--truly, she said long prayers,--and sometimes\n",
      "read her Week's Preparation: she dreaded that horrid place vulgarly\n",
      "called _hell_, the regions below; but whether Mary's was a mounting\n",
      "spirit, I cannot pretend to determine; or what sort of a planet would\n",
      "have been proper for her, when she left her _material_ part in this\n",
      "world, let metaphysicians settle; I have nothing to say to her unclothed\n",
      "spirit.\n",
      "\n",
      "As she was sometimes obliged to be alone, or only with her French\n",
      "waiting-maid, she sent to the metropolis for all the new publications,\n",
      "and while she was dressing her hair, and she could turn her eyes from\n",
      "the glass, she ran over those most delightful substitutes for bodily\n",
      "dissipation, novels. I say bodily, or the animal soul, for a rational\n",
      "one can find no employment in polite circles. The glare of lights, the\n",
      "studied inelegancies of dress, and the compliments offered up at the\n",
      "shrine of false beauty, are all equally addressed to the senses.\n",
      "\n",
      " When she could not any longer indulge the caprices of fancy one way, she\n",
      "tried another. The Platonic Marriage, Eliza Warwick, and some other\n",
      "interesting tales were perused with eagerness. Nothing could be more\n",
      "natural than the developement of the passions, nor more striking than\n",
      "the views of the human heart. What delicate struggles! and uncommonly\n",
      "pretty turns of thought! The picture that was found on a bramble-bush,\n",
      "the new sensitive-plant, or tree, which caught the swain by the\n",
      "upper-garment, and presented to his ravished eyes a portrait.--Fatal\n",
      "image!--It planted a thorn in a till then insensible heart, and sent a\n",
      "new kind of a knight-errant into the world. But even this was nothing to\n",
      "the catastrophe, and the circumstance on which it hung, the hornet\n",
      "settling on the sleeping lover's face. What a _heart-rending_ accident!\n",
      "She planted, in imitation of those susceptible souls, a rose bush; but\n",
      "there was not a lover to weep in concert with her, when she watered it\n",
      "with her tears.--Alas! Alas!\n",
      "\n",
      "If my readers would excuse the sportiveness of fancy, and give me credit\n",
      "for genius, I would go on and tell them such tales as would force the\n",
      "sweet tears of sensibility to flow in copious showers down beautiful\n",
      "cheeks, to the discomposure of rouge, &c. &c. Nay, I would make it so\n",
      "interesting, that the fair peruser should beg the hair-dresser to\n",
      "settle the curls himself, and not interrupt her.\n",
      "\n",
      " the Heroine of this Fiction had besides another resource, two most beautiful dogs, who shared\n",
      "her bed, and reclined on cushions near her all the day. These she\n",
      "watched with the most assiduous care, and bestowed on them the warmest\n",
      "caresses. This fondness for animals was not that kind of\n",
      "_attendrissement_ which makes a person take pleasure in providing for\n",
      "the subsistence and comfort of a living creature; but it proceeded from\n",
      "vanity, it gave her an opportunity of lisping out the prettiest French\n",
      "expressions of ecstatic fondness, in accents that had never been attuned\n",
      "by tenderness.\n",
      "\n",
      " She was chaste, according to the vulgar acceptation of the word, that\n",
      "is, she did not make any actual _faux pas_; she feared the world, and\n",
      "was indolent; but then, to make amends for this seeming self-denial, she\n",
      "read all the sentimental novels, dwelt on the love-scenes, and, had she\n",
      "thought while she read, her mind would have been contaminated; as she\n",
      "accompanied the lovers to the lonely arbors, and would walk with them by\n",
      "the clear light of the moon. She wondered her husband did not stay at\n",
      "home. She was jealous--why did he not love her, sit by her side, squeeze\n",
      "her hand, and look unutterable things? Gentle reader, I will tell thee;\n",
      "they neither of them felt what they could not utter. I will not pretend\n",
      "to say that they always annexed an idea to a word; but they had none of\n",
      "those feelings which are not easily analyzed.\n",
      "\n",
      " \n",
      "\n",
      " \n",
      "CHAP. II.\n",
      "\n",
      "\n",
      "In due time the Heroine of this Fiction brought forth a son, a feeble babe; and the following\n",
      "year a daughter. After the mother's throes she felt very few sentiments\n",
      "of maternal tenderness: the children were given to nurses, and she\n",
      "played with her dogs. Want of exercise prevented the least chance of her\n",
      "recovering strength; and two or three milk-fevers brought on a\n",
      "consumption, to which her constitution tended. Her children all died in\n",
      "their infancy, except the two first, and she began to grow fond of the\n",
      "son, as he was remarkably handsome. For years she divided her time\n",
      "between the sofa, and the card-table. She thought not of death, though\n",
      "on the borders of the grave; nor did any of the duties of her station\n",
      "occur to her as necessary. Her children were left in the nursery; and\n",
      "when Mary, the little blushing girl, appeared, she would send the\n",
      "awkward thing away. To own the truth, she was awkward enough, in a house\n",
      "without any play-mates; for her brother had been sent to school, and she\n",
      "scarcely knew how to employ herself; she would ramble about the garden,\n",
      "admire the flowers, and play with the dogs. An old house-keeper told her\n",
      "stories, read to her, and, at last, taught her to read. Her mother\n",
      "talked of enquiring for a governess when her health would permit; and,\n",
      "in the interim desired her own maid to teach her French. As she had\n",
      "learned to read, she perused with avidity every book that came in her\n",
      "way. Neglected in every respect, and left to the operations of her own\n",
      "mind, she considered every thing that came under her inspection, and\n",
      "learned to think. She had heard of a separate state, and that angels\n",
      "sometimes visited this earth. She would sit in a thick wood in the park,\n",
      "and talk to them; make little songs addressed to them, and sing them to\n",
      "tunes of her own composing; and her native wood notes wild were sweet\n",
      "and touching.\n",
      "\n",
      "Her father always exclaimed against female acquirements, and was glad\n",
      "that his wife's indolence and ill health made the Heroine of this Fiction not trouble herself\n",
      "about them. She had besides another reason, she did not wish to have a\n",
      "fine tall girl brought forward into notice as her daughter; she still\n",
      "expected to recover, and figure away in the gay world. Her husband was\n",
      "very tyrannical and passionate; indeed so very easily irritated when\n",
      "inebriated, that Mary was continually in dread lest he should frighten\n",
      "her mother to death; her sickness called forth all Mary's tenderness,\n",
      "and exercised her compassion so continually, that it became more than a\n",
      "match for self-love, and was the governing propensity of her heart\n",
      "through life. She was violent in her temper; but she saw her father's\n",
      "faults, and would weep when obliged to compare his temper with her\n",
      "own.--She did more; artless prayers rose to Heaven for pardon, when she\n",
      "was conscious of having erred; and her contrition was so exceedingly\n",
      "painful, that she watched diligently the first movements of anger and\n",
      "impatience, to save herself this cruel remorse.\n",
      "\n",
      " Sublime ideas filled her young mind--always connected with devotional\n",
      "sentiments; extemporary effusions of gratitude, and rhapsodies of\n",
      "praise would burst often from her, when she listened to the birds, or\n",
      "pursued the deer. She would gaze on the moon, and ramble through the\n",
      "gloomy path, observing the various shapes the clouds assumed, and listen\n",
      "to the sea that was not far distant. The wandering spirits, which she\n",
      "imagined inhabited every part of nature, were her constant friends and\n",
      "confidants. She began to consider the Great First Cause, formed just\n",
      "notions of his attributes, and, in particular, dwelt on his wisdom and\n",
      "goodness. Could she have loved her father or mother, had they returned\n",
      "her affection, she would not so soon, perhaps, have sought out a new\n",
      "world.\n",
      "\n",
      "Her sensibility prompted her to search for an object to love; on earth\n",
      "it was not to be found: her mother had often disappointed her, and the\n",
      "apparent partiality she shewed to her brother gave her exquisite\n",
      "pain--produced a kind of habitual melancholy, led her into a fondness\n",
      "for reading tales of woe, and made her almost realize the fictitious\n",
      "distress.\n",
      "\n",
      " She had not any notion of death till a little chicken expired at her\n",
      "feet; and her father had a dog hung in a passion. She then concluded\n",
      "animals had souls, or they would not have been subjected to the caprice\n",
      "of man; but what was the soul of man or beast? In this style year after\n",
      "year rolled on, her mother still vegetating.\n",
      "\n",
      " A little girl who attended in the nursery fell sick. Mary paid her great\n",
      "attention; contrary to her wish, she was sent out of the house to her\n",
      "mother, a poor woman, whom necessity obliged to leave her sick child\n",
      "while she earned her daily bread. The poor wretch, in a fit of delirium\n",
      "stabbed herself, and Mary saw her dead body, and heard the dismal\n",
      "account; and so strongly did it impress her imagination, that every\n",
      "night of her life the bleeding corpse presented itself to her when the\n",
      "first began to slumber. Tortured by it, she at last made a vow, that if\n",
      "she was ever mistress of a family she would herself watch over every\n",
      "part of it. The impression that this accident made was indelible.\n",
      "\n",
      "As her mother grew imperceptibly worse and worse, her father, who did\n",
      "not understand such a lingering complaint, imagined his wife was only\n",
      "grown still more whimsical, and that if she could be prevailed on to\n",
      "exert herself, her health would soon be re-established. In general he\n",
      "treated her with indifference; but when her illness at all interfered\n",
      "with his pleasures, he expostulated in the most cruel manner, and\n",
      "visibly harassed the invalid. Mary would then assiduously try to turn\n",
      "his attention to something else; and when sent out of the room, would\n",
      "watch at the door, until the storm was over, for unless it was, she\n",
      "could not rest. Other causes also contributed to disturb her repose: her\n",
      "mother's luke-warm manner of performing her religious duties, filled her\n",
      "with anguish; and when she observed her father's vices, the unbidden\n",
      "tears would flow. She was miserable when beggars were driven from the\n",
      "gate without being relieved; if she could do it unperceived, she would\n",
      "give them her own breakfast, and feel gratified, when, in consequence of\n",
      "it, she was pinched by hunger.\n",
      "\n",
      " She had once, or twice, told her little secrets to her mother; they were\n",
      "laughed at, and she determined never to do it again. In this manner was\n",
      "she left to reflect on her own feelings; and so strengthened were they\n",
      "by being meditated on, that her character early became singular and\n",
      "permanent. Her understanding was strong and clear, when not clouded by\n",
      "her feelings; but she was too much the creature of impulse, and the\n",
      "slave of compassion.\n",
      "\n",
      " \n",
      "\n",
      " \n",
      "CHAP. III.\n",
      "\n",
      "\n",
      "Near her father's house lived a poor widow, who had been brought up in\n",
      "affluence, but reduced to great distress by the extravagance of her\n",
      "husband; he had destroyed his constitution while he spent his fortune;\n",
      "and dying, left his wife, and five small children, to live on a very\n",
      "scanty pittance. The eldest daughter was for some years educated by a\n",
      "distant relation, a Clergyman. While she was with him a young gentleman,\n",
      "son to a man of property in the neighbourhood, took particular notice of\n",
      "her. It is true, he never talked of love; but then they played and sung\n",
      "in concert; drew landscapes together, and while she worked he read to\n",
      "her, cultivated her taste, and stole imperceptibly her heart. Just at\n",
      "this juncture, when smiling, unanalyzed hope made every prospect bright,\n",
      "and gay expectation danced in her eyes, her benefactor died. She\n",
      "returned to her mother--the companion of her youth forgot her, they took\n",
      "no more sweet counsel together. This disappointment spread a sadness\n",
      "over her countenance, and made it interesting. She grew fond of\n",
      "solitude, and her character appeared similar to Mary's, though her\n",
      "natural disposition was very different.\n",
      "\n",
      " She was several years older than Mary, yet her refinement, her taste,\n",
      "caught her eye, and she eagerly sought her friendship: before her return\n",
      "she had assisted the family, which was almost reduced to the last ebb;\n",
      "and now she had another motive to actuate her.\n",
      "\n",
      "As she had often occasion to send messages to Ann, her new friend,\n",
      "mistakes were frequently made; Ann proposed that in future they should\n",
      "be written ones, to obviate this difficulty, and render their\n",
      "intercourse more agreeable. Young people are mostly fond of scribbling;\n",
      "Mary had had very little instruction; but by copying her friend's\n",
      "letters, whose hand she admired, she soon became a proficient; a little\n",
      "practice made her write with tolerable correctness, and her genius gave\n",
      "force to it. In conversation, and in writing, when she felt, she was\n",
      "pathetic, tender and persuasive; and she expressed contempt with such\n",
      "energy, that few could stand the flash of her eyes.\n",
      "\n",
      " As she grew more intimate with Ann, her manners were softened, and she\n",
      "acquired a degree of equality in her behaviour: yet still her spirits\n",
      "were fluctuating, and her movements rapid. She felt less pain on\n",
      "account of her mother's partiality to her brother, as she hoped now to\n",
      "experience the pleasure of being beloved; but this hope led her into new\n",
      "sorrows, and, as usual, paved the way for disappointment. Ann only felt\n",
      "gratitude; her heart was entirely engrossed by one object, and\n",
      "friendship could not serve as a substitute; memory officiously retraced\n",
      "past scenes, and unavailing wishes made time loiter.\n",
      "\n",
      " Mary was often hurt by the involuntary indifference which these\n",
      "consequences produced. When her friend was all the world to her, she\n",
      "found she was not as necessary to her happiness; and her delicate mind\n",
      "could not bear to obtrude her affection, or receive love as an alms, the\n",
      "offspring of pity. Very frequently has she ran to her with delight, and\n",
      "not perceiving any thing of the same kind in Ann's countenance, she has\n",
      "shrunk back; and, falling from one extreme into the other, instead of a\n",
      "warm greeting that was just slipping from her tongue, her expressions\n",
      "seemed to be dictated by the most chilling insensibility.\n",
      "\n",
      "She would then imagine that she looked sickly or unhappy, and then all\n",
      "her tenderness would return like a torrent, and bear away all\n",
      "reflection. In this manner was her sensibility called forth, and\n",
      "exercised, by her mother's illness, her friend's misfortunes, and her\n",
      "own unsettled mind.\n",
      "\n",
      " \n",
      "\n",
      " \n",
      "CHAP. IV.\n",
      "\n",
      " \n",
      "Near to her father's house was a range of mountains; some of them were,\n",
      "literally speaking, cloud-capt, for on them clouds continually rested,\n",
      "and gave grandeur to the prospect; and down many of their sides the\n",
      "little bubbling cascades ran till they swelled a beautiful river.\n",
      "Through the straggling trees and bushes the wind whistled, and on them\n",
      "the birds sung, particularly the robins; they also found shelter in the\n",
      "ivy of an old castle, a haunted one, as the story went; it was situated\n",
      "on the brow of one of the mountains, and commanded a view of the sea.\n",
      "This castle had been inhabited by some of her ancestors; and many tales\n",
      "had the old house-keeper told her of the worthies who had resided there.\n",
      "\n",
      " When her mother frowned, and her friend looked cool, she would steal to\n",
      "this retirement, where human foot seldom trod--gaze on the sea, observe\n",
      "the grey clouds, or listen to the wind which struggled to free itself\n",
      "from the only thing that impeded its course. When more cheerful, she\n",
      "admired the various dispositions of light and shade, the beautiful tints\n",
      "the gleams of sunshine gave to the distant hills; then she rejoiced in\n",
      "existence, and darted into futurity.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(''.join(coref_resolved_paragraphs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(''.join(paragraphs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Context Decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set OpenAI's API key and API base to use vLLM's API server.\n",
    "openai_api_key = \"EMPTY\"\n",
    "openai_api_base = \"http://localhost:8000/v1\"\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key=openai_api_key,\n",
    "    base_url=openai_api_base,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Where does the witch live?\n"
     ]
    }
   ],
   "source": [
    "print(dataset_dict[task_name][test_i]['input'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The Atlas Mountains']\n"
     ]
    }
   ],
   "source": [
    "print(dataset_dict[task_name][test_i]['answers'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataset_dict[task_name][test_i]['context'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Index text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "context_type = 'novel'\n",
    "ent_num = 10\n",
    "n = 20\n",
    "temperature = 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/29 [00:00<?, ?it/s]02/28/2024 13:48:39 - INFO - \t HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "  3%|▎         | 1/29 [00:13<06:31, 13.98s/it]02/28/2024 13:48:50 - INFO - \t HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "  7%|▋         | 2/29 [00:24<05:21, 11.91s/it]02/28/2024 13:49:00 - INFO - \t HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 10%|█         | 3/29 [00:35<04:54, 11.33s/it]02/28/2024 13:49:14 - INFO - \t HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 14%|█▍        | 4/29 [00:48<05:08, 12.35s/it]02/28/2024 13:49:24 - INFO - \t HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 17%|█▋        | 5/29 [00:58<04:29, 11.21s/it]02/28/2024 13:49:35 - INFO - \t HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 21%|██        | 6/29 [01:10<04:22, 11.43s/it]02/28/2024 13:50:03 - INFO - \t HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 24%|██▍       | 7/29 [01:37<06:05, 16.60s/it]02/28/2024 13:50:19 - INFO - \t HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 28%|██▊       | 8/29 [01:53<05:47, 16.57s/it]02/28/2024 13:50:39 - INFO - \t HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 31%|███       | 9/29 [02:13<05:53, 17.70s/it]02/28/2024 13:50:48 - INFO - \t HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 34%|███▍      | 10/29 [02:22<04:42, 14.87s/it]02/28/2024 13:51:00 - INFO - \t HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 38%|███▊      | 11/29 [02:34<04:14, 14.12s/it]02/28/2024 13:51:11 - INFO - \t HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 41%|████▏     | 12/29 [02:45<03:40, 12.94s/it]02/28/2024 13:51:24 - INFO - \t HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 45%|████▍     | 13/29 [02:58<03:27, 12.99s/it]02/28/2024 13:51:31 - INFO - \t HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 48%|████▊     | 14/29 [03:05<02:49, 11.33s/it]02/28/2024 13:51:41 - INFO - \t HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 52%|█████▏    | 15/29 [03:15<02:30, 10.74s/it]02/28/2024 13:51:51 - INFO - \t HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 55%|█████▌    | 16/29 [03:25<02:16, 10.54s/it]02/28/2024 13:52:09 - INFO - \t HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 59%|█████▊    | 17/29 [03:43<02:36, 13.00s/it]02/28/2024 13:52:30 - INFO - \t HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 62%|██████▏   | 18/29 [04:04<02:48, 15.28s/it]02/28/2024 13:52:46 - INFO - \t HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 66%|██████▌   | 19/29 [04:20<02:35, 15.50s/it]02/28/2024 13:53:01 - INFO - \t HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 69%|██████▉   | 20/29 [04:35<02:18, 15.34s/it]02/28/2024 13:53:15 - INFO - \t HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 72%|███████▏  | 21/29 [04:49<02:00, 15.05s/it]02/28/2024 13:53:36 - INFO - \t HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 76%|███████▌  | 22/29 [05:10<01:57, 16.80s/it]02/28/2024 13:53:42 - INFO - \t HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 79%|███████▉  | 23/29 [05:17<01:21, 13.66s/it]02/28/2024 13:53:53 - INFO - \t HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 83%|████████▎ | 24/29 [05:27<01:03, 12.79s/it]02/28/2024 13:54:05 - INFO - \t HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 86%|████████▌ | 25/29 [05:39<00:49, 12.36s/it]02/28/2024 13:54:23 - INFO - \t HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 90%|████████▉ | 26/29 [05:57<00:42, 14.18s/it]02/28/2024 13:54:43 - INFO - \t HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 93%|█████████▎| 27/29 [06:17<00:31, 15.78s/it]02/28/2024 13:54:55 - INFO - \t HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 97%|█████████▋| 28/29 [06:29<00:14, 14.65s/it]02/28/2024 13:54:59 - INFO - \t HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "100%|██████████| 29/29 [06:33<00:00, 13.56s/it]\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "for paragraph in tqdm(paragraphs):\n",
    "    list_entity_prompt = f'''{context_type.upper()}:\\n\\n{paragraph}\\n\\nAbove is part of a {context_type}. First, list the important entities in the above passages that are relevant to most of the content. You may synthesis entities to avoid ambiguity. Don't give any explanation. Then, summarize the information in the above context for each of the important entities and try to include other important entities in each entity's summary if they are related. The two steps should be generated in the following format: \"Important entities:\\n1. Entity 1\\n2. Entity 2\\n...\\nEntity summary:\\nEntity 1: Entity 1's summary\\nEntity 2: Entity 2's summary\\n...\"'''\n",
    "    chat_response = client.chat.completions.create(\n",
    "        model=\"mistralai/Mistral-7B-Instruct-v0.2\",\n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\": list_entity_prompt},\n",
    "        ],\n",
    "        # n=n,\n",
    "        # temperature=temperature\n",
    "    )\n",
    "    results.append((paragraph, chat_response.choices[0].message.content))\n",
    "\n",
    "with open(f'response_{test_i}.json', 'w') as f_out:\n",
    "    json.dump(results, f_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interact with LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load index\n",
    "with open(f'response_{test_i}.json') as f_in:\n",
    "    results = json.load(f_in)\n",
    "\n",
    "paragraph:str\n",
    "all_graph = nx.DiGraph()\n",
    "all_summary:List[str] = []\n",
    "for pid, (paragraph, response) in enumerate(results):\n",
    "    temp_graph, temp_summary = longdoc.parse_to_graph(response)\n",
    "    s_offset = len(all_summary)\n",
    "    for head, tail, sids in temp_graph.edges.data('sum'):\n",
    "        if not all_graph.has_edge(head, tail):\n",
    "            all_graph.add_edge(head, tail, sum=[])\n",
    "        all_graph.get_edge_data(head, tail)['sum'].extend([(sid + s_offset, pid) for sid in sids])\n",
    "    all_summary.extend(temp_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: identity entities of interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = dataset_dict[task_name][test_i]['input']\n",
    "query_entity_prompt = f'''Question: {question}\\nYou need to answer the above question based on a given story. Before searching in the story, identify some entities you want to query to gain useful information. Generate your response in the following format:\\n\"Query entities:\\nthe first entity\\nthe second entity\\n...\". Don't give any explanation.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "02/28/2024 15:25:10 - INFO - \t HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Query entities:\n",
      "the witch's character\n",
      "the setting of the story.\n"
     ]
    }
   ],
   "source": [
    "chat_response = client.chat.completions.create(\n",
    "    model=\"mistralai/Mistral-7B-Instruct-v0.2\",\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": query_entity_prompt},\n",
    "    ]\n",
    ")\n",
    "print(chat_response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "ent_sets = longdoc.retrieve_node(all_graph, [\"Ann\", \"Mary\", \"feelings of affection\"])\n",
    "# ent_sets = longdoc.retrieve_node(all_graph, ['the witch', \"the character's residence in the story\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Ann', 'Ann and Mary', \"Ann's mother\", 'Mother of Ann', 'Mary and Ann'],\n",
       " ['Mary', 'Mary and Ann', 'Ann and Mary', \"Mary's husband\", \"Mary's maid\"],\n",
       " ['Affection',\n",
       "  'Feelings',\n",
       "  'Affections',\n",
       "  'Understanding and affections',\n",
       "  'Affection/support']]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ent_sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: retrieve summary/original text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "pair2sids = set()\n",
    "for ent_set in ent_sets:\n",
    "    for ent in ent_set:\n",
    "        for pair in all_graph.edges(ent):\n",
    "            pair2sids.update([((ent, ), sid, pid) for sid, pid in all_graph.get_edge_data(*pair)['sum']])\n",
    "for pairs in itertools.combinations(ent_sets, 2):\n",
    "    for m_node, a_node in itertools.product(*pairs):\n",
    "        if all_graph.has_edge(m_node, a_node):\n",
    "            pair2sids.update([((m_node, a_node), sid, pid) for sid, pid in all_graph.get_edge_data(m_node, a_node)['sum']])\n",
    "        if all_graph.has_edge(a_node, m_node):\n",
    "            pair2sids.update([((a_node, m_node), sid, pid) for sid, pid in all_graph.get_edge_data(a_node, m_node)['sum']])\n",
    "pair2sids = list(pair2sids)\n",
    "pair2sids.sort(key=lambda x: x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('Mary',), 14, 2),\n",
       " (('Mary',), 65, 10),\n",
       " (('Mary',), 74, 11),\n",
       " (('Mary', 'Ann'), 86, 13),\n",
       " (('Mary',), 86, 13),\n",
       " (('Ann', 'Mary'), 87, 13),\n",
       " (('Ann',), 87, 13),\n",
       " (('Mary',), 93, 14),\n",
       " (('Affection',), 97, 14),\n",
       " (('Affection', 'Mary'), 97, 14),\n",
       " (('Mary',), 140, 19),\n",
       " (('Understanding and affections', 'Mary'), 148, 19),\n",
       " (('Understanding and affections',), 148, 19),\n",
       " (('Ann',), 155, 20),\n",
       " ((\"Ann's mother\",), 156, 20),\n",
       " (('Mary', 'Ann'), 165, 22),\n",
       " (('Mary',), 165, 22),\n",
       " (('Ann',), 166, 22),\n",
       " (('Mary',), 172, 23),\n",
       " (('Mary', 'Ann'), 172, 23),\n",
       " (('Ann',), 176, 23),\n",
       " (('Ann', 'Mary'), 176, 23),\n",
       " (('Mary',), 177, 24),\n",
       " (('Ann', 'Mary'), 181, 24),\n",
       " (('Ann',), 181, 24),\n",
       " (('Mary',), 182, 25),\n",
       " (('Mary', 'Ann'), 182, 25),\n",
       " (('Ann',), 184, 25),\n",
       " (('Ann', 'Mary'), 184, 25),\n",
       " (('Mary', 'Ann'), 191, 27),\n",
       " (('Mary',), 191, 27),\n",
       " (('Ann',), 193, 27),\n",
       " (('Ann', 'Mary'), 193, 27),\n",
       " (('Mary',), 196, 28),\n",
       " (('Mary',), 200, 29),\n",
       " (('Mary', 'Ann'), 200, 29),\n",
       " (('Ann',), 201, 29),\n",
       " (('Ann', 'Mary'), 201, 29),\n",
       " (('Ann',), 218, 32),\n",
       " (('Mary', 'Ann'), 219, 32),\n",
       " (('Mary',), 219, 32),\n",
       " (('Mary',), 234, 33),\n",
       " (('Mary', 'Ann'), 244, 35),\n",
       " (('Mary',), 244, 35),\n",
       " (('Ann',), 245, 35),\n",
       " (('Ann', 'Mary'), 245, 35),\n",
       " (('Mary',), 251, 37),\n",
       " (('Ann and Mary',), 263, 39),\n",
       " (('Mary',), 275, 41),\n",
       " (('Mary', 'Ann'), 275, 41),\n",
       " (('Ann',), 276, 41),\n",
       " (('Ann', 'Mary'), 276, 41),\n",
       " (('Mary',), 280, 42),\n",
       " (('Mary', 'Ann'), 280, 42),\n",
       " (('Ann',), 281, 42),\n",
       " (('Mary',), 287, 43),\n",
       " (('Mary',), 289, 44),\n",
       " (('Mary',), 327, 47),\n",
       " (('Mary', 'Ann'), 327, 47),\n",
       " (('Ann', 'Mary'), 329, 47),\n",
       " (('Ann',), 329, 47),\n",
       " ((\"Mary's maid\", 'Ann'), 331, 47),\n",
       " ((\"Mary's maid\",), 331, 47),\n",
       " (('Mary',), 333, 48),\n",
       " (('Ann',), 334, 48),\n",
       " (('Ann', 'Mary'), 334, 48),\n",
       " (('Mary',), 335, 49),\n",
       " (('Mary', 'Ann'), 335, 49),\n",
       " (('Ann',), 336, 49),\n",
       " (('Mary', 'Ann'), 345, 50),\n",
       " (('Mary',), 345, 50),\n",
       " (('Ann', 'Mary'), 347, 50),\n",
       " (('Ann',), 347, 50),\n",
       " (('Mary',), 374, 54),\n",
       " (('Ann',), 382, 55),\n",
       " (('Mary',), 396, 57),\n",
       " (('Mary',), 410, 59),\n",
       " (('Mary', 'Ann'), 415, 60),\n",
       " (('Mary',), 415, 60),\n",
       " ((\"Mary's husband\",), 417, 60),\n",
       " (('Ann', 'Mary'), 418, 60),\n",
       " (('Ann',), 418, 60),\n",
       " (('Affections',), 421, 61),\n",
       " (('Feelings',), 453, 63),\n",
       " (('Mary',), 455, 64),\n",
       " (('Mary',), 456, 65),\n",
       " (('Affection/support', 'Mary'), 458, 65),\n",
       " (('Affection/support',), 458, 65),\n",
       " (('Mary', 'Ann'), 462, 66),\n",
       " (('Mary',), 462, 66),\n",
       " (('Ann', 'Mary'), 464, 66),\n",
       " (('Ann',), 464, 66),\n",
       " (('Mary',), 520, 74),\n",
       " (('Mary', 'Ann'), 524, 76),\n",
       " (('Mary',), 524, 76),\n",
       " (('Mary', 'Mother of Ann'), 524, 76),\n",
       " (('Mother of Ann',), 525, 76),\n",
       " (('Mother of Ann', 'Mary'), 525, 76),\n",
       " (('Ann',), 526, 76),\n",
       " (('Ann', 'Mary'), 526, 76),\n",
       " (('Mary',), 530, 77),\n",
       " (('Ann',), 531, 77),\n",
       " (('Ann', 'Mary'), 531, 77),\n",
       " (('Mary',), 545, 79),\n",
       " (('Mary',), 551, 80),\n",
       " (('Mary',), 569, 82),\n",
       " (('Ann', 'Mary'), 570, 82),\n",
       " (('Ann',), 570, 82),\n",
       " (('Mary',), 603, 86),\n",
       " (('Mary',), 635, 88),\n",
       " (('Mary',), 640, 90),\n",
       " (('Mary',), 642, 91),\n",
       " (('Mary',), 646, 92),\n",
       " (('Mary',), 653, 93),\n",
       " (('Mary',), 658, 94),\n",
       " (('Mary',), 669, 96),\n",
       " (('Mary', 'Affection'), 669, 96),\n",
       " (('Affection',), 671, 96),\n",
       " (('Affection', 'Mary'), 671, 96),\n",
       " (('Mary',), 683, 97),\n",
       " (('Ann', 'Mary'), 685, 97),\n",
       " (('Ann',), 685, 97),\n",
       " (('Mary',), 692, 98),\n",
       " (('Mary',), 708, 100),\n",
       " (('Mary',), 710, 101),\n",
       " (('Mary',), 717, 102),\n",
       " (('Mary',), 735, 105)]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pair2sids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "pid2pairs = defaultdict(set)\n",
    "for pair, sid, pid in pair2sids:\n",
    "    pid2pairs[pid].add(frozenset(pair))\n",
    "    \n",
    "passage_retrieve_prompt = f'''Question: {question}\\nYou need to answer the above question based on a given story.\\nBelow is a list of related entities and entity pairs contained in each passage from the story. The passage numbers are assigned based on the original order of the passages in the text.\\n\\n'''\n",
    "menu = ''\n",
    "for pid, pairs in pid2pairs.items():\n",
    "    menu += f\"Passage {pid}: {', '.join([str(tuple(pair)) if len(pair) == 2 else tuple(pair)[0] for pair in pairs])}\\n\\n\"\n",
    "passage_retrieve_prompt += menu\n",
    "passage_retrieve_prompt += '''Now, you need to gain more information from the passages to answer the queston. Select a retrieval type and the passage numbers. For the retrieval type, you may choose \"original text\" to retrieve the original passages, or \"summary\" to retrieve the summary of the entities in the passage. For passage selection, you may select passage numbers that do not exist in the above list to obtain continuous contextual information. You may retrieve either 5 passages for \"original text\" or 10 passages for \"summary\". Generate your response in the following format:\\n\"Retrieval type: summary/original text\\nPassage numbers: first passage number, second passage number, ...\".\\nDon't give any explanation.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Why does Ann not return Mary's feelings of affection?\n",
      "You need to answer the above question based on a given story.\n",
      "Below is a list of related entities and entity pairs contained in each passage from the story. The passage numbers are assigned based on the original order of the passages in the text.\n",
      "\n",
      "Passage 2: Mary\n",
      "\n",
      "Passage 10: Mary\n",
      "\n",
      "Passage 11: Mary\n",
      "\n",
      "Passage 13: Mary, ('Mary', 'Ann'), Ann\n",
      "\n",
      "Passage 14: Mary, ('Affection', 'Mary'), Affection\n",
      "\n",
      "Passage 19: Mary, Understanding and affections, ('Mary', 'Understanding and affections')\n",
      "\n",
      "Passage 20: Ann, Ann's mother\n",
      "\n",
      "Passage 22: Mary, ('Mary', 'Ann'), Ann\n",
      "\n",
      "Passage 23: Mary, ('Mary', 'Ann'), Ann\n",
      "\n",
      "Passage 24: Mary, ('Mary', 'Ann'), Ann\n",
      "\n",
      "Passage 25: Mary, ('Mary', 'Ann'), Ann\n",
      "\n",
      "Passage 27: Mary, ('Mary', 'Ann'), Ann\n",
      "\n",
      "Passage 28: Mary\n",
      "\n",
      "Passage 29: Mary, ('Mary', 'Ann'), Ann\n",
      "\n",
      "Passage 32: Mary, ('Mary', 'Ann'), Ann\n",
      "\n",
      "Passage 33: Mary\n",
      "\n",
      "Passage 35: Mary, ('Mary', 'Ann'), Ann\n",
      "\n",
      "Passage 37: Mary\n",
      "\n",
      "Passage 39: Ann and Mary\n",
      "\n",
      "Passage 41: Mary, ('Mary', 'Ann'), Ann\n",
      "\n",
      "Passage 42: Mary, ('Mary', 'Ann'), Ann\n",
      "\n",
      "Passage 43: Mary\n",
      "\n",
      "Passage 44: Mary\n",
      "\n",
      "Passage 47: Mary's maid, Mary, ('Mary', 'Ann'), Ann, (\"Mary's maid\", 'Ann')\n",
      "\n",
      "Passage 48: Mary, ('Mary', 'Ann'), Ann\n",
      "\n",
      "Passage 49: Mary, ('Mary', 'Ann'), Ann\n",
      "\n",
      "Passage 50: Mary, ('Mary', 'Ann'), Ann\n",
      "\n",
      "Passage 54: Mary\n",
      "\n",
      "Passage 55: Ann\n",
      "\n",
      "Passage 57: Mary\n",
      "\n",
      "Passage 59: Mary\n",
      "\n",
      "Passage 60: Mary, ('Mary', 'Ann'), Ann, Mary's husband\n",
      "\n",
      "Passage 61: Affections\n",
      "\n",
      "Passage 63: Feelings\n",
      "\n",
      "Passage 64: Mary\n",
      "\n",
      "Passage 65: Mary, Affection/support, ('Mary', 'Affection/support')\n",
      "\n",
      "Passage 66: Mary, ('Mary', 'Ann'), Ann\n",
      "\n",
      "Passage 74: Mary\n",
      "\n",
      "Passage 76: ('Mary', 'Mother of Ann'), Mary, Mother of Ann, ('Mary', 'Ann'), Ann\n",
      "\n",
      "Passage 77: Mary, ('Mary', 'Ann'), Ann\n",
      "\n",
      "Passage 79: Mary\n",
      "\n",
      "Passage 80: Mary\n",
      "\n",
      "Passage 82: Mary, ('Mary', 'Ann'), Ann\n",
      "\n",
      "Passage 86: Mary\n",
      "\n",
      "Passage 88: Mary\n",
      "\n",
      "Passage 90: Mary\n",
      "\n",
      "Passage 91: Mary\n",
      "\n",
      "Passage 92: Mary\n",
      "\n",
      "Passage 93: Mary\n",
      "\n",
      "Passage 94: Mary\n",
      "\n",
      "Passage 96: Mary, ('Mary', 'Affection'), Affection\n",
      "\n",
      "Passage 97: Mary, ('Mary', 'Ann'), Ann\n",
      "\n",
      "Passage 98: Mary\n",
      "\n",
      "Passage 100: Mary\n",
      "\n",
      "Passage 101: Mary\n",
      "\n",
      "Passage 102: Mary\n",
      "\n",
      "Passage 105: Mary\n",
      "\n",
      "Now, you need to gain more information from the passages to answer the queston. Select a retrieval type and the passage numbers. For the retrieval type, you may choose \"original text\" to retrieve the original passages, or \"summary\" to retrieve the summary of the entities in the passage. For passage selection, you may select passage numbers that do not exist in the above list to obtain continuous contextual information. You may retrieve either 5 passages for \"original text\" or 10 passages for \"summary\". Generate your response in the following format:\n",
      "\"Retrieval type: summary/original text\n",
      "Passage numbers: first passage number, second passage number, ...\".\n",
      "Don't give any explanation.\n"
     ]
    }
   ],
   "source": [
    "print(passage_retrieve_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "02/28/2024 15:25:27 - INFO - \t HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Retrieval type: original text\n",
      "Passage numbers: 1, 13, 27.\n"
     ]
    }
   ],
   "source": [
    "chat_response2 = client.chat.completions.create(\n",
    "    model=\"mistralai/Mistral-7B-Instruct-v0.2\",\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": passage_retrieve_prompt},\n",
    "    ]\n",
    ")\n",
    "print(chat_response2.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: analyze retrieved info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "passage_indices = [1, 13, 27]\n",
    "# passage_indices = [13, 22, 23, 24, 25, 27, 28, 29, 32, 33]\n",
    "retrieve_result = ''\n",
    "pid2sids = defaultdict(set)\n",
    "for pair, sid, pid in pair2sids:\n",
    "    pid2sids[pid].add(sid)\n",
    "for pid, sids in pid2sids.items():\n",
    "    if pid in passage_indices:\n",
    "        temp_summary = '\\n'.join([all_summary[sid] for sid in sids])\n",
    "        retrieve_result += f'''Passage {pid}:\\n{temp_summary}\\n\\n'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Passage 13:\n",
      "Mary: Mary frequently made mistakes while sending messages to her new friend Ann. To make their communication more agreeable, Ann proposed writing letters instead. Mary had little instruction, but with practice and observing Ann's handwriting, she became proficient. Mary felt less pain about her mother's favoritism towards her brother, as she hoped to be beloved by someone else. However, this hope led to new sorrows and disappointment. Mary's manners were softened, but her spirits were still fluctuating, and her movements were rapid.\n",
      "Ann: Ann felt gratitude towards Mary and her friendship. Her heart was entirely engrossed by one object, making friendship an insufficient substitute. Ann recalled past scenes and made unavailing wishes, causing time to loiter. She proposed writing letters instead of verbal communication to avoid mistakes.\n",
      "\n",
      "Passage 22:\n",
      "Mary: She was not at home when summoned by her father. She had visited Ann, who was in an hysteric fit due to threats of eviction from their landlord.\n",
      "Ann: She was in an hysteric fit due to the landlord's agent's threats of eviction and the loss of their farm.\n",
      "\n",
      "Passage 23:\n",
      "Ann: Mary's close friend whom she loves deeply and wishes to keep near her.\n",
      "Mary: Witnessed a scene of misery, learned that her mother was dying, and was surprised by her father's announcement that they had decided to marry her to Charles's son. She was overwhelmed by this news but also saw the potential benefits of the marriage, such as being able to keep Ann near her and ease her concerns about her family.\n",
      "\n",
      "Passage 24:\n",
      "Mary: Entered her mother's chamber to find her dying. Forgave her mother's past mistakes. Cried as her mother expired in her arms. Husband left the same day for the continent.\n",
      "Ann: Sent for to console Mary and reconcile her to her fate. Necessary for Mary to have a female companion, as there was no maiden aunt or cousin of the same class.\n",
      "\n",
      "Passage 25:\n",
      "Ann: Ann was ill and had a nurse during the mourning period. Her health did not improve, and she provided little companionship for Mary.\n",
      "Mary: Mary was trying to get her father to help support her family by paying the rent and allowing her mother to start an industry scheme. Her arguments were based on philanthropy and friendship, but her father didn't understand these abstract concepts. After her mother's death, Mary took care of Ann and they lived in retirement, filling their time with music, drawing, and reading. Mary's quick wit and observation skills improved during this time, but she was still troubled and disappointed by Ann's company.\n",
      "\n",
      "Passage 27:\n",
      "Ann: Ann is sick and Mary shows concern for her. Mary's dislike for Ann's boyfriend is mentioned, but her focus shifts to Ann when her father falls ill.\n",
      "Mary: Mary experiences various forms of sorrow. She has an extreme dislike for someone named Ann's boyfriend, but her focus shifts when her father falls ill. She sits by her father's bedside, grieving for him despite their strained relationship. Her grief is not selfish as he is her father, but she wonders if his life of sensuality can prepare him for a peaceful death.\n",
      "\n",
      "Passage 28:\n",
      "Mary: Mary finds the night terrific due to her father's illness and the thunder storm. She fears the eternal separation of the soul and body when someone dies, and finds no comfort in the thought of death.\n",
      "\n",
      "Passage 29:\n",
      "Mary: A person who is excessively watching and worrying about Ann, impairing her own health. Fears Ann's condition might prevent her from executing a plan to travel to a healthier climate with her.\n",
      "Ann: A person who is constantly going to bed but unable to rest due to uneasy thoughts and apprehensions about Mary. Had a fit of coughing and burst a blood-vessel, diagnosed with a critical condition and likely to die in the spring if she spends the winter in England.\n",
      "\n",
      "Passage 32:\n",
      "Ann: A person who is terrified by the sight of water and stays in the cabin on the ship.\n",
      "Mary: A person whose spirits are raised by Ann's recovered looks and goes on deck to survey the ocean and converse with sailors.\n",
      "\n",
      "Passage 33:\n",
      "Mary: The protagonist of the story, she was struck with awe during the nun's singing and felt the presence of her Almighty Friend, particularly when she was alone. She was traveling with the nuns and was concerned for their welfare during the rain.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(retrieve_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze_retrieve_prompt = f'''Question: {question}\\nYou need to answer the above question based on a given story.\\nBelow is a list of related entities and entity pairs contained in each passage from the story. The passage numbers are assigned based on the original order of the passages in the text.\\n\\n'''\n",
    "analyze_retrieve_prompt += menu\n",
    "analyze_retrieve_prompt += f'''Below are some selected passages with the entity summary.\\n\\n'''\n",
    "analyze_retrieve_prompt += retrieve_result\n",
    "analyze_retrieve_prompt += '''Now, summarize any useful information from the above selected passages. Generate your response in the following format:\\n\"Summary: the summary of current useful information\".'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "02/28/2024 15:25:49 - INFO - \t HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Summary: The women named Ruth and Lucy are praised by Wordsworth and are likely the subjects of his poetry as grandsons' sweethearts. The entity \"Love\" is mentioned multiple times in the story, and in one passage, it is described as helping lovers experience joy together for ten consecutive moons, with the Witch ensuring their well-being during this time. There is no direct mention of a witch's residence in the given passages.\n"
     ]
    }
   ],
   "source": [
    "chat_response3 = client.chat.completions.create(\n",
    "    model=\"mistralai/Mistral-7B-Instruct-v0.2\",\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": analyze_retrieve_prompt},\n",
    "    ]\n",
    ")\n",
    "print(chat_response3.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: continue searching or start answering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_summary = chat_response3.choices[0].message.content + '\\n\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "decision_prompt = f'''Question: {question}\\nYou need to answer the above question based on a given story.\\nBelow is a list of related entities and entity pairs contained in each passage from the story. The passage numbers are assigned based on the original order of the passages in the text.\\n\\n'''\n",
    "decision_prompt += menu\n",
    "retrieved_passage_idx_str = ', '.join(map(str, passage_indices))\n",
    "decision_prompt += f'''Below is the summary of useful information from passage {retrieved_passage_idx_str}.\\n\\n'''\n",
    "decision_prompt += current_summary\n",
    "decision_prompt += '''Now, you need to choose whether to continue searching for more information or to start answering the question.\n",
    "\n",
    "If the information is not adequate, you may choose to continue searching. Select a retrieval type and the passage numbers. For the retrieval type, you may choose \"original text\" to retrieve the original passages, or \"summary\" to retrieve the summary of the entities in the passage. For passage selection, you may select passage numbers that do not exist in the above list to obtain continuous contextual information. You may retrieve either 5 passages for \"original text\" or 10 passages for \"summary\". Generate your response in the following format:\\n\"Retrieval type: summary/original text\\nPassage numbers: first passage number, second passage number, ...\".\n",
    "\n",
    "Otherwise, if the information is adequate, you may choose to start answering the question. Generate your answer to the question in the following format:\\n\"Answer: your answer here\".\n",
    "\n",
    "For either choice, don't give any explanation.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "02/28/2024 15:20:47 - INFO - \t HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Retrieval type: summary\n",
      "Passage numbers: 13, 22, 23, 24, 25, 27, 28, 29, 32, 33\n",
      "\n",
      "Answer: Ann does not return Mary's feelings of affection due to her intense focus on one object and her belief that friendship is an insufficient substitute for deeper connection.\n"
     ]
    }
   ],
   "source": [
    "chat_response4 = client.chat.completions.create(\n",
    "    model=\"mistralai/Mistral-7B-Instruct-v0.2\",\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": decision_prompt},\n",
    "    ]\n",
    ")\n",
    "print(chat_response4.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]02/28/2024 04:55:09 - INFO - \t HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "02/28/2024 04:55:18 - INFO - \t HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "100%|██████████| 1/1 [00:14<00:00, 14.51s/it]\n"
     ]
    }
   ],
   "source": [
    "results3 = []\n",
    "for paragraph in tqdm(paragraphs[8:9]):\n",
    "    list_entity_prompt = f\"{context_type.upper()}:\\n\\n{paragraph}\\n\\nAbove is part of a {context_type}. List {ent_num} important entities in the above passages that are relevant to most of the content. You may synthesis entities to avoid ambiguity. List and separate the entities with '\\n' and don't give any explanation.\"\n",
    "    chat_response = client.chat.completions.create(\n",
    "        model=\"mistralai/Mistral-7B-Instruct-v0.2\",\n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\": list_entity_prompt},\n",
    "        ],\n",
    "        n=n,\n",
    "        temperature=temperature\n",
    "    )\n",
    "    ent_cnt = Counter()\n",
    "    for i in range(n):\n",
    "        for p in chat_response.choices[i].message.content.split('\\n\\n'):\n",
    "            if p.count('\\n') >= ent_num - 1:\n",
    "                entities = [ent.strip('*. ') for ent in p.split('\\n')]\n",
    "                if all([ent.startswith(str(eid + 1)) for eid, ent in enumerate(entities)]):\n",
    "                    entities = [ent[len(str(eid + 1)):].strip('. ') for eid, ent in enumerate(entities)]\n",
    "                ent_cnt.update(entities)\n",
    "    important_entities = [ent for ent, cnt in ent_cnt.most_common(ent_num) if cnt > n // 3]\n",
    "    important_entities_str = '\\n'.join(important_entities)\n",
    "    describe_relation_prompt = f\"{context_type.upper()}:\\n\\n{paragraph}\\n\\nAbove is part of a {context_type}. Summarize the information in the above context for each of the following entities:\\n\\n{important_entities_str}\\n\\nTry to include other important entities in each entity's summary if they are related. Separate the passages with '\\n'.\"\n",
    "    chat_response2 = client.chat.completions.create(\n",
    "        model=\"mistralai/Mistral-7B-Instruct-v0.2\",\n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\": describe_relation_prompt}\n",
    "        ]\n",
    "    )\n",
    "    results3.append((paragraph, important_entities, chat_response2.choices[0].message.content))\n",
    "\n",
    "# with open('temp2.json', 'w') as f_out:\n",
    "#     json.dump(results, f_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Her father',\n",
       " 'Angels',\n",
       " 'Wood in the park',\n",
       " 'Her husband',\n",
       " 'She (Mary)',\n",
       " 'Female acquirements',\n",
       " 'Her mother',\n",
       " 'Separate state',\n",
       " 'Gay world',\n",
       " 'Indolence and ill health']"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "important_entities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Long context and multi-hop reasoning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HotpotQA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hotpot_qa = load_dataset('hotpot_qa', 'distractor', split='validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hotpot_qa[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NarrativeQA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "narrative_qa = load_dataset('narrativeqa', split='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "narrative_qa[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QASPER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qasper = load_dataset('allenai/qasper', split='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qasper[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QuALITY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quality_qa = [json.loads(l) for l in open('../../QuALITY.v1.0.1.train')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quality_qa[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### openbookqa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "openbookqa = load_dataset('openbookqa', 'main', split='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "openbookqa[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LongBench"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = [\n",
    "    # \"narrativeqa\", \n",
    "    # \"qasper\", \n",
    "    # \"multifieldqa_en\", \n",
    "    # \"multifieldqa_zh\", \n",
    "    # \"hotpotqa\", \n",
    "    # \"2wikimqa\", \n",
    "    \"musique\", \n",
    "    # \"dureader\", \n",
    "    # \"gov_report\", \n",
    "    # \"qmsum\", \n",
    "    # \"multi_news\", \n",
    "    # \"vcsum\", \n",
    "    # \"trec\", \n",
    "    # \"triviaqa\", \n",
    "    # \"samsum\", \n",
    "    # \"lsht\", \n",
    "    # \"passage_count\", \n",
    "    # \"passage_retrieval_en\", \n",
    "    # \"passage_retrieval_zh\", \n",
    "    # \"lcc\", \n",
    "    # \"repobench-p\"\n",
    "]\n",
    "task_name = datasets[0]\n",
    "\n",
    "dataset_dict = {task_name: load_dataset('THUDM/LongBench', task_name, split='test')}\n",
    "print(dataset_dict[task_name][1]['context'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dict[task_name][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LooGLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = [\n",
    "    # \"shortdep_qa\", \n",
    "    # \"shortdep_cloze\", \n",
    "    \"longdep_qa\", \n",
    "    # \"longdep_summarization\"\n",
    "]\n",
    "\n",
    "for testset in datasets:\n",
    "    data = load_dataset('bigainlco/LooGLE', testset, split='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "local",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
