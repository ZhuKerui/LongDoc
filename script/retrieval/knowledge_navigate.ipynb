{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MYOnCMh83ZRE"
      },
      "outputs": [],
      "source": [
        "from tqdm.notebook import tqdm\n",
        "from nltk import sent_tokenize\n",
        "from transformers import AutoTokenizer\n",
        "import sys\n",
        "sys.path.append('../..')\n",
        "\n",
        "from src import *\n",
        "from src.test_utils import * \n",
        "\n",
        "torch.backends.cuda.enable_mem_efficient_sdp(False)\n",
        "torch.backends.cuda.enable_flash_sdp(False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained('intfloat/multilingual-e5-large')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tokenizer.model_max_length"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# gritlm = GritLM(\"GritLM/GritLM-7B\", device_map=\"cuda:2\", torch_dtype=\"auto\")\n",
        "retriever = Retriever()\n",
        "# llm = LLM()\n",
        "# llm = 'mistralai/Mistral-7B-Instruct-v0.2'\n",
        "llm = None\n",
        "longdoc = LongDoc(retriever, llm)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Experiment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dataset = NarrativeQADataset(llm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dataset = QualityDataset(llm, split='dev')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8YKNTyDsXNIn"
      },
      "outputs": [],
      "source": [
        "reading_agent = ReadingAgent(dataset, llm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_i = 2\n",
        "results = [ChunkInfo(**ci) for ci in read_json(os.path.join(dataset.data_dir, f'index_wg_2_{test_i}.json'))]\n",
        "relation_graph = longdoc.build_relation_graph(results)\n",
        "pages = [ci.passage for ci in results]\n",
        "questions, answers = dataset.get_questions_and_answers(dataset.data[test_i])\n",
        "questions = [q.splitlines()[0] for q in questions]\n",
        "questions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for ci in results:\n",
        "    print(len(gritlm.tokenizer(ci.passage)['input_ids']))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Index passages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "paragraphs = ['\\n'.join(p) for p in read_json(os.path.join(dataset.data_dir, f'pages_{1}.json'))]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Eval"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "results[11].print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "results[11].prev_summaries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(results[11].recap_str)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Retrieval"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "qid = 8\n",
        "print(questions[qid])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Eval"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Contriever"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Query Encode With Note, Doc Encode Without Note"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "ent_candidates = longdoc.collect_entities_from_text(questions[qid])\n",
        "prev_ent_descriptions, prev_relation_descriptions = longdoc.retrieve_descriptions(results, relation_graph, ent_candidates, 1, 2)\n",
        "q_info = ChunkInfo(len(results), questions[qid], prev_ent_descriptions=prev_ent_descriptions, prev_relation_descriptions=prev_relation_descriptions)\n",
        "recap_str = f'''Recap:\\n{q_info.recap_str}\\n\\nQuery:\\n'''\n",
        "full_input = recap_str + questions[qid]\n",
        "print(len(retriever.retriever_tokenizer(full_input)['input_ids']))\n",
        "\n",
        "q_embedding = retriever.embed_paragraphs([full_input], normalize=False, complete_return=True)\n",
        "page_embeddings = retriever.embed_paragraphs(pages, normalize=False, complete_return=True)\n",
        "c_retriever_tokenizer = retriever.retriever_tokenizer\n",
        "c_q_input_ids, c_q_emb, c_q_lhs = hidden_states_wo_instruction(q_embedding.input_ids.copy(), q_embedding.last_hidden_states.copy(), q_embedding.attention_mask.copy(), c_retriever_tokenizer([recap_str])['attention_mask'], True)\n",
        "c_p_input_ids, c_p_emb, c_p_lhs = hidden_states_wo_instruction(page_embeddings.input_ids.copy(), page_embeddings.last_hidden_states.copy(), page_embeddings.attention_mask.copy(), c_retriever_tokenizer([''])['attention_mask'], True)\n",
        "c_pids, c_scores = retriever.dense_retrieval(c_q_emb, c_p_emb, None, normalize=False, return_score=True)\n",
        "q_spans = word_split(c_q_input_ids[0], c_retriever_tokenizer, False, True)\n",
        "query_indicatiors(c_retriever_tokenizer, questions[qid], pages, c_q_lhs[0], c_q_input_ids[0], c_p_lhs, c_p_input_ids, c_pids, c_scores, q_spans=q_spans)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Query Encode Without Note, Doc Encode Without Note"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "recap_str = ''\n",
        "full_input = recap_str + questions[qid]\n",
        "print(len(retriever.retriever_tokenizer(full_input)['input_ids']))\n",
        "\n",
        "q_embedding = retriever.embed_paragraphs([full_input], normalize=False, complete_return=True)\n",
        "page_embeddings = retriever.embed_paragraphs(pages, normalize=False, complete_return=True)\n",
        "c_retriever_tokenizer = retriever.retriever_tokenizer\n",
        "c_q_input_ids, c_q_emb, c_q_lhs = hidden_states_wo_instruction(q_embedding.input_ids.copy(), q_embedding.last_hidden_states.copy(), q_embedding.attention_mask.copy(), c_retriever_tokenizer([recap_str])['attention_mask'], True)\n",
        "c_p_input_ids, c_p_emb, c_p_lhs = hidden_states_wo_instruction(page_embeddings.input_ids.copy(), page_embeddings.last_hidden_states.copy(), page_embeddings.attention_mask.copy(), c_retriever_tokenizer([''])['attention_mask'], True)\n",
        "c_pids, c_scores = retriever.dense_retrieval(c_q_emb, c_p_emb, None, normalize=False, return_score=True)\n",
        "q_spans = word_split(c_q_input_ids[0], c_retriever_tokenizer, False, True)\n",
        "query_indicatiors(c_retriever_tokenizer, questions[qid], pages, c_q_lhs[0], c_q_input_ids[0], c_p_lhs, c_p_input_ids, c_pids, c_scores)#, q_spans=q_spans)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### GritLM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Query Encode With Note, Doc Encode With Note"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "ent_candidates = longdoc.collect_entities_from_text(questions[qid])\n",
        "prev_ent_descriptions, prev_relation_descriptions = longdoc.retrieve_descriptions(results, relation_graph, ent_candidates, 4, True)\n",
        "q_info = ChunkInfo(len(results), questions[qid], prev_ent_descriptions=prev_ent_descriptions, prev_relation_descriptions=prev_relation_descriptions)\n",
        "g_q_emb, g_q_input_ids, g_q_lhs = gritlm.encode([questions[qid]], max_length=8192, instructions=[LongDocPrompt.embed_w_note(q_info.recap_str, 'query')])\n",
        "\n",
        "g_p_emb, g_p_input_ids, g_p_lhs = gritlm.encode(pages, batch_size=5, max_length=8192, instructions=[LongDocPrompt.embed_w_note(ci.recap_str, 'passage') for ci in results])\n",
        "g_retriever_tokenizer = gritlm.tokenizer\n",
        "q_spans = word_split(g_q_input_ids[0], g_retriever_tokenizer)\n",
        "g_pids, g_scores = retriever.dense_retrieval(g_q_emb, g_p_emb, None, normalize=False, return_score=True)\n",
        "query_indicatiors(g_retriever_tokenizer, questions[qid], pages, g_q_lhs[0], g_q_input_ids[0], g_p_lhs, g_p_input_ids, g_pids, g_scores)#, q_spans=q_spans)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Query Encode Without Note, Doc Encode With Note"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "g_q_emb, g_q_input_ids, g_q_lhs = gritlm.encode([questions[qid]])#, instructions=[\"Retrieve relevant passages from a story to answer a given question.\"])\n",
        "\n",
        "g_p_emb, g_p_input_ids, g_p_lhs = gritlm.encode(pages, batch_size=5, max_length=8192, instructions=[LongDocPrompt.embed_w_note(ci.recap_str, 'passage') for ci in results])\n",
        "g_retriever_tokenizer = gritlm.tokenizer\n",
        "q_spans = word_split(g_q_input_ids[0], g_retriever_tokenizer)\n",
        "g_pids, g_scores = retriever.dense_retrieval(g_q_emb, g_p_emb, None, normalize=False, return_score=True)\n",
        "query_indicatiors(g_retriever_tokenizer, questions[qid], pages, g_q_lhs[0], g_q_input_ids[0], g_p_lhs, g_p_input_ids, g_pids, g_scores)#, q_spans=q_spans)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Query Encode With Note, Doc Encode Without Note"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "ent_candidates = longdoc.collect_entities_from_text(questions[qid])\n",
        "prev_ent_descriptions, prev_relation_descriptions = longdoc.retrieve_descriptions(results, relation_graph, ent_candidates, 1, 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "prev_ent_descriptions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "prev_relation_descriptions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "ent_candidates = longdoc.collect_entities_from_text(questions[qid])\n",
        "prev_ent_descriptions, prev_relation_descriptions = longdoc.retrieve_descriptions(results, relation_graph, ent_candidates, 1, 2)\n",
        "q_info = ChunkInfo(len(results), questions[qid], prev_ent_descriptions=prev_ent_descriptions, prev_relation_descriptions=prev_relation_descriptions)\n",
        "instruction = gritlm.gritlm_instruction('Use the recap context to help you understand the query and retrieve relevant passages from a story to answer the query.')\n",
        "recap_str = f'''{instruction}\\nRecap:\\n{q_info.recap_str}\\n\\nQuery:\\n'''\n",
        "print(len(gritlm.tokenizer(recap_str + questions[qid])['input_ids']))\n",
        "g_q_emb, g_q_input_ids, g_q_lhs = gritlm.encode([questions[qid]], max_length=8192, instructions=[recap_str])\n",
        "\n",
        "g_p_emb, g_p_input_ids, g_p_lhs = gritlm.encode(pages, max_length=8192)\n",
        "g_retriever_tokenizer = gritlm.tokenizer\n",
        "q_spans = word_split(g_q_input_ids[0], g_retriever_tokenizer)\n",
        "g_pids, g_scores = retriever.dense_retrieval(g_q_emb, g_p_emb, None, normalize=False, return_score=True)\n",
        "query_indicatiors(g_retriever_tokenizer, questions[qid], pages, g_q_lhs[0], g_q_input_ids[0], g_p_lhs, g_p_input_ids, g_pids, g_scores, q_spans=q_spans)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "important_page_tokens(g_retriever_tokenizer, questions[qid], pages, g_q_lhs[0], g_q_input_ids[0], g_q_emb[0], g_p_lhs, g_p_input_ids, g_pids, g_scores)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Query Encode Without Note, Doc Encode Without Note"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "g_q_emb, g_q_input_ids, g_q_lhs = gritlm.encode([questions[qid]], instructions=[gritlm.gritlm_instruction(\"Retrieve relevant passages from a story to answer a given question.\")])\n",
        "\n",
        "g_p_emb, g_p_input_ids, g_p_lhs = gritlm.encode(pages, max_length=8192)\n",
        "g_retriever_tokenizer = gritlm.tokenizer\n",
        "q_spans = word_split(g_q_input_ids[0], g_retriever_tokenizer)\n",
        "g_pids, g_scores = retriever.dense_retrieval(g_q_emb, g_p_emb, None, normalize=False, return_score=True)\n",
        "query_indicatiors(g_retriever_tokenizer, questions[qid], pages, g_q_lhs[0], g_q_input_ids[0], g_p_lhs, g_p_input_ids, g_pids, g_scores, q_spans=q_spans)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Test Code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "results[11].print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%matplotlib widget\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "from matplotlib.widgets import Cursor\n",
        "\n",
        "# Fixing random state for reproducibility\n",
        "np.random.seed(19680801)\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(8, 6))\n",
        "\n",
        "x, y = 4*(np.random.rand(2, 100) - .5)\n",
        "ax.plot(x, y, 'o')\n",
        "ax.set_xlim(-2, 2)\n",
        "ax.set_ylim(-2, 2)\n",
        "\n",
        "# Set useblit=True on most backends for enhanced performance.\n",
        "cursor = Cursor(ax, useblit=True, color='red', linewidth=2)\n",
        "\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
