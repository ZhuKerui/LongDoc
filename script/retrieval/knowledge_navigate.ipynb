{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MYOnCMh83ZRE"
      },
      "outputs": [],
      "source": [
        "from tqdm.notebook import tqdm\n",
        "from nltk import sent_tokenize\n",
        "from transformers import AutoTokenizer\n",
        "import sys\n",
        "import seaborn as sb\n",
        "sys.path.append('../..')\n",
        "\n",
        "from src import *\n",
        "from src.test_utils import *\n",
        "\n",
        "# torch.backends.cuda.enable_mem_efficient_sdp(False)\n",
        "# torch.backends.cuda.enable_flash_sdp(False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# gritlm = GritLM(\"GritLM/GritLM-7B\", device_map=\"cuda:2\", torch_dtype=\"auto\")\n",
        "retriever = Retriever(device='cpu', syn_dist=0.1)\n",
        "doc_split = DocSplit(retriever.retriever_tokenizer)\n",
        "# llm = LLM()\n",
        "# llm = 'mistralai/Mistral-7B-Instruct-v0.2'\n",
        "llm = None\n",
        "longdoc = LongDoc(retriever, llm)\n",
        "# dataset = NarrativeQADataset(llm)\n",
        "dataset = QualityDataset(llm, split='dev')\n",
        "# reading_agent = ReadingAgent(dataset, llm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_i = 2\n",
        "sample = dataset.data[test_i]\n",
        "questions, answers = dataset.get_questions_and_answers(sample)\n",
        "article = dataset.get_article(sample)\n",
        "questions = [q.splitlines()[0] for q in questions]\n",
        "questions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Index passages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "paragraphs = read_json(os.path.join(dataset.data_dir, f'pages_{2}.json'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Eval"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "results[11].print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "results[11].prev_summaries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(results[11].recap_str)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Retrieval"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "qid = 5\n",
        "question = questions[qid]\n",
        "print(question)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Eval"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Contriever"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Query Encode With Note, Doc Encode Without Note"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "ent_candidates = longdoc.collect_entities_from_text(questions[qid])\n",
        "prev_ent_descriptions, prev_relation_descriptions = longdoc.retrieve_descriptions(results, relation_graph, ent_candidates, 1, 2)\n",
        "q_info = ChunkInfo(len(results), questions[qid], prev_ent_descriptions=prev_ent_descriptions, prev_relation_descriptions=prev_relation_descriptions)\n",
        "recap_str = f'''Recap:\\n{q_info.recap_str}\\n\\nQuery:\\n'''\n",
        "full_input = recap_str + questions[qid]\n",
        "print(len(retriever.retriever_tokenizer(full_input)['input_ids']))\n",
        "\n",
        "q_embedding = retriever.embed_paragraphs([full_input], normalize=False, complete_return=True)\n",
        "page_embeddings = retriever.embed_paragraphs(pages, normalize=False, complete_return=True)\n",
        "c_retriever_tokenizer = retriever.retriever_tokenizer\n",
        "c_q_input_ids, c_q_emb, c_q_lhs = hidden_states_wo_instruction(q_embedding.input_ids.copy(), q_embedding.last_hidden_states.copy(), q_embedding.attention_mask.copy(), c_retriever_tokenizer([recap_str])['attention_mask'], True)\n",
        "c_p_input_ids, c_p_emb, c_p_lhs = hidden_states_wo_instruction(page_embeddings.input_ids.copy(), page_embeddings.last_hidden_states.copy(), page_embeddings.attention_mask.copy(), c_retriever_tokenizer([''])['attention_mask'], True)\n",
        "c_pids, c_scores = retriever.dense_retrieval(c_q_emb, c_p_emb, None, normalize=False, return_score=True)\n",
        "q_spans = word_split(c_q_input_ids[0], c_retriever_tokenizer, False, True)\n",
        "query_indicatiors(c_retriever_tokenizer, questions[qid], pages, c_q_lhs[0], c_q_input_ids[0], c_p_lhs, c_p_input_ids, c_pids, c_scores, q_spans=q_spans)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Query Encode Without Note, Doc Encode Without Note"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "recap_str = ''\n",
        "full_input = recap_str + questions[qid]\n",
        "print(len(retriever.retriever_tokenizer(full_input)['input_ids']))\n",
        "\n",
        "q_embedding = retriever.embed_paragraphs([full_input], normalize=False, complete_return=True)\n",
        "page_embeddings = retriever.embed_paragraphs(pages, normalize=False, complete_return=True)\n",
        "c_retriever_tokenizer = retriever.retriever_tokenizer\n",
        "c_q_input_ids, c_q_emb, c_q_lhs = hidden_states_wo_instruction(q_embedding.input_ids.copy(), q_embedding.last_hidden_states.copy(), q_embedding.attention_mask.copy(), c_retriever_tokenizer([recap_str])['attention_mask'], True)\n",
        "c_p_input_ids, c_p_emb, c_p_lhs = hidden_states_wo_instruction(page_embeddings.input_ids.copy(), page_embeddings.last_hidden_states.copy(), page_embeddings.attention_mask.copy(), c_retriever_tokenizer([''])['attention_mask'], True)\n",
        "c_pids, c_scores = retriever.dense_retrieval(c_q_emb, c_p_emb, None, normalize=False, return_score=True)\n",
        "q_spans = word_split(c_q_input_ids[0], c_retriever_tokenizer, False, True)\n",
        "query_indicatiors(c_retriever_tokenizer, questions[qid], pages, c_q_lhs[0], c_q_input_ids[0], c_p_lhs, c_p_input_ids, c_pids, c_scores)#, q_spans=q_spans)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### GritLM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Query Encode With Note, Doc Encode With Note"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "ent_candidates = longdoc.collect_entities_from_text(questions[qid])\n",
        "prev_ent_descriptions, prev_relation_descriptions = longdoc.retrieve_descriptions(results, relation_graph, ent_candidates, 4, True)\n",
        "q_info = ChunkInfo(len(results), questions[qid], prev_ent_descriptions=prev_ent_descriptions, prev_relation_descriptions=prev_relation_descriptions)\n",
        "g_q_emb, g_q_input_ids, g_q_lhs = gritlm.encode([questions[qid]], max_length=8192, instructions=[LongDocPrompt.embed_w_note(q_info.recap_str, 'query')])\n",
        "\n",
        "g_p_emb, g_p_input_ids, g_p_lhs = gritlm.encode(pages, batch_size=5, max_length=8192, instructions=[LongDocPrompt.embed_w_note(ci.recap_str, 'passage') for ci in results])\n",
        "g_retriever_tokenizer = gritlm.tokenizer\n",
        "q_spans = word_split(g_q_input_ids[0], g_retriever_tokenizer)\n",
        "g_pids, g_scores = retriever.dense_retrieval(g_q_emb, g_p_emb, None, normalize=False, return_score=True)\n",
        "query_indicatiors(g_retriever_tokenizer, questions[qid], pages, g_q_lhs[0], g_q_input_ids[0], g_p_lhs, g_p_input_ids, g_pids, g_scores)#, q_spans=q_spans)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Query Encode Without Note, Doc Encode With Note"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "g_q_emb, g_q_input_ids, g_q_lhs = gritlm.encode([questions[qid]])#, instructions=[\"Retrieve relevant passages from a story to answer a given question.\"])\n",
        "\n",
        "g_p_emb, g_p_input_ids, g_p_lhs = gritlm.encode(pages, batch_size=5, max_length=8192, instructions=[LongDocPrompt.embed_w_note(ci.recap_str, 'passage') for ci in results])\n",
        "g_retriever_tokenizer = gritlm.tokenizer\n",
        "q_spans = word_split(g_q_input_ids[0], g_retriever_tokenizer)\n",
        "g_pids, g_scores = retriever.dense_retrieval(g_q_emb, g_p_emb, None, normalize=False, return_score=True)\n",
        "query_indicatiors(g_retriever_tokenizer, questions[qid], pages, g_q_lhs[0], g_q_input_ids[0], g_p_lhs, g_p_input_ids, g_pids, g_scores)#, q_spans=q_spans)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Query Encode With Note, Doc Encode Without Note"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "ent_candidates = longdoc.collect_entities_from_text(questions[qid])\n",
        "prev_ent_descriptions, prev_relation_descriptions = longdoc.retrieve_descriptions(results, relation_graph, ent_candidates, 1, 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "prev_ent_descriptions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "prev_relation_descriptions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "ent_candidates = longdoc.collect_entities_from_text(questions[qid])\n",
        "prev_ent_descriptions, prev_relation_descriptions = longdoc.retrieve_descriptions(results, relation_graph, ent_candidates, 1, 2)\n",
        "q_info = ChunkInfo(len(results), questions[qid], prev_ent_descriptions=prev_ent_descriptions, prev_relation_descriptions=prev_relation_descriptions)\n",
        "instruction = gritlm.gritlm_instruction('Use the recap context to help you understand the query and retrieve relevant passages from a story to answer the query.')\n",
        "recap_str = f'''{instruction}\\nRecap:\\n{q_info.recap_str}\\n\\nQuery:\\n'''\n",
        "print(len(gritlm.tokenizer(recap_str + questions[qid])['input_ids']))\n",
        "g_q_emb, g_q_input_ids, g_q_lhs = gritlm.encode([questions[qid]], max_length=8192, instructions=[recap_str])\n",
        "\n",
        "g_p_emb, g_p_input_ids, g_p_lhs = gritlm.encode(pages, max_length=8192)\n",
        "g_retriever_tokenizer = gritlm.tokenizer\n",
        "q_spans = word_split(g_q_input_ids[0], g_retriever_tokenizer)\n",
        "g_pids, g_scores = retriever.dense_retrieval(g_q_emb, g_p_emb, None, normalize=False, return_score=True)\n",
        "query_indicatiors(g_retriever_tokenizer, questions[qid], pages, g_q_lhs[0], g_q_input_ids[0], g_p_lhs, g_p_input_ids, g_pids, g_scores, q_spans=q_spans)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "important_page_tokens(g_retriever_tokenizer, questions[qid], pages, g_q_lhs[0], g_q_input_ids[0], g_q_emb[0], g_p_lhs, g_p_input_ids, g_pids, g_scores)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Query Encode Without Note, Doc Encode Without Note"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "g_q_emb, g_q_input_ids, g_q_lhs = gritlm.encode([questions[qid]], instructions=[gritlm.gritlm_instruction(\"Retrieve relevant passages from a story to answer a given question.\")])\n",
        "\n",
        "g_p_emb, g_p_input_ids, g_p_lhs = gritlm.encode(pages, max_length=8192)\n",
        "g_retriever_tokenizer = gritlm.tokenizer\n",
        "q_spans = word_split(g_q_input_ids[0], g_retriever_tokenizer)\n",
        "g_pids, g_scores = retriever.dense_retrieval(g_q_emb, g_p_emb, None, normalize=False, return_score=True)\n",
        "query_indicatiors(g_retriever_tokenizer, questions[qid], pages, g_q_lhs[0], g_q_input_ids[0], g_p_lhs, g_p_input_ids, g_pids, g_scores, q_spans=q_spans)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Test Code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Encode questions\n",
        "queries = [\"the Skipper\", \"the new cook\", \"advice\", \"avoiding\", \"Vesta\", \"avoiding Vesta\"]\n",
        "q_emb = retriever.embed_paragraphs(queries, normalize=True, complete_return=True)\n",
        "q_strs, q_lhs = [], []\n",
        "for qid in range(len(q_emb.embeddings)):\n",
        "    word_spans = word_split(q_emb.input_ids[qid], retriever.retriever_tokenizer, retriever.retriever_tokenizer.bos_token, retriever.retriever_tokenizer.eos_token)\n",
        "    temp_q_strs, temp_q_lhs = merge_words_and_embeddings(retriever.retriever_tokenizer, q_emb.input_ids[qid], q_emb.last_hidden_states[qid], word_spans, False)\n",
        "    q_strs.append(temp_q_strs)\n",
        "    q_lhs.append(temp_q_lhs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Encode pages\n",
        "pages = doc_split.split_paragraphs(article, 512 // 5)\n",
        "p_emb = retriever.embed_paragraphs(pages, normalize=True, complete_return=True)\n",
        "p_strs, p_lhs = [], []\n",
        "for pid in range(len(p_emb.embeddings)):\n",
        "    word_spans = sent_split(p_emb.input_ids[pid], retriever.retriever_tokenizer, retriever.retriever_tokenizer.bos_token, retriever.retriever_tokenizer.eos_token)\n",
        "    temp_p_strs, temp_p_lhs = merge_words_and_embeddings(retriever.retriever_tokenizer, p_emb.input_ids[pid], p_emb.last_hidden_states[pid], word_spans, False)\n",
        "    p_strs.append(temp_p_strs)\n",
        "    p_lhs.append(temp_p_lhs)\n",
        "tsne_plot(p_emb.embeddings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "score_mat = q_emb.embeddings @ p_emb.embeddings.T\n",
        "fig, ax = plt.subplots(figsize=(score_mat.shape[1], score_mat.shape[0]))\n",
        "sb.heatmap(score_mat, xticklabels=range(len(pages)), yticklabels=queries, annot=True, ax=ax)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "score_mat = q_emb.embeddings @ p_emb.embeddings.T\n",
        "score_mat_min = score_mat.min(1, keepdims=True)\n",
        "score_mat_max = score_mat.max(1, keepdims=True)\n",
        "score_mat = (score_mat - score_mat_min) / (score_mat_max - score_mat_min)\n",
        "fig, ax = plt.subplots(figsize=(score_mat.shape[1], score_mat.shape[0]))\n",
        "sb.heatmap(score_mat, xticklabels=range(len(pages)), yticklabels=queries, annot=True, ax=ax)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "score_mat_max.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def slide_encode(pages:List[str], retriever:Retriever, window_size:int=3):\n",
        "    padded_pages = ([''] * (window_size-1)) + pages + ([''] * (window_size-1))\n",
        "    p_input_ids = [retriever.retriever_tokenizer(p)['input_ids'][1:-1] for p in pages]\n",
        "    batched_pids = [[pid_ - window_size + 1 for pid_ in range(pid, pid + window_size) if padded_pages[pid_]] for pid in range(len(padded_pages) - window_size + 1)]\n",
        "    reformed_pages = [' '.join([pages[pid] for pid in pids]) for pids in batched_pids]\n",
        "    p_emb = retriever.embed_paragraphs(reformed_pages, complete_return=True)\n",
        "    pid2embs = [[] for p in pages]\n",
        "    pid2lhs = [[] for p in pages]\n",
        "    for temp_input_ids, temp_lhs, pids in zip(p_emb.input_ids, p_emb.last_hidden_states, batched_pids):\n",
        "        p_start = 1\n",
        "        for pid in pids:\n",
        "            p_len = len(p_input_ids[pid])\n",
        "            p_end = p_start + p_len\n",
        "            if temp_input_ids[p_start:p_end].tolist() != p_input_ids[pid]: # align check\n",
        "                print('fail')\n",
        "                break\n",
        "            pid2lhs[pid].append(temp_lhs[p_start:p_end])\n",
        "            pid2embs[pid].append(temp_lhs[p_start:p_end].mean(0))\n",
        "            p_start = p_end\n",
        "    pid2embs = [np.vstack(embs) for embs in pid2embs]\n",
        "    pid2lhs = [np.concatenate(np.expand_dims(lhs, 0), 0) for lhs in pid2lhs]\n",
        "    return p_input_ids, pid2embs, pid2lhs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def kernel_conv(score_mat:np.ndarray, kernel:np.ndarray):\n",
        "    padded_score_mat = \n",
        "    y_shape, x_shape = kernel.shape\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print_input_ids(p_strs, range(57, 60))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print_input_ids(p_strs, [57])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print_pages(pages, range(80, 85))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Question-page token-sent matching\n",
        "xid, yid = 1, 0\n",
        "x_start, x_end = 0, None\n",
        "y_start, y_end = 0, None\n",
        "\n",
        "score_mat = (q_lhs[yid] / np.expand_dims(np.linalg.norm(q_lhs[yid], axis=1), axis=1)) @ (p_lhs[xid] / np.expand_dims(np.linalg.norm(p_lhs[xid], axis=1), axis=1)).T\n",
        "score_mat = score_mat[y_start:y_end, x_start:x_end]\n",
        "fig, ax = plt.subplots(figsize=(score_mat.shape[1], score_mat.shape[0]))\n",
        "sb.heatmap(score_mat, xticklabels=p_strs[xid][x_start:x_end], yticklabels=q_strs[yid][y_start:y_end], annot=True, ax=ax)\n",
        "fig.savefig('qp.pdf')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Page-page matching\n",
        "score_mat = p_emb.embeddings @ p_emb.embeddings.T\n",
        "fig, ax = plt.subplots(figsize=(score_mat.shape[1], score_mat.shape[0]))\n",
        "sb.heatmap(score_mat, xticklabels=range(score_mat.shape[1]), yticklabels=range(score_mat.shape[0]), annot=True, ax=ax)\n",
        "fig.savefig('pp_all.pdf')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Page-page sent-sent matching\n",
        "xid, yid = 9, 10\n",
        "x_start, x_end = 0, None\n",
        "y_start, y_end = 0, None\n",
        "\n",
        "score_mat = (p_lhs[yid] / np.expand_dims(np.linalg.norm(p_lhs[yid], axis=1), axis=1)) @ (p_lhs[xid] / np.expand_dims(np.linalg.norm(p_lhs[xid], axis=1), axis=1)).T\n",
        "score_mat = score_mat[y_start:y_end, x_start:x_end]\n",
        "fig, ax = plt.subplots(figsize=(score_mat.shape[1]/2, score_mat.shape[0]/2))\n",
        "sb.heatmap(score_mat, xticklabels=range(x_start, score_mat.shape[1] + x_start), yticklabels=range(y_start, score_mat.shape[0] + y_start), annot=True, ax=ax)\n",
        "fig.savefig('pp.pdf')\n",
        "print('x:\\n', pages[xid])\n",
        "print('y:\\n', pages[yid])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_x_sent = 2\n",
        "test_y_sent = 2\n",
        "print(score_mat[test_y_sent, test_x_sent])\n",
        "print(p_strs[xid][test_x_sent])\n",
        "print(p_strs[yid][test_y_sent])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "p_input_ids, pid2embs_3, pid2lhs_3 = slide_encode(pages, retriever, 3)\n",
        "# pid2embs_5 = slide_encode(pages, retriever, 5)\n",
        "p_input_ids, pid2embs_1, pid2lhs_1 = slide_encode(pages, retriever, 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# p_weight_5 = np.array([[0., 0., 0.3, 0., 0.]])\n",
        "p_weight_3 = np.array([0., 0., 0.])\n",
        "p_weight_1 = np.array([1.0])\n",
        "# p_embeddings = np.vstack([(p_weight_5 @ embs_5)[0] + (p_weight_1 @ embs_1)[0] for embs_5, embs_1 in zip(pid2embs_5, pid2embs_1)])\n",
        "p_embeddings = np.vstack([(np.expand_dims(p_weight_3, 0) @ embs_3)[0] + (np.expand_dims(p_weight_1, 0) @ embs_1)[0] for embs_3, embs_1 in zip(pid2embs_3, pid2embs_1)])\n",
        "p_lhs = [(lhs_3 * np.expand_dims(p_weight_3, (1,2))).mean(0) + (lhs_1 * np.expand_dims(p_weight_1, (1,2))).mean(0) for lhs_3, lhs_1 in zip(pid2lhs_3, pid2lhs_1)]\n",
        "tsne_plot(p_embeddings, 4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# p_weight_5 = np.array([[0., 0., 0.3, 0., 0.]])\n",
        "p_weight_3 = np.array([0., 0.5, 0.])\n",
        "p_weight_1 = np.array([0.5])\n",
        "# p_embeddings = np.vstack([(p_weight_5 @ embs_5)[0] + (p_weight_1 @ embs_1)[0] for embs_5, embs_1 in zip(pid2embs_5, pid2embs_1)])\n",
        "p_embeddings = np.vstack([(np.expand_dims(p_weight_3, 0) @ embs_3)[0] + (np.expand_dims(p_weight_1, 0) @ embs_1)[0] for embs_3, embs_1 in zip(pid2embs_3, pid2embs_1)])\n",
        "p_lhs = [(lhs_3 * np.expand_dims(p_weight_3, (1,2))).mean(0) + (lhs_1 * np.expand_dims(p_weight_1, (1,2))).mean(0) for lhs_3, lhs_1 in zip(pid2lhs_3, pid2lhs_1)]\n",
        "tsne_plot(p_embeddings, 4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Page-page matching\n",
        "normalized_p_embeddings = p_embeddings / np.expand_dims(np.linalg.norm(p_embeddings, axis=1), 1)\n",
        "score_mat = normalized_p_embeddings @ normalized_p_embeddings.T\n",
        "fig, ax = plt.subplots(figsize=(score_mat.shape[1], score_mat.shape[0]))\n",
        "sb.heatmap(score_mat, xticklabels=range(score_mat.shape[1]), yticklabels=range(score_mat.shape[0]), annot=True, ax=ax)\n",
        "fig.savefig('pp_all.pdf')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "score_mat[60, 20]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print_pages(pages, range(60, 70))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Page-page sent-sent matching\n",
        "xid, yid = 60, 20\n",
        "\n",
        "x_word_spans = sent_split(p_input_ids[xid], retriever.retriever_tokenizer)\n",
        "y_word_spans = sent_split(p_input_ids[yid], retriever.retriever_tokenizer)\n",
        "plot_score_matrix(retriever.retriever_tokenizer, p_input_ids[xid], p_lhs[xid], x_word_spans, p_input_ids[yid], p_lhs[yid], y_word_spans, False, False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def norm(x):\n",
        "    return x / np.linalg.norm(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "norm(p_lhs[yid][0:21].mean(0)).dot(norm(p_lhs[xid][33:77].mean(0)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Page-page sent-sent matching\n",
        "xid, yid = 60, 20\n",
        "# x_start, x_end = 33, 77\n",
        "# y_start, y_end = 0, 21\n",
        "\n",
        "x_start, x_end = 0, None\n",
        "y_start, y_end = 0, None\n",
        "\n",
        "x_word_spans = word_split(p_input_ids[xid], retriever.retriever_tokenizer)\n",
        "x_strs, x_lhs = merge_words_and_embeddings(retriever.retriever_tokenizer, p_input_ids[xid], p_lhs[xid], [], False, True)\n",
        "y_word_spans = word_split(p_input_ids[yid], retriever.retriever_tokenizer)\n",
        "y_strs, y_lhs = merge_words_and_embeddings(retriever.retriever_tokenizer, p_input_ids[yid], p_lhs[yid], [], False, True)\n",
        "\n",
        "score_mat = (y_lhs) @ (x_lhs).T\n",
        "score_mat = score_mat[y_start:y_end, x_start:x_end]\n",
        "fig, ax = plt.subplots(figsize=(score_mat.shape[1], score_mat.shape[0]))\n",
        "sb.heatmap(score_mat, xticklabels=x_strs[x_start:score_mat.shape[1] + x_start], yticklabels=y_strs[y_start:score_mat.shape[0] + y_start], annot=True, ax=ax)\n",
        "fig.savefig('pp.pdf')\n",
        "print('x:\\n', x_strs)\n",
        "print('y:\\n', y_strs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "p_lhs = [np.array(pid2embs[pid]).mean(0) for pid in range(len(pid2embs))]\n",
        "p_embeddings = np.array([lhs.mean(0) for lhs in p_lhs])\n",
        "p_norm = np.linalg.norm(p_embeddings, axis=1)\n",
        "p_embeddings = p_embeddings / np.expand_dims(p_norm, 1)\n",
        "p_lhs = [lhs / n for lhs, n in zip(p_lhs, p_norm)]\n",
        "pids, scores = retriever.dense_retrieval(q_emb.embeddings, p_embeddings, None, normalize=False, return_score=True)\n",
        "pids"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "query_distribution(retriever.retriever_tokenizer, q_emb.last_hidden_states[0], q_emb.input_ids[0], p_lhs, 5, q_spans=word_spans[3:-1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "query_indicatiors(retriever.retriever_tokenizer, question, [f'passage: {p}' for p in pages], q_emb.last_hidden_states[0], q_emb.input_ids[0], p_lhs, p_input_ids, pids[:10], scores, 5, q_spans=word_spans)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "p_emb = retriever.embed_paragraphs([f'passage: {p}' for p in pages], normalize=True, complete_return=True)\n",
        "pids, scores = retriever.dense_retrieval(q_emb.embeddings, p_emb.embeddings, None, normalize=False, return_score=True)\n",
        "pids"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "query_indicatiors(retriever.retriever_tokenizer, question, [f'passage: {p}' for p in pages], q_emb.last_hidden_states[0], q_emb.input_ids[0], p_emb.last_hidden_states, p_emb.input_ids, pids, scores, q_spans=word_spans)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%matplotlib widget\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "from matplotlib.widgets import Cursor\n",
        "\n",
        "# Fixing random state for reproducibility\n",
        "np.random.seed(19680801)\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(8, 6))\n",
        "\n",
        "x, y = 4*(np.random.rand(2, 100) - .5)\n",
        "ax.plot(x, y, 'o')\n",
        "ax.set_xlim(-2, 2)\n",
        "ax.set_ylim(-2, 2)\n",
        "\n",
        "# Set useblit=True on most backends for enhanced performance.\n",
        "cursor = Cursor(ax, useblit=True, color='red', linewidth=2)\n",
        "\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
