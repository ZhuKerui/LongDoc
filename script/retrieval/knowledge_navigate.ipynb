{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MYOnCMh83ZRE"
      },
      "outputs": [],
      "source": [
        "import time, datetime, json, os\n",
        "from tqdm.notebook import tqdm\n",
        "from collections import defaultdict, Counter\n",
        "import numpy as np\n",
        "from nltk import sent_tokenize\n",
        "\n",
        "from index_files import LongDoc, write_json, QualityDataset, NarrativeQADataset, ReadingAgent, read_json, read_jsonline, LLM, Retriever"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "retriever = Retriever()\n",
        "llm = LLM()\n",
        "# llm = 'mistralai/Mistral-7B-Instruct-v0.2'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Experiment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dataset = NarrativeQADataset(llm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dataset = QualityDataset(llm, split='dev')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8YKNTyDsXNIn"
      },
      "outputs": [],
      "source": [
        "reading_agent = ReadingAgent(dataset, llm)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Index passages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from typing import List, Tuple, Set, Dict\n",
        "import itertools\n",
        "import networkx as nx\n",
        "from prompt import prompt_shorten_template, prompt_ent_description_template, \\\n",
        "    prompt_relation_description_template, prompt_shorten_w_note_template, \\\n",
        "    prompt_ent_description_w_note_template, prompt_relation_description_w_note_template\n",
        "\n",
        "def match_entities(target_ents:List[str], refer_ents:List[str]):\n",
        "    target_ents_emb = retriever.embed_paragraphs(target_ents, True)\n",
        "    refer_ents_emb = retriever.embed_paragraphs(refer_ents, True)\n",
        "    sim_mat:np.ndarray = np.matmul(target_ents_emb, refer_ents_emb.T)\n",
        "    ent_map:Dict[str, str] = {}\n",
        "    for eid, ent in enumerate(target_ents):\n",
        "        max_idx = sim_mat[eid].argmax()\n",
        "        if sim_mat[eid, max_idx] > 0.8:\n",
        "            ent_map[ent] = refer_ents[max_idx]\n",
        "    return ent_map\n",
        "    \n",
        "def index_text(paragraphs:List[str], context_type:str='novel'):\n",
        "    results = []\n",
        "    test_results = []\n",
        "    for paragraph in tqdm(paragraphs):\n",
        "        \n",
        "        # Extract important entities\n",
        "        list_entity_prompt = f'''Context:\\n\\n{paragraph}\\n\\nAbove is part of a {context_type}. List the important named entities in the above context that are relevant to most of its content. Don't give any explanation. Generate your response in the following format: \"Important entities:\\n1. Entity 1\\n2. Entity 2\\n3. Entity 3\\n...\"'''\n",
        "        chat_response = llm(list_entity_prompt, 5, 0.7)[0]\n",
        "        ent_lists:List[str] = []\n",
        "        ent_cnt = Counter()\n",
        "        for response in chat_response:\n",
        "            i = 1\n",
        "            temp_ents = []\n",
        "            for line in response.splitlines():\n",
        "                if line.startswith(f'{i}. '):\n",
        "                    temp_ents.append(line.split(' ', 1)[1].strip().strip('.'))\n",
        "                    i += 1\n",
        "            ent_lists.append(temp_ents)\n",
        "            ent_cnt.update(temp_ents)\n",
        "        g = nx.Graph()\n",
        "        for list1, list2 in itertools.combinations(ent_lists, 2):\n",
        "            g.add_edges_from(match_entities(list1, list2).items())\n",
        "        ent_cluster:Set[str]\n",
        "        rep_cnt = {}\n",
        "        for ent_cluster in nx.connected_components(g):\n",
        "            cnts = [(ent_cnt[ent], ent) for ent in ent_cluster]\n",
        "            cnts.sort(key=lambda x: x[0], reverse=True)\n",
        "            rep_cnt[cnts[0][1]] = sum([cnt for cnt, _ in cnts])\n",
        "        important_ents = [rep for rep, cnt in rep_cnt.items() if cnt >= 3]\n",
        "        \n",
        "        # Generate entity description, summary, relation description\n",
        "        important_ents_str = '\\n'.join(important_ents)\n",
        "        prompt_ent_description = prompt_ent_description_template.format(paragraph=paragraph, context_type=context_type, important_ents_str=important_ents_str, important_ents_0=important_ents[0], important_ents_1=important_ents[1])\n",
        "        prompt_shorten = prompt_shorten_template.format(paragraph)\n",
        "        prompt_relation_description = prompt_relation_description_template.format(paragraph=paragraph, context_type=context_type, important_ents_str=important_ents_str)\n",
        "        \n",
        "        ent_description, relation_description, shorten = llm([prompt_ent_description, prompt_relation_description, prompt_shorten])\n",
        "        ent_description, relation_description, shorten = ent_description[0], relation_description[0], shorten[0]\n",
        "        description_dict = {}\n",
        "        for line in ent_description.splitlines():\n",
        "            if line:\n",
        "                ent, description = line.split(': ', 1)\n",
        "                ent = ent.strip()\n",
        "                description = description.strip()\n",
        "                if ent in important_ents:\n",
        "                    description_dict[ent] = description\n",
        "        test_results.append({\n",
        "            'paragraph': paragraph, \n",
        "            'important_ents': important_ents, \n",
        "            'description_dict': description_dict, \n",
        "            'shorten': shorten, \n",
        "            'relation_description': relation_description\n",
        "        })\n",
        "        \n",
        "        if len(results):\n",
        "            r_num = 1\n",
        "            recaps = []\n",
        "            for rid, result in enumerate(results[-r_num:]):\n",
        "                prev_description_dict:Dict[str, str] = result['description_dict']\n",
        "                match_dict = match_entities(important_ents, list(prev_description_dict.keys()))\n",
        "                prev_description = '\\n'.join([f'{ent}: {prev_description_dict[ent]}' for _, ent in match_dict.items()])\n",
        "                recap = f'Passage {rid - r_num}:\\nEntity descriptions:\\n{prev_description}\\nSummary:\\n{result[\"shorten\"]}'\n",
        "                recaps.append(recap)\n",
        "            recap_str = '\\n\\n'.join(recaps)\n",
        "            prompt_ent_description = prompt_ent_description_w_note_template.format(recap=recap_str, paragraph=paragraph, context_type=context_type, important_ents_str=important_ents_str, important_ents_0=important_ents[0], important_ents_1=important_ents[1])\n",
        "            prompt_shorten = prompt_shorten_w_note_template.format(recap_str, paragraph)\n",
        "            prompt_relation_description = prompt_relation_description_w_note_template.format(recap=recap_str, paragraph=paragraph, context_type=context_type, important_ents_str=important_ents_str)\n",
        "            \n",
        "            ent_description, relation_description, shorten = llm([prompt_ent_description, prompt_relation_description, prompt_shorten])\n",
        "            ent_description, relation_description, shorten = ent_description[0], relation_description[0], shorten[0]\n",
        "            description_dict = {}\n",
        "            for line in ent_description.splitlines():\n",
        "                if line:\n",
        "                    ent, description = line.split(': ', 1)\n",
        "                    ent = ent.strip()\n",
        "                    description = description.strip()\n",
        "                    if ent in important_ents:\n",
        "                        description_dict[ent] = description\n",
        "        \n",
        "            results.append({\n",
        "                'paragraph': paragraph, \n",
        "                'important_ents': important_ents, \n",
        "                'description_dict': description_dict, \n",
        "                'shorten': shorten, \n",
        "                'relation_description': relation_description\n",
        "            })\n",
        "        else:\n",
        "            results.append({\n",
        "                'paragraph': paragraph, \n",
        "                'important_ents': important_ents, \n",
        "                'description_dict': description_dict, \n",
        "                'shorten': shorten, \n",
        "                'relation_description': relation_description\n",
        "            })\n",
        "    return test_results, results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "paragraphs = ['\\n'.join(p) for p in read_json(os.path.join(dataset.data_dir, f'pages_{1}.json'))]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_results, results = index_text(paragraphs)\n",
        "write_json('results.json', results)\n",
        "write_json('test_results.json', test_results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "results = read_json('results.json')\n",
        "test_results = read_json('test_results.json')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "results[0].keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_pid = 12\n",
        "# sent_tokenize(results[test_pid]['shorten'])\n",
        "# results[test_pid]['description_dict']\n",
        "print(results[test_pid]['prompt_shorten'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "sent_tokenize(test_results[test_pid]['shorten'])\n",
        "# test_results[test_pid]['description_dict']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(results[test_pid]['paragraph'])"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
