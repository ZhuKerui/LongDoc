{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/keruiz2/miniconda3/envs/dkg/lib/python3.11/site-packages\n"
     ]
    }
   ],
   "source": [
    "from sci_review.framework import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try a range of different questions. Besides extracting information into a taxonomy, I am converting the following datasets into test questions:\n",
    "+ ACLSum (Summarize the Challenge, Approach, and Outcome in the paper)\n",
    "+ SciREX (extract the main results of a scientific article including Dataset, Metric, Task and Method)\n",
    "+ arxivDIGESTables (given a table schema for literature survey and extract targeted values from scientific papers to fill in the table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "02/25/2025 18:31:08 - INFO - \t missing_keys: []\n",
      "02/25/2025 18:31:08 - INFO - \t unexpected_keys: []\n",
      "02/25/2025 18:31:08 - INFO - \t mismatched_keys: []\n",
      "02/25/2025 18:31:08 - INFO - \t error_msgs: []\n",
      "02/25/2025 18:31:08 - INFO - \t Model Parameters: 90.5M, Transformer: 82.1M, Coref head: 8.4M\n"
     ]
    }
   ],
   "source": [
    "with open('../../data/words_alpha.txt') as f:\n",
    "    words_alpha = set(f.read().splitlines())\n",
    "doc_manager = DocManager(word_vocab=words_alpha)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ACLSum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from aclsum_base import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset config\n",
    "split = 'train'\n",
    "\n",
    "load_from_pdf = False\n",
    "# load_from_pdf = True\n",
    "\n",
    "# Retrieval config\n",
    "# retrieval_method = 'rag'\n",
    "# retrieval_method = 'rag_base'\n",
    "retrieval_method = 'gen'\n",
    "# retrieval_method = 'cls'\n",
    "\n",
    "# Chunk config\n",
    "sent_chunk = True\n",
    "max_seq_len = None\n",
    "k = 10\n",
    "# sent_chunk = False\n",
    "# max_seq_len = None\n",
    "# k = 3\n",
    "# sent_chunk = False\n",
    "# max_seq_len = 100\n",
    "# k = 10\n",
    "\n",
    "with jsonlines.open(f'{ACLSUM_DIR}/{split}_dataset.jsonl') as f_in:\n",
    "    aclsum_dataset = [Sample.model_validate(line) for line in f_in]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question Decomposition Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords = [phrase.text for phrase in doc_manager.doc_spacy._.phrases if phrase.rank > 0.04]\n",
    "question = sample.questions['challenge']\n",
    "question_break_down_prompt = f'''Refine the given general information-seeking question about a scientific paper by breaking it down into distinct subtopics, each representing a key aspect of the required information. Ensure each subtopic is concise, addresses a single point that can be explained in one sentence, and is logically connected to others through relevant entity types. Then, for each subtopic, generate three pseudo-sentences, each offering a different way the subtopic might be expressed in the paper. Below is an example of a refined question and its subtopics, along with pseudo-sentences for each subtopic.\n",
    "\n",
    "### Question:\n",
    "What are the key contributions of the paper?\n",
    "\n",
    "### Subtopics:\n",
    "1. **Summary of proposed [Method]**\n",
    "2. **Comparison with existing approaches to [Task]**\n",
    "3. **Performance improvements on [Dataset/Benchmark]**\n",
    "\n",
    "### Pseudo-sentences:\n",
    "\n",
    "1. **Summary of proposed [Method]**\n",
    "    - This paper introduces a novel [Method] for addressing [Task].\n",
    "    - We present [Method], which enhances efficiency in [Task].\n",
    "    - Our approach leverages [Method] to improve performance in [Task].\n",
    "2. **Comparison with existing approaches to [Task]**\n",
    "    - Unlike previous methods, [Method] achieves better generalization in [Task].\n",
    "    - Compared to existing models, [Method] reduces computational cost significantly.\n",
    "    - Our approach differs from prior work by introducing [Key Novel Feature].\n",
    "3. **Performance improvements on [Dataset/Benchmark]**\n",
    "    - Our method achieves state-of-the-art results on [Dataset].\n",
    "    - We report a [X]% improvement in accuracy over previous methods on [Benchmark].\n",
    "    - Experimental results demonstrate superior performance of [Method] on [Dataset].\n",
    "\n",
    "You should follow the format of the example. To assist you in generating subtopics and pseudo-sentences, we provide a list of keywords from the paper as context. Use these keywords to guide your understanding and develop relevant subtopics and pseudo-sentences. Additionally, apply your own knowledge and reasoning to refine the question and enhance your responses.\n",
    "\n",
    "Keywords:\n",
    "{keywords}\n",
    "\n",
    "### Question:\n",
    "{question}'''\n",
    "\n",
    "chat_completion = doc_manager.client.chat.completions.create(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": question_break_down_prompt,\n",
    "        }\n",
    "    ],\n",
    "    model=doc_manager.tool_llm,\n",
    ")\n",
    "content = chat_completion.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_question_breakdown(content:str):\n",
    "    subtopics:dict[str, list[str]] = defaultdict(list[str])\n",
    "    is_subtopic = False\n",
    "    is_pesudo_sentence = False\n",
    "    curr_subtopic = None\n",
    "    for line in content.split('\\n'):\n",
    "        line = line.strip()\n",
    "        if not line:\n",
    "            continue\n",
    "        if not is_subtopic:\n",
    "            if line.startswith('### Subtopics:'):\n",
    "                is_subtopic = True\n",
    "        else:\n",
    "            if line.startswith('### Pseudo-sentences:'):\n",
    "                is_pesudo_sentence = True\n",
    "            elif not is_pesudo_sentence:\n",
    "                subtopics[line]\n",
    "            else:\n",
    "                if line in subtopics:\n",
    "                    curr_subtopic = line\n",
    "                else:\n",
    "                    subtopics[curr_subtopic].append(line.strip('- '))\n",
    "    return {subtopic.replace('*', ''): sentences for subtopic, sentences in subtopics.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subtopics = parse_question_breakdown(content)\n",
    "subtopics.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieval2configs = {\n",
    "    'rag': [\n",
    "        # {\n",
    "        #     'load_from_pdf': False, \n",
    "        #     'sent_chunk': True, \n",
    "        #     'max_seq_len': None, \n",
    "        #     'k': 10\n",
    "        # },\n",
    "        # {\n",
    "        #     'load_from_pdf': False, \n",
    "        #     'sent_chunk': False, \n",
    "        #     'max_seq_len': 100, \n",
    "        #     'k': 10\n",
    "        # }\n",
    "    ],\n",
    "    'gen': [\n",
    "        {\n",
    "            'load_from_pdf': False, \n",
    "            'sent_chunk': True, \n",
    "            'max_seq_len': None, \n",
    "            'k': None\n",
    "        },\n",
    "        # {\n",
    "        #     'load_from_pdf': True, \n",
    "        #     'sent_chunk': True, \n",
    "        #     'max_seq_len': None, \n",
    "        #     'k': None\n",
    "        # }\n",
    "    ]\n",
    "}\n",
    "retrieval2configs['rag_base'] = retrieval2configs['rag']\n",
    "\n",
    "\n",
    "sid = 25\n",
    "split = 'train'\n",
    "question_type = 'challenge'\n",
    "with jsonlines.open(f'{ACLSUM_DIR}/{split}_dataset.jsonl') as f_in:\n",
    "    aclsum_dataset = [Sample.model_validate(line) for line in f_in]\n",
    "\n",
    "sample = aclsum_dataset[sid]\n",
    "test2sents = dict[str, list[str]]()\n",
    "test2process = dict[str, list[dict]]()\n",
    "test2chunks = dict[str, list[str]]()\n",
    "\n",
    "for retrieval_method, retrieval_configs in retrieval2configs.items():\n",
    "    for retrieval_config in retrieval_configs:\n",
    "        load_doc_manager(doc_manager, sample, retrieval_config['load_from_pdf'])\n",
    "        doc_manager.build_chunks(sent_chunk=retrieval_config['sent_chunk'], max_seq_length=retrieval_config['max_seq_len'])\n",
    "        \n",
    "        unique_ngram2sent = get_sent_index([sent.text for section in doc_manager.sections if section.section_nlp_local for sent in section.section_nlp_local.sents])\n",
    "        if retrieval_config['load_from_pdf']:\n",
    "            valid_sent_ids = get_sent_ids([sent for block in sample.doc_strs if block not in ['Abstract', 'Introduction', 'Conclusion'] for sent in spacy_sent_tokenize(doc_manager.nlp, block)], unique_ngram2sent)\n",
    "            if -1 in valid_sent_ids:\n",
    "                print(f'Invalid sent id in sample {sid}, retrieval_config {retrieval_config}, {valid_sent_ids.count(-1)}/{len(valid_sent_ids)}')\n",
    "                valid_sent_ids = [sent_id for sent_id in valid_sent_ids if sent_id > -1]\n",
    "            valid_sent_ids = set(valid_sent_ids)\n",
    "        else:\n",
    "            valid_sent_ids = set(range(max(sent_id for ngram, (sent_id, sent) in unique_ngram2sent.items()) + 1))\n",
    "        \n",
    "        process, retrieved_sents = get_sents_and_process(\n",
    "            doc_manager=doc_manager,\n",
    "            retrieval_method=retrieval_method,\n",
    "            split=split,\n",
    "            sid=sid,\n",
    "            question_type=question_type,\n",
    "            is_temp=True,\n",
    "            **retrieval_config\n",
    "        )\n",
    "        valid_retrieved_sents = [sent for sent_id, sent in zip(get_sent_ids(retrieved_sents, unique_ngram2sent), retrieved_sents) if sent_id in valid_sent_ids]\n",
    "        test_name = f\"{retrieval_method}_{retrieval_config['load_from_pdf']}_{retrieval_config['sent_chunk']}_{retrieval_config['max_seq_len']}\"\n",
    "        test2sents[test_name] = valid_retrieved_sents\n",
    "        test2process[test_name] = process\n",
    "        test2chunks[test_name] = [chunk.page_content for chunk in doc_manager.chunks]\n",
    "        \n",
    "test2label = {\n",
    "    'rag_False_True_None': 'rag_sent', \n",
    "    'rag_False_False_100': 'rag_100', \n",
    "    'gen_False_True_None': 'gen', \n",
    "    'gen_True_True_None': 'gen_full', \n",
    "    'rag_base_False_True_None': 'rag_sent_base', \n",
    "    'rag_base_False_False_100': 'rag_100_base',\n",
    "    'GOLD': 'GOLD'\n",
    "}\n",
    "\n",
    "label2order = {\n",
    "    'rag_sent': 6, \n",
    "    'rag_100': 5, \n",
    "    'gen': 4, \n",
    "    'gen_full': 3, \n",
    "    'rag_sent_base': 2, \n",
    "    'rag_100_base': 1, \n",
    "    'GOLD': 0, \n",
    "}\n",
    "\n",
    "load_doc_manager(doc_manager, sample, False)\n",
    "source_sents = [sent.text for section in doc_manager.sections if section.section_nlp_local for sent in section.section_nlp_local.sents]\n",
    "unique_ngram2sent = get_sent_index(source_sents)\n",
    "\n",
    "sent_id2labels = [[] for _ in range(max(sent_id for ngram, (sent_id, sent) in unique_ngram2sent.items()) + 1)]\n",
    "for test_name, test_label in test2label.items():\n",
    "    if test_name == 'GOLD':\n",
    "        test_sents = sample.extractions[question_type]\n",
    "    else:\n",
    "        if test_name not in test2sents:\n",
    "            continue\n",
    "        test_sents = test2sents[test_name]\n",
    "    for sent_id in get_sent_ids(test_sents, unique_ngram2sent):\n",
    "        sent_id2labels[sent_id].append(test_label)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample.extractions[question_type]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "content = PARAGRAPH_SEP.join([f'Chunk {chunk.metadata[\"chunk_id\"]}: {chunk.page_content}' for chunk in doc_manager.chunks])\n",
    "prompt = f'Below are text chunks from a paper:\\n\\n\\n\\n{content}\\n\\n\\n\\nSelect the Chunk ids that are relevant to the following question: \\n\\n{sample.questions[question_type]}\\n\\nReturn only the selected chunk ids separated by commas, e.g. \"1, 3, 5\".'\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# skipped_labels = {'gen_full', 'rag_sent', 'rag_100'}\n",
    "# skipped_labels = {'gen_full', 'gen'}\n",
    "# skipped_labels = {'gen_full', 'gen', 'rag_sent', 'rag_100', 'rag_sent_base', 'rag_100_base'}\n",
    "skipped_labels = {'gen_full', 'rag_sent', 'rag_100', 'rag_sent_base', 'rag_100_base'}\n",
    "with open(f'observations_{sid}.txt', 'w') as f_out:\n",
    "    for sent_id, sent in enumerate(source_sents):\n",
    "        f_out.write(f'{sent} --- {\", \".join(sorted([label for label in sent_id2labels[sent_id] if label not in skipped_labels], key=lambda x: label2order[x]))}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_file = get_eval_file('rag', split, question_type, load_from_pdf=False, sent_chunk=False, max_seq_len=100, k=10, is_temp=False)\n",
    "with open(eval_file) as f_in:\n",
    "    eval_results = json.load(f_in)\n",
    "eval_results[sid]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for eval_result in eval_results:\n",
    "    if eval_result['recall']:\n",
    "        print(eval_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test2chunks.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test2chunks['rag_base_False_False_100']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample.extractions['challenge']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample.questions['challenge']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_manager.build_chunks(sent_chunk=True, max_seq_length=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_manager.vectorstore.similarity_search('Limitations of the current methods')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_manager.vectorstore.similarity_search('We propose a new method to solve this problem.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "content = PARAGRAPH_SEP.join([f'Chunk {chunk.metadata[\"chunk_id\"]}: {chunk.page_content}' for chunk in doc_manager.chunks])\n",
    "similar_chunk_prompt = f'Below are text chunks from a paper:\\n\\n\\n\\n{content}\\n\\n\\n\\nSelect the Chunk ids that express similar general meaning as the following statement: \\n\\n{\"Previous [Method] has been used for [Task].\"}\\n\\nReturn only the selected chunk ids separated by commas, e.g. \"1, 3, 5\".'\n",
    "chat_completion = doc_manager.client.chat.completions.create(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": similar_chunk_prompt,\n",
    "        }\n",
    "    ],\n",
    "    model=doc_manager.tool_llm,\n",
    ")\n",
    "content = chat_completion.choices[0].message.content\n",
    "content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_manager.chunks[21]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "split = 'train'\n",
    "question_type = 'challenge'\n",
    "with jsonlines.open(f'{ACLSUM_DIR}/{split}_dataset.jsonl') as f_in:\n",
    "    aclsum_dataset = [Sample.model_validate(line) for line in f_in]\n",
    "eval_metrics = EvalMetrics()\n",
    "eval_results = list[dict]()\n",
    "for sid, sample in enumerate(tqdm(aclsum_dataset)):\n",
    "    load_doc_manager(doc_manager, sample, False)\n",
    "    doc_manager.build_chunks(sent_chunk=True, max_seq_length=None)\n",
    "    unique_ngram2sent = get_sent_index([sent.text for section in doc_manager.sections if section.section_nlp_local for sent in section.section_nlp_local.sents])\n",
    "    chunks = [chunk.page_content for chunk in doc_manager.chunks]\n",
    "    # random.shuffle(chunks)\n",
    "    content = PARAGRAPH_SEP.join([f'Chunk {chunk_id}: {chunk}' for chunk_id, chunk in enumerate(chunks)])\n",
    "    selected_chunk_ids = set[int]()\n",
    "    question2chunk_ids = dict[str, list[int]]()\n",
    "    for question in [\n",
    "        # \"[Task] is widely studied in the research.\",\n",
    "        \"Introduction of [Task].\",\n",
    "        # \"Previous [Method] has been used for [Task].\",\n",
    "        # \"Previous [Method] has drawbacks.\",\n",
    "        \"[Method] has been used for [Task].\",\n",
    "        \"[Method] has limitations.\",\n",
    "        # \"We propose a new [Method] to solve this problem.\",\n",
    "    ]:\n",
    "        similar_chunk_prompt = f'Below are text chunks from a paper:\\n\\n\\n\\n{content}\\n\\n\\n\\nRank the **TOP 5** Chunk ids that belong to the following topic: \\n\\n{question}\\n\\nReturn only the selected chunk ids separated by commas, e.g. \"1, 3, 5\".'\n",
    "        chat_completion = doc_manager.client.chat.completions.create(\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": similar_chunk_prompt,\n",
    "                }\n",
    "            ],\n",
    "            model=doc_manager.tool_llm,\n",
    "        )\n",
    "        try:\n",
    "            selected_chunk_ids.update(map(int, chat_completion.choices[0].message.content.split(', ')))\n",
    "            question2chunk_ids[question] = list(map(int, chat_completion.choices[0].message.content.split(', ')))\n",
    "        except:\n",
    "            question2chunk_ids[question] = []\n",
    "    \n",
    "    retrieved_sents = [sent for chunk_id in selected_chunk_ids if chunk_id < len(chunks)  for sent in spacy_sent_tokenize(doc_manager.nlp, chunks[chunk_id])]\n",
    "    if not retrieved_sents:\n",
    "        eval_result = {'f1': 0, 'precision': 0, 'recall': 0}\n",
    "    else:\n",
    "        retrieved_sent_ids = get_binary_sent_ids(retrieved_sents, unique_ngram2sent)\n",
    "        gold_sent_ids = get_binary_sent_ids(sample.extractions[question_type], unique_ngram2sent)\n",
    "        \n",
    "        eval_result:dict[str, Any] = eval_metrics.eval_precision_recall_f1(predictions=retrieved_sent_ids, references=gold_sent_ids)\n",
    "    eval_result.update({'sid': sid, 'sent_ids': retrieved_sents, 'question2chunk_ids': question2chunk_ids})\n",
    "    eval_results.append(eval_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('temp_eval.json', 'w') as f_out:\n",
    "    json.dump(eval_results, f_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('temp_eval.json') as f_in:\n",
    "    eval_results = json.load(f_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('recall', np.mean([result['recall'] for result in eval_results[:]]))\n",
    "print('precision', np.mean([result['precision'] for result in eval_results[:]]))\n",
    "print('f1', np.mean([result['f1'] for result in eval_results[:]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for eval_result in eval_results:\n",
    "    if eval_result['recall'] < 0.5:\n",
    "        print(eval_result['sid'], eval_result['recall'], eval_result['precision'], eval_result['f1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aclsum_dataset[1].extractions['challenge']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for eval_result, sample in zip(eval_results, aclsum_dataset):\n",
    "    eval_result['missing'] = set(sample.extractions['challenge']).difference(eval_result['sent_ids'])\n",
    "    eval_result['shared'] = set(sample.extractions['challenge']).intersection(eval_result['sent_ids'])\n",
    "    eval_result['extra'] = set(eval_result['sent_ids']).difference(sample.extractions['challenge'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_doc_manager(doc_manager, aclsum_dataset[0], False)\n",
    "doc_manager.build_chunks(sent_chunk=True, max_seq_length=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_results[0]['missing']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_results[0]['extra']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_results[0]['shared']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks = [chunk.page_content for chunk in doc_manager.chunks]\n",
    "[sent for chunk_id in eval_results[0]['question2chunk_ids']['[Method] has limitations.'] if chunk_id < len(chunks)  for sent in spacy_sent_tokenize(doc_manager.nlp, chunks[chunk_id])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aclsum_dataset[0].answers['challenge']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aclsum_dataset[4].questions['outcome']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# context = '''Results show that the proposed system outperforms significantly other stateof-the-art QE systems. This study is part of a bigger, ongoing project, aiming to develop a real-time QE system for Web search, where simplicity is the key to the success. Thus, what we learned from this study is particularly encouraging.'''\n",
    "\n",
    "# context = '''These models are trained on pairs of user queries and the titles of clicked documents using EM. Second, we present a ranker-based QE system, the heart of which is a MRF-based ranker in which the lexicon models are incorporated as features. We perform experiments on the Web search task using a real world data set.'''\n",
    "\n",
    "# context = '''The experimental results show that when implementing the sequence modeling layer with a single-layer Bi-LSTM, our method achieves considerable improvements over the state-of-theart methods in both inference speed and sequence labeling performance.'''\n",
    "\n",
    "context = '''Experimental studies on four benchmark Chinese NER datasets show that our method achieves an inference speed up to 6.15 times faster than those of state-ofthe-art methods, along with a better performance. The experimental results also show that the proposed method can be easily incorporated with pre-trained models like BERT.'''\n",
    "\n",
    "question = aclsum_dataset[4].questions['outcome']\n",
    "\n",
    "grade_doc_prompt = f\"\"\"You are a grader assessing relevance of a retrieved document to a user question.\n",
    "\n",
    "Here is the retrieved document:\n",
    "\n",
    "{context}\n",
    "\n",
    "Here is the user question:\n",
    "\n",
    "{question}\n",
    "\n",
    "If the document contains keyword(s) or semantic meaning related to the user question, grade it as relevant.\n",
    "Give a binary score 'yes' or 'no' score to indicate whether the document is relevant to the question. Briefly explain your reasoning for the grade.\"\"\"\n",
    "\n",
    "chat_completion = doc_manager.client.chat.completions.create(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": grade_doc_prompt,\n",
    "        }\n",
    "    ],\n",
    "    model=doc_manager.tool_llm,\n",
    ")\n",
    "\n",
    "chat_completion.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "context = '''In this work, we propose a simple but effective method for incorporating the word lexicon into the character representations. This method avoids designing a complicated sequence modeling architecture, and for any neural NER model, it requires only subtle adjustment of the character representation layer to introduce the lexicon information. Experimental studies on four benchmark Chinese NER datasets show that our method achieves an inference speed up to 6.15 times faster than those of state-ofthe-art methods, along with a better performance. The experimental results also show that the proposed method can be easily incorporated with pre-trained models like BERT.'''\n",
    "\n",
    "question = aclsum_dataset[4].questions['outcome']\n",
    "\n",
    "grade_doc_prompt = f\"\"\"You are a grader assessing relevance of a retrieved document to a user question.\n",
    "\n",
    "Here is the retrieved document:\n",
    "\n",
    "{context}\n",
    "\n",
    "Here is the user question:\n",
    "\n",
    "{question}\n",
    "\n",
    "If the document contains keyword(s) or semantic meaning related to the user question, grade it as relevant.\n",
    "Give a binary score 'yes' or 'no' score to indicate whether the document is relevant to the question. Briefly explain your reasoning for the grade.\"\"\"\n",
    "\n",
    "chat_completion = doc_manager.client.chat.completions.create(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": grade_doc_prompt,\n",
    "        }\n",
    "    ],\n",
    "    model=doc_manager.tool_llm,\n",
    ")\n",
    "\n",
    "chat_completion.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SciREX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Salient Entity Extraction\n",
    "  + Extract the salient Dataset, Method, Task and Metric of the paper.\n",
    "  + An entity is extracted if one of its mentions is being returned.\n",
    "+ Salient Entity Mention Extraction\n",
    "  + Extract the sentences where a salient entity's mention appear.\n",
    "  + An entity mention is extracted if the sentence containing the mention is extracted.\n",
    "+ Salient N-ary Relation Extraction\n",
    "  + Extract the Dataset, Method, Task and Metric tuples that are bounded together."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Observation and Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with jsonlines.open('../../data/SciREX/train.jsonl') as f_in:\n",
    "    scirex_dataset = list(f_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sample = scirex_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sample.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sample['n_ary_relations']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sample['doc_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sample['words'][12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from time import sleep\n",
    "from tqdm import tqdm\n",
    "\n",
    "failed_ids = []\n",
    "for sample in tqdm(scirex_dataset[2:]):\n",
    "    paper_meta = requests.get(f\"https://api.semanticscholar.org/graph/v1/paper/{sample['doc_id']}\", params={'fields': 'externalIds'}).json()\n",
    "    while 'externalIds' not in paper_meta:\n",
    "        sleep(10)\n",
    "        paper_meta = requests.get(f\"https://api.semanticscholar.org/graph/v1/paper/{sample['doc_id']}\", params={'fields': 'externalIds'}).json()\n",
    "    if 'ArXiv' not in paper_meta['externalIds']:\n",
    "        failed_ids.append(sample['doc_id'])\n",
    "        continue\n",
    "    download_file(f\"https://arxiv.org/pdf/{paper_meta['externalIds']['ArXiv']}\", f\"../../data/SciREX/pdf/{sample['doc_id']}.pdf\")\n",
    "    sleep(2)\n",
    "with open('../../data/SciREX/failed_ids.txt', 'w') as f_out:\n",
    "    f_out.write('\\n'.join(failed_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "208291415"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'externalIds', 'url', "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = requests.get(f\"https://api.semanticscholar.org/graph/v1/paper/CorpusID:13530374\", params={'fields': 'externalIds'}).json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = requests.get(f\"https://api.semanticscholar.org/graph/v1/paper/ACL:2020.aacl-main.88\", params={'fields': 'externalIds'}).json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_manager = DocManager()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_file = f\"../../data/SciREX/pdfs/{test_sample['doc_id']}.pdf\"\n",
    "if os.path.exists(test_file):\n",
    "    doc_manager.load_doc(test_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(doc_manager.outline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_manager.get_section_by_header('6. Conclusion').text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_manager.sections[5].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_manager.sections[3].blocks[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# doc_strs = list[str]()\n",
    "# for section_range in test_sample['sections']:\n",
    "#     section_words = test_sample['words'][section_range[0]:section_range[1]]\n",
    "#     if section_words[0] == 'section' and section_words[1] == ':':\n",
    "#         section_words = section_words[2:]\n",
    "#     doc_strs.append(' '.join(section_words))\n",
    "'https://arxiv.org/pdf/2210.14427'\n",
    "doc_manager.load_doc(doc_file='https://arxiv.org/pdf/1611.08323')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sample['sentences']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sample['method_subrelations']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ArxivDIGESTables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from arxivdigestables_base import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalize Data Samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data into MongoDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../../data/ArxivDIGESTables/papers.jsonl') as f_in:\n",
    "    papers = [json.loads(line) for line in f_in]\n",
    "with open('../../data/ArxivDIGESTables/tables.jsonl') as f_in:\n",
    "    tables = [json.loads(line) for line in f_in]\n",
    "with open('../../data/ArxivDIGESTables/full_texts.jsonl') as f_in:\n",
    "    full_texts = [json.loads(line) for line in f_in]\n",
    "\n",
    "full_texts_collection.insert_many(full_texts)\n",
    "papers_collection.insert_many(papers)\n",
    "tables_collection.insert_many(tables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download PDFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paper = papers_collection.find_one()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../../reference_repo/arxivDIGESTables/predictions/predictions.jsonl') as f_in:\n",
    "    predictions = [json.loads(line) for line in f_in]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = tables_collection.find_one({'tabid': 'bb09b7e1-2ab7-4193-922a-1b1b93486e83'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "papers_collection.find_one({'corpus_id': 208291415})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QASA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../../data/QASA/testset_answerable_1554_v1.1.json') as f_in:\n",
    "    qasa_dataset = [sample for _, sample in sorted((int(sid), sample) for sid, sample in json.load(f_in).items())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = qasa_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample['question']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample['question_type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample['evidential_info'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample['s2orc_url']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../../data/QASA/testset_unanswerable_244_v1.1.json') as f_in:\n",
    "    qasa_dataset = json.load(f_in)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sci_review.framework import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Extraction(BaseModel):\n",
    "    chunks: list[str] = []\n",
    "    extractions: str = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('new_results.json') as f_in:\n",
    "    results = defaultdict(dict[str, Extraction])\n",
    "    for k, v in json.load(f_in).items():\n",
    "        data = Extraction(**v)\n",
    "        doc_file, question  = k.split('---')\n",
    "        results[doc_file][question] = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset_from_jsonl('../../data/ACLSum/train_dataset.jsonl')\n",
    "notebooklm_samples = list[Sample]()\n",
    "for sample in dataset:\n",
    "    if sample.doc_file in results:\n",
    "        result = results[sample.doc_file]\n",
    "        unique_ngram2chunk = get_chunk_index(sample.doc_blocks)\n",
    "        for question, extraction in result.items():\n",
    "            sample.selected_blocks[question] = list[int]()\n",
    "            blocks = [block.strip() for chunk in extraction.chunks for block in chunk.split(PARAGRAPH_SEP)]\n",
    "            blocks = [block for block in blocks if block]\n",
    "            for block in blocks:\n",
    "                if block not in sample.doc_blocks:\n",
    "                    bids = get_chunk_ids([block], unique_ngram2chunk)[0]\n",
    "                    if len(bids) > 1:\n",
    "                        for bid in bids:\n",
    "                            if block[:10] == sample.doc_blocks[bid][:10]:\n",
    "                                sample.selected_blocks[question].append(bid)\n",
    "                                break\n",
    "                    else:\n",
    "                        sample.selected_blocks[question].append(bids.pop())\n",
    "                else:\n",
    "                    sample.selected_blocks[question].append(sample.doc_blocks.index(block))\n",
    "            \n",
    "        notebooklm_samples.append(sample)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_by_qtype:bool = True\n",
    "eval_metrics = EvalMetrics()\n",
    "retrieval_setting = f'notebooklm_None'\n",
    "eval_selected_blocks(dataset=notebooklm_samples, eval_metrics=eval_metrics)\n",
    "\n",
    "print_eval_selected_blocks(dataset=notebooklm_samples, eval_by_qtype=True)\n",
    "        \n",
    "save_dataset_to_jsonl(dataset, f'../../data/ACLSum/notebooklm_train_dataset_{retrieval_setting}_eval.jsonl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "citation_eval = [sample for sample in load_dataset_from_jsonl('../../data/ACLSum/gpt4o_train_dataset_citation_None_eval.jsonl') if sample.doc_file in results]\n",
    "print(len(citation_eval))\n",
    "print_eval_selected_blocks(dataset=citation_eval, eval_by_qtype=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset_from_jsonl('../../data/ACLSum/gpt4o_train_dataset_gen_None_eval.jsonl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = dataset[0]\n",
    "for block in sample.doc_blocks:\n",
    "    print(block)\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample.questions['challenge'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selection_eval = [sample for sample in load_dataset_from_jsonl('../../data/ACLSum/gpt4o_train_dataset_gen_None_eval.jsonl') if sample.doc_file in results]\n",
    "print(len(selection_eval))\n",
    "print_eval_selected_blocks(dataset=selection_eval, eval_by_qtype=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Paper Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "02/25/2025 18:31:10 - INFO - \t Tokenize 55 inputs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97e38b41e41e48c195b4c661abdf1f19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/55 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "02/25/2025 18:31:12 - INFO - \t ***** Running Inference on 55 texts *****\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32fe6815ebfd4be194e6e3bf0f422b5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Inference:   0%|          | 0/55 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "paragraphs, outline, title_text = get_arxiv_paper_text('2403.05303')\n",
    "\n",
    "doc_manager.load_doc(doc_strs=[DocManager.remove_citations(p) for p in paragraphs], outline=outline, simple_load=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dash app running on http://128.174.246.108:8051/\n"
     ]
    }
   ],
   "source": [
    "doc_manager.plot_dkg(host='128.174.246.108')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Additionally, we explore the effectiveness of extractive versus abstractive summarization within the scholarly domain on the basis of automatically discovered aspects."
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent = list(doc_manager.blocks[1].nlp_local.sents)[5]\n",
    "sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_manager.dkg.number_of_nodes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "undir_dkg = doc_manager.dkg.to_undirected()\n",
    "sents = doc_manager.sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'5.2 RQ2: CoT vs. E2E instruct-tuning.'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_manager.blocks[42].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_block_id = 32\n",
    "end_block_id = 39\n",
    "block_start = doc_manager.blocks[start_block_id]\n",
    "block_end = doc_manager.blocks[end_block_id]\n",
    "block_start_ents:set[int] = {pid for pid in set(doc_manager.tid2phrase_id[block_start.nlp_global.start: block_start.nlp_global.end]) if pid != -1}\n",
    "block_end_ents:set[int] = {pid for pid in set(doc_manager.tid2phrase_id[block_end.nlp_global.start: block_end.nlp_global.end]) if pid != -1}\n",
    "valid_blocks = set(range(start_block_id, end_block_id + 1))\n",
    "valid_path_blocks = set(range(start_block_id + 1, end_block_id))\n",
    "valid_ents = {pid for block_id in valid_blocks for pid in set(doc_manager.tid2phrase_id[doc_manager.blocks[block_id].nlp_global.start: doc_manager.blocks[block_id].nlp_global.end]) if pid != -1}\n",
    "subgraph = undir_dkg.subgraph(valid_ents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_block_id = 32\n",
    "end_block_id = 47\n",
    "block_start = doc_manager.blocks[start_block_id]\n",
    "block_end = doc_manager.blocks[end_block_id]\n",
    "block_start_ents:set[int] = {pid for pid in set(doc_manager.tid2phrase_id[block_start.nlp_global.start: block_start.nlp_global.end]) if pid != -1}\n",
    "block_end_ents:set[int] = {pid for pid in set(doc_manager.tid2phrase_id[block_end.nlp_global.start: block_end.nlp_global.end]) if pid != -1}\n",
    "valid_blocks = set(range(start_block_id, end_block_id + 1)) - {33, 34, 35, 36, 37, 38, 39, 40, 41}\n",
    "valid_path_blocks = set(range(start_block_id + 1, end_block_id)) - {33, 34, 35, 36, 37, 38, 39, 40, 41}\n",
    "valid_ents = {pid for block_id in valid_blocks for pid in set(doc_manager.tid2phrase_id[doc_manager.blocks[block_id].nlp_global.start: doc_manager.blocks[block_id].nlp_global.end]) if pid != -1}\n",
    "subgraph = undir_dkg.subgraph(valid_ents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subgraph.has_edge(512, 511, key=SUBJ_OBJ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subgraph.edges[512, 511, SUBJ_OBJ]['weight']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path 0: 24.394711799232052\n",
      "strategy\n",
      "The first strategy\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "\n",
      "The first strategy\n",
      "a summary\n",
      "subj_obj\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "\n",
      "a summary\n",
      "a summary\n",
      "shared_text\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "a summary\n",
      "the summary\n",
      "coref\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the summary\n",
      "sentences\n",
      "subj_obj\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "sentences\n",
      "a sentence\n",
      "shared_text\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "To see if models’ outputs contain valid sequences for labels, we compute the average success rates by checking if (1) models predict at least one index to a sentence and (2) predicted indexes are in the valid range.\n",
      "\n",
      "\n",
      "Path 1: 25.394711799232052\n",
      "strategy\n",
      "The first strategy\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "\n",
      "The first strategy\n",
      "a summary\n",
      "subj_obj\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "\n",
      "a summary\n",
      "a summary\n",
      "shared_text\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "a summary\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "subj_obj\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "sentences\n",
      "subj_obj\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "sentences\n",
      "a sentence\n",
      "shared_text\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "To see if models’ outputs contain valid sequences for labels, we compute the average success rates by checking if (1) models predict at least one index to a sentence and (2) predicted indexes are in the valid range.\n",
      "\n",
      "\n",
      "Path 2: 31.808716959699147\n",
      "strategy\n",
      "The first strategy\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "\n",
      "The first strategy\n",
      "a summary\n",
      "subj_obj\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "\n",
      "a summary\n",
      "a summary\n",
      "shared_text\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "a summary\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "subj_obj\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "A training data sample used for EtA-CoT\n",
      "shared_text\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "A training data sample used for EtA-CoT is shown in Table 5.\n",
      "\n",
      "A training data sample used for EtA-CoT\n",
      "Table 5\n",
      "subj_obj\n",
      "A training data sample used for EtA-CoT is shown in Table 5.\n",
      "\n",
      "Table 5\n",
      "Table 6\n",
      "shared_text\n",
      "A training data sample used for EtA-CoT is shown in Table 5.\n",
      "Table 6 presents ROUGE scores, BERTScores, and extraction performance using our gold extractive labels measured by F1 for EtA-CoT models.\n",
      "\n",
      "\n",
      "Path 3: 32.80871695969915\n",
      "strategy\n",
      "The first strategy\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "\n",
      "The first strategy\n",
      "a summary\n",
      "subj_obj\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "\n",
      "a summary\n",
      "a summary\n",
      "shared_text\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "a summary\n",
      "the summary\n",
      "coref\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the summary\n",
      "sentences\n",
      "subj_obj\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "sentences\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "subj_obj\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "A training data sample used for EtA-CoT\n",
      "shared_text\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "A training data sample used for EtA-CoT is shown in Table 5.\n",
      "\n",
      "A training data sample used for EtA-CoT\n",
      "Table 5\n",
      "subj_obj\n",
      "A training data sample used for EtA-CoT is shown in Table 5.\n",
      "\n",
      "Table 5\n",
      "Table 6\n",
      "shared_text\n",
      "A training data sample used for EtA-CoT is shown in Table 5.\n",
      "Table 6 presents ROUGE scores, BERTScores, and extraction performance using our gold extractive labels measured by F1 for EtA-CoT models.\n",
      "\n",
      "\n",
      "Path 4: 34.14028470221401\n",
      "strategy\n",
      "The first strategy\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "\n",
      "The first strategy\n",
      "an instruction\n",
      "subj_obj\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "\n",
      "an instruction\n",
      "this instruction-tuning dataset\n",
      "shared_text\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "this instruction-tuning dataset\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "we\n",
      "coref\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "the popular Llama 2 model\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "the Llama 2 model\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "the Llama 2 model\n",
      "not its instruction-tuned variant\n",
      "coref\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "not its instruction-tuned variant\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "shared_text\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "performance between Llama 2\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "While it is difficult to compare performance between Llama 2 and T5 due to the massive difference in model sizes (Llama 2: 7B vs. \\text{T5}_{\\textsc{LARGE}}: 770M parameters), the E2E model with Llama 2 substantially outperforms the latter on the Challenge aspect.\n",
      "\n",
      "\n",
      "Path 5: 34.14028470221401\n",
      "strategy\n",
      "The first strategy\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "\n",
      "The first strategy\n",
      "an instruction\n",
      "subj_obj\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "\n",
      "an instruction\n",
      "this instruction-tuning dataset\n",
      "shared_text\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "this instruction-tuning dataset\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "we\n",
      "coref\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "the popular Llama 2 model\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "the Llama 2 model\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "the Llama 2 model\n",
      "not its instruction-tuned variant\n",
      "coref\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "not its instruction-tuned variant\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "shared_text\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "performance between Llama 2\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "While it is difficult to compare performance between Llama 2 and T5 due to the massive difference in model sizes (Llama 2: 7B vs. \\text{T5}_{\\textsc{LARGE}}: 770M parameters), the E2E model with Llama 2 substantially outperforms the latter on the Challenge aspect.\n",
      "\n",
      "\n",
      "Path 6: 35.44147352100734\n",
      "strategy\n",
      "The first strategy\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "\n",
      "The first strategy\n",
      "a summary\n",
      "subj_obj\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "\n",
      "a summary\n",
      "a summary\n",
      "shared_text\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "a summary\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "subj_obj\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "A training data sample used for EtA-CoT\n",
      "shared_text\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "A training data sample used for EtA-CoT is shown in Table 5.\n",
      "\n",
      "A training data sample used for EtA-CoT\n",
      "EtA-CoT models\n",
      "shared_text\n",
      "A training data sample used for EtA-CoT is shown in Table 5.\n",
      "Table 6 presents ROUGE scores, BERTScores, and extraction performance using our gold extractive labels measured by F1 for EtA-CoT models.\n",
      "\n",
      "\n",
      "Path 7: 36.44147352100734\n",
      "strategy\n",
      "The first strategy\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "\n",
      "The first strategy\n",
      "a summary\n",
      "subj_obj\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "\n",
      "a summary\n",
      "a summary\n",
      "shared_text\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "a summary\n",
      "the summary\n",
      "coref\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the summary\n",
      "sentences\n",
      "subj_obj\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "sentences\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "subj_obj\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "A training data sample used for EtA-CoT\n",
      "shared_text\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "A training data sample used for EtA-CoT is shown in Table 5.\n",
      "\n",
      "A training data sample used for EtA-CoT\n",
      "EtA-CoT models\n",
      "shared_text\n",
      "A training data sample used for EtA-CoT is shown in Table 5.\n",
      "Table 6 presents ROUGE scores, BERTScores, and extraction performance using our gold extractive labels measured by F1 for EtA-CoT models.\n",
      "\n",
      "\n",
      "Path 8: 37.844002459050344\n",
      "strategy\n",
      "The first strategy\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "\n",
      "The first strategy\n",
      "a summary\n",
      "subj_obj\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "\n",
      "a summary\n",
      "a summary\n",
      "shared_text\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "a summary\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "subj_obj\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "the model\n",
      "subj_obj\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the model\n",
      "the model\n",
      "coref\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "\n",
      "the model\n",
      "the popular Llama 2 model\n",
      "shared_text\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "the Llama 2 model\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "the Llama 2 model\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "shared_text\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "performance between Llama 2\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "While it is difficult to compare performance between Llama 2 and T5 due to the massive difference in model sizes (Llama 2: 7B vs. \\text{T5}_{\\textsc{LARGE}}: 770M parameters), the E2E model with Llama 2 substantially outperforms the latter on the Challenge aspect.\n",
      "\n",
      "\n",
      "Path 9: 37.844002459050344\n",
      "strategy\n",
      "The first strategy\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "\n",
      "The first strategy\n",
      "a summary\n",
      "subj_obj\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "\n",
      "a summary\n",
      "a summary\n",
      "shared_text\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "a summary\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "subj_obj\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "the model\n",
      "subj_obj\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the model\n",
      "the model\n",
      "coref\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "\n",
      "the model\n",
      "the popular Llama 2 model\n",
      "shared_text\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "the Llama 2 model\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "the Llama 2 model\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "shared_text\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "performance between Llama 2\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "While it is difficult to compare performance between Llama 2 and T5 due to the massive difference in model sizes (Llama 2: 7B vs. \\text{T5}_{\\textsc{LARGE}}: 770M parameters), the E2E model with Llama 2 substantially outperforms the latter on the Challenge aspect.\n",
      "\n",
      "\n",
      "Path 10: 38.211202337810285\n",
      "strategy\n",
      "The first strategy\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "\n",
      "The first strategy\n",
      "an instruction\n",
      "subj_obj\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "\n",
      "an instruction\n",
      "this instruction-tuning dataset\n",
      "shared_text\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "this instruction-tuning dataset\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "we\n",
      "coref\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "the popular Llama 2 model\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "the Llama 2 model\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "the Llama 2 model\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "shared_text\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "performance between Llama 2\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "While it is difficult to compare performance between Llama 2 and T5 due to the massive difference in model sizes (Llama 2: 7B vs. \\text{T5}_{\\textsc{LARGE}}: 770M parameters), the E2E model with Llama 2 substantially outperforms the latter on the Challenge aspect.\n",
      "\n",
      "\n",
      "Path 11: 38.211202337810285\n",
      "strategy\n",
      "The first strategy\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "\n",
      "The first strategy\n",
      "an instruction\n",
      "subj_obj\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "\n",
      "an instruction\n",
      "this instruction-tuning dataset\n",
      "shared_text\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "this instruction-tuning dataset\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "we\n",
      "coref\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "its summarization abilities\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "its summarization abilities\n",
      "the popular Llama 2 model\n",
      "coref\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "the Llama 2 model\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "the Llama 2 model\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "shared_text\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "performance between Llama 2\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "While it is difficult to compare performance between Llama 2 and T5 due to the massive difference in model sizes (Llama 2: 7B vs. \\text{T5}_{\\textsc{LARGE}}: 770M parameters), the E2E model with Llama 2 substantially outperforms the latter on the Challenge aspect.\n",
      "\n",
      "\n",
      "Path 12: 41.418702694279546\n",
      "strategy\n",
      "The first strategy\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "\n",
      "The first strategy\n",
      "an instruction\n",
      "subj_obj\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "\n",
      "an instruction\n",
      "this instruction-tuning dataset\n",
      "shared_text\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "this instruction-tuning dataset\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "we\n",
      "coref\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "the popular Llama 2 model\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "fine-tune the Llama 2 7B.\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "\n",
      "fine-tune the Llama 2 7B.\n",
      "the Llama 2 model\n",
      "coref\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "the Llama 2 model\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "shared_text\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "performance between Llama 2\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "While it is difficult to compare performance between Llama 2 and T5 due to the massive difference in model sizes (Llama 2: 7B vs. \\text{T5}_{\\textsc{LARGE}}: 770M parameters), the E2E model with Llama 2 substantially outperforms the latter on the Challenge aspect.\n",
      "\n",
      "\n",
      "Path 13: 41.418702694279546\n",
      "strategy\n",
      "The first strategy\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "\n",
      "The first strategy\n",
      "an instruction\n",
      "subj_obj\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "\n",
      "an instruction\n",
      "this instruction-tuning dataset\n",
      "shared_text\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "this instruction-tuning dataset\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "we\n",
      "coref\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "the popular Llama 2 model\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "fine-tune the Llama 2 7B.\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "\n",
      "fine-tune the Llama 2 7B.\n",
      "the Llama 2 model\n",
      "coref\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "the Llama 2 model\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "shared_text\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "performance between Llama 2\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "While it is difficult to compare performance between Llama 2 and T5 due to the massive difference in model sizes (Llama 2: 7B vs. \\text{T5}_{\\textsc{LARGE}}: 770M parameters), the E2E model with Llama 2 substantially outperforms the latter on the Challenge aspect.\n",
      "\n",
      "\n",
      "Path 14: 42.165561854240835\n",
      "step chain-of-thought or end-to-end abstractive summarization\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "sentences\n",
      "subj_obj\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "sentences\n",
      "a sentence\n",
      "shared_text\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "To see if models’ outputs contain valid sequences for labels, we compute the average success rates by checking if (1) models predict at least one index to a sentence and (2) predicted indexes are in the valid range.\n",
      "\n",
      "\n",
      "Path 15: 43.165561854240835\n",
      "step chain-of-thought or end-to-end abstractive summarization\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "a summary\n",
      "subj_obj\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "a summary\n",
      "the summary\n",
      "coref\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the summary\n",
      "sentences\n",
      "subj_obj\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "sentences\n",
      "a sentence\n",
      "shared_text\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "To see if models’ outputs contain valid sequences for labels, we compute the average success rates by checking if (1) models predict at least one index to a sentence and (2) predicted indexes are in the valid range.\n",
      "\n",
      "\n",
      "Path 16: 48.56389537160766\n",
      "step chain-of-thought or end-to-end abstractive summarization\n",
      "our extractive and abstractive summarization annotations\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "our extractive and abstractive summarization annotations\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "we\n",
      "coref\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "the popular Llama 2 model\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "its summarization abilities\n",
      "coref\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the model\n",
      "the model\n",
      "shared_text\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the model\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "subj_obj\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "sentences\n",
      "subj_obj\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "sentences\n",
      "a sentence\n",
      "shared_text\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "To see if models’ outputs contain valid sequences for labels, we compute the average success rates by checking if (1) models predict at least one index to a sentence and (2) predicted indexes are in the valid range.\n",
      "\n",
      "\n",
      "Path 17: 48.56389537160766\n",
      "step chain-of-thought or end-to-end abstractive summarization\n",
      "our extractive and abstractive summarization annotations\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "our extractive and abstractive summarization annotations\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "we\n",
      "coref\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "the popular Llama 2 model\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "its summarization abilities\n",
      "coref\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the model\n",
      "the model\n",
      "shared_text\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the model\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "subj_obj\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "sentences\n",
      "subj_obj\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "sentences\n",
      "a sentence\n",
      "shared_text\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "To see if models’ outputs contain valid sequences for labels, we compute the average success rates by checking if (1) models predict at least one index to a sentence and (2) predicted indexes are in the valid range.\n",
      "\n",
      "\n",
      "Path 18: 48.56389537160766\n",
      "step chain-of-thought or end-to-end abstractive summarization\n",
      "our extractive and abstractive summarization annotations\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "our extractive and abstractive summarization annotations\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "we\n",
      "coref\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "its summarization abilities\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "its summarization abilities\n",
      "the model\n",
      "coref\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "\n",
      "the model\n",
      "the model\n",
      "shared_text\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the model\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "subj_obj\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "sentences\n",
      "subj_obj\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "sentences\n",
      "a sentence\n",
      "shared_text\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "To see if models’ outputs contain valid sequences for labels, we compute the average success rates by checking if (1) models predict at least one index to a sentence and (2) predicted indexes are in the valid range.\n",
      "\n",
      "\n",
      "Path 19: 48.56389537160766\n",
      "step chain-of-thought or end-to-end abstractive summarization\n",
      "our extractive and abstractive summarization annotations\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "our extractive and abstractive summarization annotations\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "we\n",
      "coref\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "its summarization abilities\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "its summarization abilities\n",
      "the model\n",
      "coref\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "\n",
      "the model\n",
      "the model\n",
      "shared_text\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the model\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "subj_obj\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "sentences\n",
      "subj_obj\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "sentences\n",
      "a sentence\n",
      "shared_text\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "To see if models’ outputs contain valid sequences for labels, we compute the average success rates by checking if (1) models predict at least one index to a sentence and (2) predicted indexes are in the valid range.\n",
      "\n",
      "\n",
      "Path 20: 48.56389537160766\n",
      "step chain-of-thought or end-to-end abstractive summarization\n",
      "our extractive and abstractive summarization annotations\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "our extractive and abstractive summarization annotations\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "we\n",
      "coref\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "the popular Llama 2 model\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "its summarization abilities\n",
      "coref\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the model\n",
      "the model\n",
      "shared_text\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the model\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "subj_obj\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "sentences\n",
      "subj_obj\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "sentences\n",
      "a sentence\n",
      "shared_text\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "To see if models’ outputs contain valid sequences for labels, we compute the average success rates by checking if (1) models predict at least one index to a sentence and (2) predicted indexes are in the valid range.\n",
      "\n",
      "\n",
      "Path 21: 48.56389537160766\n",
      "step chain-of-thought or end-to-end abstractive summarization\n",
      "our extractive and abstractive summarization annotations\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "our extractive and abstractive summarization annotations\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "we\n",
      "coref\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "the popular Llama 2 model\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "its summarization abilities\n",
      "coref\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the model\n",
      "the model\n",
      "shared_text\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the model\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "subj_obj\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "sentences\n",
      "subj_obj\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "sentences\n",
      "a sentence\n",
      "shared_text\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "To see if models’ outputs contain valid sequences for labels, we compute the average success rates by checking if (1) models predict at least one index to a sentence and (2) predicted indexes are in the valid range.\n",
      "\n",
      "\n",
      "Path 22: 48.56389537160766\n",
      "step chain-of-thought or end-to-end abstractive summarization\n",
      "our extractive and abstractive summarization annotations\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "our extractive and abstractive summarization annotations\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "we\n",
      "coref\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "its summarization abilities\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "its summarization abilities\n",
      "the model\n",
      "coref\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "\n",
      "the model\n",
      "the model\n",
      "shared_text\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the model\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "subj_obj\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "sentences\n",
      "subj_obj\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "sentences\n",
      "a sentence\n",
      "shared_text\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "To see if models’ outputs contain valid sequences for labels, we compute the average success rates by checking if (1) models predict at least one index to a sentence and (2) predicted indexes are in the valid range.\n",
      "\n",
      "\n",
      "Path 23: 48.56389537160766\n",
      "step chain-of-thought or end-to-end abstractive summarization\n",
      "our extractive and abstractive summarization annotations\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "our extractive and abstractive summarization annotations\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "we\n",
      "coref\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "its summarization abilities\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "its summarization abilities\n",
      "the model\n",
      "coref\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "\n",
      "the model\n",
      "the model\n",
      "shared_text\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the model\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "subj_obj\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "sentences\n",
      "subj_obj\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "sentences\n",
      "a sentence\n",
      "shared_text\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "To see if models’ outputs contain valid sequences for labels, we compute the average success rates by checking if (1) models predict at least one index to a sentence and (2) predicted indexes are in the valid range.\n",
      "\n",
      "\n",
      "Path 24: 48.579567014707926\n",
      "step chain-of-thought or end-to-end abstractive summarization\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "A training data sample used for EtA-CoT\n",
      "shared_text\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "A training data sample used for EtA-CoT is shown in Table 5.\n",
      "\n",
      "A training data sample used for EtA-CoT\n",
      "Table 5\n",
      "subj_obj\n",
      "A training data sample used for EtA-CoT is shown in Table 5.\n",
      "\n",
      "Table 5\n",
      "Table 6\n",
      "shared_text\n",
      "A training data sample used for EtA-CoT is shown in Table 5.\n",
      "Table 6 presents ROUGE scores, BERTScores, and extraction performance using our gold extractive labels measured by F1 for EtA-CoT models.\n",
      "\n",
      "\n",
      "Path 25: 48.85184332642399\n",
      "step chain-of-thought or end-to-end abstractive summarization\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "the model\n",
      "subj_obj\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the model\n",
      "the model\n",
      "coref\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "\n",
      "the model\n",
      "the popular Llama 2 model\n",
      "shared_text\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "the Llama 2 model\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "the Llama 2 model\n",
      "not its instruction-tuned variant\n",
      "coref\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "not its instruction-tuned variant\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "shared_text\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "We\n",
      "subj_obj\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "We\n",
      "zero-shot prompting\n",
      "subj_obj\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "zero-shot prompting\n",
      "zero-shot prompting\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "By comparing zero-shot prompting and end-to-end tuning, one can observe that even with LLMs that are shown to be strong in summarization without any training, our dataset can help to improve their performance.\n",
      "\n",
      "\n",
      "Path 26: 48.85184332642399\n",
      "step chain-of-thought or end-to-end abstractive summarization\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "the model\n",
      "subj_obj\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the model\n",
      "the model\n",
      "coref\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "\n",
      "the model\n",
      "the popular Llama 2 model\n",
      "shared_text\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "the Llama 2 model\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "the Llama 2 model\n",
      "not its instruction-tuned variant\n",
      "coref\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "not its instruction-tuned variant\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "shared_text\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "We\n",
      "subj_obj\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "We\n",
      "zero-shot prompting\n",
      "subj_obj\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "zero-shot prompting\n",
      "zero-shot prompting\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "By comparing zero-shot prompting and end-to-end tuning, one can observe that even with LLMs that are shown to be strong in summarization without any training, our dataset can help to improve their performance.\n",
      "\n",
      "\n",
      "Path 27: 48.85184332642399\n",
      "step chain-of-thought or end-to-end abstractive summarization\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "the model\n",
      "subj_obj\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the model\n",
      "the model\n",
      "coref\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "\n",
      "the model\n",
      "the popular Llama 2 model\n",
      "shared_text\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "the Llama 2 model\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "the Llama 2 model\n",
      "not its instruction-tuned variant\n",
      "coref\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "not its instruction-tuned variant\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "shared_text\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "We\n",
      "subj_obj\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "We\n",
      "zero-shot prompting\n",
      "subj_obj\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "zero-shot prompting\n",
      "zero-shot prompting\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "By comparing zero-shot prompting and end-to-end tuning, one can observe that even with LLMs that are shown to be strong in summarization without any training, our dataset can help to improve their performance.\n",
      "\n",
      "\n",
      "Path 28: 48.85184332642399\n",
      "step chain-of-thought or end-to-end abstractive summarization\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "the model\n",
      "subj_obj\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the model\n",
      "the model\n",
      "coref\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "\n",
      "the model\n",
      "the popular Llama 2 model\n",
      "shared_text\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "the Llama 2 model\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "the Llama 2 model\n",
      "not its instruction-tuned variant\n",
      "coref\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "not its instruction-tuned variant\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "shared_text\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "We\n",
      "subj_obj\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "We\n",
      "zero-shot prompting\n",
      "subj_obj\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "zero-shot prompting\n",
      "zero-shot prompting\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "By comparing zero-shot prompting and end-to-end tuning, one can observe that even with LLMs that are shown to be strong in summarization without any training, our dataset can help to improve their performance.\n",
      "\n",
      "\n",
      "Path 29: 49.009474142360816\n",
      "step chain-of-thought or end-to-end abstractive summarization\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "the model\n",
      "subj_obj\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the model\n",
      "the model\n",
      "coref\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "\n",
      "the popular Llama 2 model\n",
      "the Llama 2 model\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "the Llama 2 model\n",
      "not its instruction-tuned variant\n",
      "coref\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "not its instruction-tuned variant\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "shared_text\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "performance between Llama 2\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "While it is difficult to compare performance between Llama 2 and T5 due to the massive difference in model sizes (Llama 2: 7B vs. \\text{T5}_{\\textsc{LARGE}}: 770M parameters), the E2E model with Llama 2 substantially outperforms the latter on the Challenge aspect.\n",
      "\n",
      "\n",
      "Path 30: 49.009474142360816\n",
      "step chain-of-thought or end-to-end abstractive summarization\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "the model\n",
      "subj_obj\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the model\n",
      "the model\n",
      "coref\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "\n",
      "the popular Llama 2 model\n",
      "the Llama 2 model\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "the Llama 2 model\n",
      "not its instruction-tuned variant\n",
      "coref\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "not its instruction-tuned variant\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "shared_text\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "performance between Llama 2\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "While it is difficult to compare performance between Llama 2 and T5 due to the massive difference in model sizes (Llama 2: 7B vs. \\text{T5}_{\\textsc{LARGE}}: 770M parameters), the E2E model with Llama 2 substantially outperforms the latter on the Challenge aspect.\n",
      "\n",
      "\n",
      "Path 31: 49.009474142360816\n",
      "step chain-of-thought or end-to-end abstractive summarization\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "the model\n",
      "subj_obj\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the model\n",
      "the model\n",
      "coref\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "\n",
      "the popular Llama 2 model\n",
      "the Llama 2 model\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "the Llama 2 model\n",
      "not its instruction-tuned variant\n",
      "coref\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "not its instruction-tuned variant\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "shared_text\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "performance between Llama 2\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "While it is difficult to compare performance between Llama 2 and T5 due to the massive difference in model sizes (Llama 2: 7B vs. \\text{T5}_{\\textsc{LARGE}}: 770M parameters), the E2E model with Llama 2 substantially outperforms the latter on the Challenge aspect.\n",
      "\n",
      "\n",
      "Path 32: 49.009474142360816\n",
      "step chain-of-thought or end-to-end abstractive summarization\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "the model\n",
      "subj_obj\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the model\n",
      "the model\n",
      "coref\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "\n",
      "the popular Llama 2 model\n",
      "the Llama 2 model\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "the Llama 2 model\n",
      "not its instruction-tuned variant\n",
      "coref\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "not its instruction-tuned variant\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "shared_text\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "performance between Llama 2\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "While it is difficult to compare performance between Llama 2 and T5 due to the massive difference in model sizes (Llama 2: 7B vs. \\text{T5}_{\\textsc{LARGE}}: 770M parameters), the E2E model with Llama 2 substantially outperforms the latter on the Challenge aspect.\n",
      "\n",
      "\n",
      "Path 33: 49.18501849773605\n",
      "Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization,\n",
      "our extractive and abstractive summarization annotations\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "our extractive and abstractive summarization annotations\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "we\n",
      "coref\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "the popular Llama 2 model\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "its summarization abilities\n",
      "coref\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the model\n",
      "the model\n",
      "shared_text\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the model\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "subj_obj\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "sentences\n",
      "subj_obj\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "sentences\n",
      "a sentence\n",
      "shared_text\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "To see if models’ outputs contain valid sequences for labels, we compute the average success rates by checking if (1) models predict at least one index to a sentence and (2) predicted indexes are in the valid range.\n",
      "\n",
      "\n",
      "Path 34: 49.18501849773605\n",
      "Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization,\n",
      "our extractive and abstractive summarization annotations\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "our extractive and abstractive summarization annotations\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "we\n",
      "coref\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "the popular Llama 2 model\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "its summarization abilities\n",
      "coref\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the model\n",
      "the model\n",
      "shared_text\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the model\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "subj_obj\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "sentences\n",
      "subj_obj\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "sentences\n",
      "a sentence\n",
      "shared_text\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "To see if models’ outputs contain valid sequences for labels, we compute the average success rates by checking if (1) models predict at least one index to a sentence and (2) predicted indexes are in the valid range.\n",
      "\n",
      "\n",
      "Path 35: 49.18501849773605\n",
      "Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization,\n",
      "our extractive and abstractive summarization annotations\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "our extractive and abstractive summarization annotations\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "we\n",
      "coref\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "its summarization abilities\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "its summarization abilities\n",
      "the model\n",
      "coref\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "\n",
      "the model\n",
      "the model\n",
      "shared_text\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the model\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "subj_obj\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "sentences\n",
      "subj_obj\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "sentences\n",
      "a sentence\n",
      "shared_text\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "To see if models’ outputs contain valid sequences for labels, we compute the average success rates by checking if (1) models predict at least one index to a sentence and (2) predicted indexes are in the valid range.\n",
      "\n",
      "\n",
      "Path 36: 49.18501849773605\n",
      "Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization,\n",
      "our extractive and abstractive summarization annotations\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "our extractive and abstractive summarization annotations\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "we\n",
      "coref\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "its summarization abilities\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "its summarization abilities\n",
      "the model\n",
      "coref\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "\n",
      "the model\n",
      "the model\n",
      "shared_text\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the model\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "subj_obj\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "sentences\n",
      "subj_obj\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "sentences\n",
      "a sentence\n",
      "shared_text\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "To see if models’ outputs contain valid sequences for labels, we compute the average success rates by checking if (1) models predict at least one index to a sentence and (2) predicted indexes are in the valid range.\n",
      "\n",
      "\n",
      "Path 37: 49.18501849773605\n",
      "Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization,\n",
      "our extractive and abstractive summarization annotations\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "our extractive and abstractive summarization annotations\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "we\n",
      "coref\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "the popular Llama 2 model\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "its summarization abilities\n",
      "coref\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the model\n",
      "the model\n",
      "shared_text\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the model\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "subj_obj\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "sentences\n",
      "subj_obj\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "sentences\n",
      "a sentence\n",
      "shared_text\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "To see if models’ outputs contain valid sequences for labels, we compute the average success rates by checking if (1) models predict at least one index to a sentence and (2) predicted indexes are in the valid range.\n",
      "\n",
      "\n",
      "Path 38: 49.18501849773605\n",
      "Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization,\n",
      "our extractive and abstractive summarization annotations\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "our extractive and abstractive summarization annotations\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "we\n",
      "coref\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "the popular Llama 2 model\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "its summarization abilities\n",
      "coref\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the model\n",
      "the model\n",
      "shared_text\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the model\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "subj_obj\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "sentences\n",
      "subj_obj\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "sentences\n",
      "a sentence\n",
      "shared_text\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "To see if models’ outputs contain valid sequences for labels, we compute the average success rates by checking if (1) models predict at least one index to a sentence and (2) predicted indexes are in the valid range.\n",
      "\n",
      "\n",
      "Path 39: 49.18501849773605\n",
      "Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization,\n",
      "our extractive and abstractive summarization annotations\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "our extractive and abstractive summarization annotations\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "we\n",
      "coref\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "its summarization abilities\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "its summarization abilities\n",
      "the model\n",
      "coref\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "\n",
      "the model\n",
      "the model\n",
      "shared_text\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the model\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "subj_obj\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "sentences\n",
      "subj_obj\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "sentences\n",
      "a sentence\n",
      "shared_text\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "To see if models’ outputs contain valid sequences for labels, we compute the average success rates by checking if (1) models predict at least one index to a sentence and (2) predicted indexes are in the valid range.\n",
      "\n",
      "\n",
      "Path 40: 49.18501849773605\n",
      "Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization,\n",
      "our extractive and abstractive summarization annotations\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "our extractive and abstractive summarization annotations\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "we\n",
      "coref\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "its summarization abilities\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "its summarization abilities\n",
      "the model\n",
      "coref\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "\n",
      "the model\n",
      "the model\n",
      "shared_text\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the model\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "subj_obj\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "sentences\n",
      "subj_obj\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "sentences\n",
      "a sentence\n",
      "shared_text\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "To see if models’ outputs contain valid sequences for labels, we compute the average success rates by checking if (1) models predict at least one index to a sentence and (2) predicted indexes are in the valid range.\n",
      "\n",
      "\n",
      "Path 41: 50.09835610770969\n",
      "step chain-of-thought or end-to-end abstractive summarization\n",
      "our extractive and abstractive summarization annotations\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "our extractive and abstractive summarization annotations\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "we\n",
      "coref\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "the popular Llama 2 model\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "the model\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "\n",
      "the model\n",
      "the model\n",
      "coref\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the model\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "subj_obj\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "sentences\n",
      "subj_obj\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "sentences\n",
      "a sentence\n",
      "shared_text\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "To see if models’ outputs contain valid sequences for labels, we compute the average success rates by checking if (1) models predict at least one index to a sentence and (2) predicted indexes are in the valid range.\n",
      "\n",
      "\n",
      "Path 42: 50.09835610770969\n",
      "step chain-of-thought or end-to-end abstractive summarization\n",
      "our extractive and abstractive summarization annotations\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "our extractive and abstractive summarization annotations\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "we\n",
      "coref\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "the popular Llama 2 model\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "the model\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "\n",
      "the model\n",
      "the model\n",
      "coref\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the model\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "subj_obj\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "sentences\n",
      "subj_obj\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "sentences\n",
      "a sentence\n",
      "shared_text\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "To see if models’ outputs contain valid sequences for labels, we compute the average success rates by checking if (1) models predict at least one index to a sentence and (2) predicted indexes are in the valid range.\n",
      "\n",
      "\n",
      "Path 43: 50.09835610770969\n",
      "step chain-of-thought or end-to-end abstractive summarization\n",
      "our extractive and abstractive summarization annotations\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "our extractive and abstractive summarization annotations\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "we\n",
      "coref\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "its summarization abilities\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "its summarization abilities\n",
      "the popular Llama 2 model\n",
      "coref\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "the model\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "\n",
      "the model\n",
      "the model\n",
      "coref\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the model\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "subj_obj\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "sentences\n",
      "subj_obj\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "sentences\n",
      "a sentence\n",
      "shared_text\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "To see if models’ outputs contain valid sequences for labels, we compute the average success rates by checking if (1) models predict at least one index to a sentence and (2) predicted indexes are in the valid range.\n",
      "\n",
      "\n",
      "Path 44: 50.09835610770969\n",
      "step chain-of-thought or end-to-end abstractive summarization\n",
      "our extractive and abstractive summarization annotations\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "our extractive and abstractive summarization annotations\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "we\n",
      "coref\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "its summarization abilities\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "its summarization abilities\n",
      "the popular Llama 2 model\n",
      "coref\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "the model\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "\n",
      "the model\n",
      "the model\n",
      "coref\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the model\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "subj_obj\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "sentences\n",
      "subj_obj\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "sentences\n",
      "a sentence\n",
      "shared_text\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "To see if models’ outputs contain valid sequences for labels, we compute the average success rates by checking if (1) models predict at least one index to a sentence and (2) predicted indexes are in the valid range.\n",
      "\n",
      "\n",
      "Path 45: 50.09835610770969\n",
      "step chain-of-thought or end-to-end abstractive summarization\n",
      "our extractive and abstractive summarization annotations\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "our extractive and abstractive summarization annotations\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "we\n",
      "coref\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "the popular Llama 2 model\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "the model\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "\n",
      "the model\n",
      "the model\n",
      "coref\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the model\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "subj_obj\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "sentences\n",
      "subj_obj\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "sentences\n",
      "a sentence\n",
      "shared_text\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "To see if models’ outputs contain valid sequences for labels, we compute the average success rates by checking if (1) models predict at least one index to a sentence and (2) predicted indexes are in the valid range.\n",
      "\n",
      "\n",
      "Path 46: 50.09835610770969\n",
      "step chain-of-thought or end-to-end abstractive summarization\n",
      "our extractive and abstractive summarization annotations\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "our extractive and abstractive summarization annotations\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "we\n",
      "coref\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "the popular Llama 2 model\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "the model\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "\n",
      "the model\n",
      "the model\n",
      "coref\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the model\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "subj_obj\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "sentences\n",
      "subj_obj\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "sentences\n",
      "a sentence\n",
      "shared_text\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "To see if models’ outputs contain valid sequences for labels, we compute the average success rates by checking if (1) models predict at least one index to a sentence and (2) predicted indexes are in the valid range.\n",
      "\n",
      "\n",
      "Path 47: 50.09835610770969\n",
      "step chain-of-thought or end-to-end abstractive summarization\n",
      "our extractive and abstractive summarization annotations\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "our extractive and abstractive summarization annotations\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "we\n",
      "coref\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "its summarization abilities\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "its summarization abilities\n",
      "the popular Llama 2 model\n",
      "coref\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "the model\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "\n",
      "the model\n",
      "the model\n",
      "coref\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the model\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "subj_obj\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "sentences\n",
      "subj_obj\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "sentences\n",
      "a sentence\n",
      "shared_text\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "To see if models’ outputs contain valid sequences for labels, we compute the average success rates by checking if (1) models predict at least one index to a sentence and (2) predicted indexes are in the valid range.\n",
      "\n",
      "\n",
      "Path 48: 50.09835610770969\n",
      "step chain-of-thought or end-to-end abstractive summarization\n",
      "our extractive and abstractive summarization annotations\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "our extractive and abstractive summarization annotations\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "we\n",
      "coref\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "its summarization abilities\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "its summarization abilities\n",
      "the popular Llama 2 model\n",
      "coref\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "the model\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "\n",
      "the model\n",
      "the model\n",
      "coref\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the model\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "subj_obj\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "sentences\n",
      "subj_obj\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "sentences\n",
      "a sentence\n",
      "shared_text\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "To see if models’ outputs contain valid sequences for labels, we compute the average success rates by checking if (1) models predict at least one index to a sentence and (2) predicted indexes are in the valid range.\n",
      "\n",
      "\n",
      "Path 49: 50.54393487846285\n",
      "step chain-of-thought or end-to-end abstractive summarization\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "the model\n",
      "subj_obj\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the model\n",
      "the model\n",
      "coref\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "\n",
      "the model\n",
      "the popular Llama 2 model\n",
      "shared_text\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "the Llama 2 model\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "the Llama 2 model\n",
      "not its instruction-tuned variant\n",
      "coref\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "not its instruction-tuned variant\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "shared_text\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "performance between Llama 2\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "While it is difficult to compare performance between Llama 2 and T5 due to the massive difference in model sizes (Llama 2: 7B vs. \\text{T5}_{\\textsc{LARGE}}: 770M parameters), the E2E model with Llama 2 substantially outperforms the latter on the Challenge aspect.\n",
      "\n",
      "\n",
      "Path 50: 50.54393487846285\n",
      "step chain-of-thought or end-to-end abstractive summarization\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "the model\n",
      "subj_obj\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the model\n",
      "the model\n",
      "coref\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "\n",
      "the model\n",
      "the popular Llama 2 model\n",
      "shared_text\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "the Llama 2 model\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "the Llama 2 model\n",
      "not its instruction-tuned variant\n",
      "coref\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "not its instruction-tuned variant\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "shared_text\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "performance between Llama 2\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "While it is difficult to compare performance between Llama 2 and T5 due to the massive difference in model sizes (Llama 2: 7B vs. \\text{T5}_{\\textsc{LARGE}}: 770M parameters), the E2E model with Llama 2 substantially outperforms the latter on the Challenge aspect.\n",
      "\n",
      "\n",
      "Path 51: 50.54393487846285\n",
      "step chain-of-thought or end-to-end abstractive summarization\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "the model\n",
      "subj_obj\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the model\n",
      "the model\n",
      "coref\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "\n",
      "the model\n",
      "the popular Llama 2 model\n",
      "shared_text\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "the Llama 2 model\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "the Llama 2 model\n",
      "not its instruction-tuned variant\n",
      "coref\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "not its instruction-tuned variant\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "shared_text\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "performance between Llama 2\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "While it is difficult to compare performance between Llama 2 and T5 due to the massive difference in model sizes (Llama 2: 7B vs. \\text{T5}_{\\textsc{LARGE}}: 770M parameters), the E2E model with Llama 2 substantially outperforms the latter on the Challenge aspect.\n",
      "\n",
      "\n",
      "Path 52: 50.54393487846285\n",
      "step chain-of-thought or end-to-end abstractive summarization\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "the model\n",
      "subj_obj\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the model\n",
      "the model\n",
      "coref\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "\n",
      "the model\n",
      "the popular Llama 2 model\n",
      "shared_text\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "the Llama 2 model\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "the Llama 2 model\n",
      "not its instruction-tuned variant\n",
      "coref\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "not its instruction-tuned variant\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "shared_text\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "performance between Llama 2\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "While it is difficult to compare performance between Llama 2 and T5 due to the massive difference in model sizes (Llama 2: 7B vs. \\text{T5}_{\\textsc{LARGE}}: 770M parameters), the E2E model with Llama 2 substantially outperforms the latter on the Challenge aspect.\n",
      "\n",
      "\n",
      "Path 53: 50.719479233838086\n",
      "Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization,\n",
      "our extractive and abstractive summarization annotations\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "our extractive and abstractive summarization annotations\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "we\n",
      "coref\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "the popular Llama 2 model\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "the model\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "\n",
      "the model\n",
      "the model\n",
      "coref\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the model\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "subj_obj\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "sentences\n",
      "subj_obj\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "sentences\n",
      "a sentence\n",
      "shared_text\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "To see if models’ outputs contain valid sequences for labels, we compute the average success rates by checking if (1) models predict at least one index to a sentence and (2) predicted indexes are in the valid range.\n",
      "\n",
      "\n",
      "Path 54: 50.719479233838086\n",
      "Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization,\n",
      "our extractive and abstractive summarization annotations\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "our extractive and abstractive summarization annotations\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "we\n",
      "coref\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "the popular Llama 2 model\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "the model\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "\n",
      "the model\n",
      "the model\n",
      "coref\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the model\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "subj_obj\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "sentences\n",
      "subj_obj\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "sentences\n",
      "a sentence\n",
      "shared_text\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "To see if models’ outputs contain valid sequences for labels, we compute the average success rates by checking if (1) models predict at least one index to a sentence and (2) predicted indexes are in the valid range.\n",
      "\n",
      "\n",
      "Path 55: 50.719479233838086\n",
      "Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization,\n",
      "our extractive and abstractive summarization annotations\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "our extractive and abstractive summarization annotations\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "we\n",
      "coref\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "its summarization abilities\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "its summarization abilities\n",
      "the popular Llama 2 model\n",
      "coref\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "the model\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "\n",
      "the model\n",
      "the model\n",
      "coref\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the model\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "subj_obj\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "sentences\n",
      "subj_obj\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "sentences\n",
      "a sentence\n",
      "shared_text\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "To see if models’ outputs contain valid sequences for labels, we compute the average success rates by checking if (1) models predict at least one index to a sentence and (2) predicted indexes are in the valid range.\n",
      "\n",
      "\n",
      "Path 56: 50.719479233838086\n",
      "Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization,\n",
      "our extractive and abstractive summarization annotations\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "our extractive and abstractive summarization annotations\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "we\n",
      "coref\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "its summarization abilities\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "its summarization abilities\n",
      "the popular Llama 2 model\n",
      "coref\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "the model\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "\n",
      "the model\n",
      "the model\n",
      "coref\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the model\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "subj_obj\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "sentences\n",
      "subj_obj\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "sentences\n",
      "a sentence\n",
      "shared_text\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "To see if models’ outputs contain valid sequences for labels, we compute the average success rates by checking if (1) models predict at least one index to a sentence and (2) predicted indexes are in the valid range.\n",
      "\n",
      "\n",
      "Path 57: 50.719479233838086\n",
      "Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization,\n",
      "our extractive and abstractive summarization annotations\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "our extractive and abstractive summarization annotations\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "we\n",
      "coref\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "the popular Llama 2 model\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "the model\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "\n",
      "the model\n",
      "the model\n",
      "coref\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the model\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "subj_obj\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "sentences\n",
      "subj_obj\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "sentences\n",
      "a sentence\n",
      "shared_text\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "To see if models’ outputs contain valid sequences for labels, we compute the average success rates by checking if (1) models predict at least one index to a sentence and (2) predicted indexes are in the valid range.\n",
      "\n",
      "\n",
      "Path 58: 50.719479233838086\n",
      "Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization,\n",
      "our extractive and abstractive summarization annotations\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "our extractive and abstractive summarization annotations\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "we\n",
      "coref\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "the popular Llama 2 model\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "the model\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "\n",
      "the model\n",
      "the model\n",
      "coref\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the model\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "subj_obj\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "sentences\n",
      "subj_obj\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "sentences\n",
      "a sentence\n",
      "shared_text\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "To see if models’ outputs contain valid sequences for labels, we compute the average success rates by checking if (1) models predict at least one index to a sentence and (2) predicted indexes are in the valid range.\n",
      "\n",
      "\n",
      "Path 59: 50.719479233838086\n",
      "Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization,\n",
      "our extractive and abstractive summarization annotations\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "our extractive and abstractive summarization annotations\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "we\n",
      "coref\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "its summarization abilities\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "its summarization abilities\n",
      "the popular Llama 2 model\n",
      "coref\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "the model\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "\n",
      "the model\n",
      "the model\n",
      "coref\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the model\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "subj_obj\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "sentences\n",
      "subj_obj\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "sentences\n",
      "a sentence\n",
      "shared_text\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "To see if models’ outputs contain valid sequences for labels, we compute the average success rates by checking if (1) models predict at least one index to a sentence and (2) predicted indexes are in the valid range.\n",
      "\n",
      "\n",
      "Path 60: 50.719479233838086\n",
      "Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization,\n",
      "our extractive and abstractive summarization annotations\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "our extractive and abstractive summarization annotations\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "we\n",
      "coref\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "its summarization abilities\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "its summarization abilities\n",
      "the popular Llama 2 model\n",
      "coref\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "the model\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "\n",
      "the model\n",
      "the model\n",
      "coref\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the model\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "subj_obj\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "sentences\n",
      "subj_obj\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "sentences\n",
      "a sentence\n",
      "shared_text\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "To see if models’ outputs contain valid sequences for labels, we compute the average success rates by checking if (1) models predict at least one index to a sentence and (2) predicted indexes are in the valid range.\n",
      "\n",
      "\n",
      "Path 61: 51.009474142360816\n",
      "step chain-of-thought or end-to-end abstractive summarization\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "the model\n",
      "subj_obj\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the model\n",
      "the model\n",
      "coref\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "\n",
      "the popular Llama 2 model\n",
      "the Llama 2 model\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "the Llama 2 model\n",
      "We\n",
      "subj_obj\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "We\n",
      "not its instruction-tuned variant\n",
      "subj_obj\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "not its instruction-tuned variant\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "coref\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "performance between Llama 2\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "While it is difficult to compare performance between Llama 2 and T5 due to the massive difference in model sizes (Llama 2: 7B vs. \\text{T5}_{\\textsc{LARGE}}: 770M parameters), the E2E model with Llama 2 substantially outperforms the latter on the Challenge aspect.\n",
      "\n",
      "\n",
      "Path 62: 51.009474142360816\n",
      "step chain-of-thought or end-to-end abstractive summarization\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "the model\n",
      "subj_obj\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the model\n",
      "the model\n",
      "coref\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "\n",
      "the popular Llama 2 model\n",
      "the Llama 2 model\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "the Llama 2 model\n",
      "We\n",
      "subj_obj\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "We\n",
      "not its instruction-tuned variant\n",
      "subj_obj\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "not its instruction-tuned variant\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "coref\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "performance between Llama 2\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "While it is difficult to compare performance between Llama 2 and T5 due to the massive difference in model sizes (Llama 2: 7B vs. \\text{T5}_{\\textsc{LARGE}}: 770M parameters), the E2E model with Llama 2 substantially outperforms the latter on the Challenge aspect.\n",
      "\n",
      "\n",
      "Path 63: 51.009474142360816\n",
      "step chain-of-thought or end-to-end abstractive summarization\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "the model\n",
      "subj_obj\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the model\n",
      "the model\n",
      "coref\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "\n",
      "the popular Llama 2 model\n",
      "the Llama 2 model\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "the Llama 2 model\n",
      "we\n",
      "subj_obj\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "we\n",
      "not its instruction-tuned variant\n",
      "subj_obj\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "not its instruction-tuned variant\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "coref\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "performance between Llama 2\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "While it is difficult to compare performance between Llama 2 and T5 due to the massive difference in model sizes (Llama 2: 7B vs. \\text{T5}_{\\textsc{LARGE}}: 770M parameters), the E2E model with Llama 2 substantially outperforms the latter on the Challenge aspect.\n",
      "\n",
      "\n",
      "Path 64: 51.009474142360816\n",
      "step chain-of-thought or end-to-end abstractive summarization\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "the model\n",
      "subj_obj\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the model\n",
      "the model\n",
      "coref\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "\n",
      "the popular Llama 2 model\n",
      "the Llama 2 model\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "the Llama 2 model\n",
      "we\n",
      "subj_obj\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "we\n",
      "not its instruction-tuned variant\n",
      "subj_obj\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "not its instruction-tuned variant\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "coref\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "performance between Llama 2\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "While it is difficult to compare performance between Llama 2 and T5 due to the massive difference in model sizes (Llama 2: 7B vs. \\text{T5}_{\\textsc{LARGE}}: 770M parameters), the E2E model with Llama 2 substantially outperforms the latter on the Challenge aspect.\n",
      "\n",
      "\n",
      "Path 65: 51.009474142360816\n",
      "step chain-of-thought or end-to-end abstractive summarization\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "the model\n",
      "subj_obj\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the model\n",
      "the model\n",
      "coref\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "\n",
      "its summarization abilities\n",
      "we\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "the popular Llama 2 model\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "the Llama 2 model\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "the Llama 2 model\n",
      "not its instruction-tuned variant\n",
      "coref\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "not its instruction-tuned variant\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "shared_text\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "performance between Llama 2\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "While it is difficult to compare performance between Llama 2 and T5 due to the massive difference in model sizes (Llama 2: 7B vs. \\text{T5}_{\\textsc{LARGE}}: 770M parameters), the E2E model with Llama 2 substantially outperforms the latter on the Challenge aspect.\n",
      "\n",
      "\n",
      "Path 66: 51.009474142360816\n",
      "step chain-of-thought or end-to-end abstractive summarization\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "the model\n",
      "subj_obj\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the model\n",
      "the model\n",
      "coref\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "\n",
      "its summarization abilities\n",
      "we\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "the popular Llama 2 model\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "the Llama 2 model\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "the Llama 2 model\n",
      "not its instruction-tuned variant\n",
      "coref\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "not its instruction-tuned variant\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "shared_text\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "performance between Llama 2\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "While it is difficult to compare performance between Llama 2 and T5 due to the massive difference in model sizes (Llama 2: 7B vs. \\text{T5}_{\\textsc{LARGE}}: 770M parameters), the E2E model with Llama 2 substantially outperforms the latter on the Challenge aspect.\n",
      "\n",
      "\n",
      "Path 67: 51.009474142360816\n",
      "step chain-of-thought or end-to-end abstractive summarization\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "the model\n",
      "subj_obj\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the model\n",
      "the model\n",
      "coref\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "\n",
      "the popular Llama 2 model\n",
      "the Llama 2 model\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "the Llama 2 model\n",
      "We\n",
      "subj_obj\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "We\n",
      "not its instruction-tuned variant\n",
      "subj_obj\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "not its instruction-tuned variant\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "coref\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "performance between Llama 2\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "While it is difficult to compare performance between Llama 2 and T5 due to the massive difference in model sizes (Llama 2: 7B vs. \\text{T5}_{\\textsc{LARGE}}: 770M parameters), the E2E model with Llama 2 substantially outperforms the latter on the Challenge aspect.\n",
      "\n",
      "\n",
      "Path 68: 51.009474142360816\n",
      "step chain-of-thought or end-to-end abstractive summarization\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "the model\n",
      "subj_obj\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the model\n",
      "the model\n",
      "coref\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "\n",
      "the popular Llama 2 model\n",
      "the Llama 2 model\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "the Llama 2 model\n",
      "We\n",
      "subj_obj\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "We\n",
      "not its instruction-tuned variant\n",
      "subj_obj\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "not its instruction-tuned variant\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "coref\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "performance between Llama 2\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "While it is difficult to compare performance between Llama 2 and T5 due to the massive difference in model sizes (Llama 2: 7B vs. \\text{T5}_{\\textsc{LARGE}}: 770M parameters), the E2E model with Llama 2 substantially outperforms the latter on the Challenge aspect.\n",
      "\n",
      "\n",
      "Path 69: 51.009474142360816\n",
      "step chain-of-thought or end-to-end abstractive summarization\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "the model\n",
      "subj_obj\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the model\n",
      "the model\n",
      "coref\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "\n",
      "the popular Llama 2 model\n",
      "the Llama 2 model\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "the Llama 2 model\n",
      "we\n",
      "subj_obj\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "we\n",
      "not its instruction-tuned variant\n",
      "subj_obj\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "not its instruction-tuned variant\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "coref\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "performance between Llama 2\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "While it is difficult to compare performance between Llama 2 and T5 due to the massive difference in model sizes (Llama 2: 7B vs. \\text{T5}_{\\textsc{LARGE}}: 770M parameters), the E2E model with Llama 2 substantially outperforms the latter on the Challenge aspect.\n",
      "\n",
      "\n",
      "Path 70: 51.009474142360816\n",
      "step chain-of-thought or end-to-end abstractive summarization\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "the model\n",
      "subj_obj\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the model\n",
      "the model\n",
      "coref\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "\n",
      "the popular Llama 2 model\n",
      "the Llama 2 model\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "the Llama 2 model\n",
      "we\n",
      "subj_obj\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "we\n",
      "not its instruction-tuned variant\n",
      "subj_obj\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "not its instruction-tuned variant\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "coref\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "performance between Llama 2\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "While it is difficult to compare performance between Llama 2 and T5 due to the massive difference in model sizes (Llama 2: 7B vs. \\text{T5}_{\\textsc{LARGE}}: 770M parameters), the E2E model with Llama 2 substantially outperforms the latter on the Challenge aspect.\n",
      "\n",
      "\n",
      "Path 71: 51.009474142360816\n",
      "step chain-of-thought or end-to-end abstractive summarization\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "the model\n",
      "subj_obj\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the model\n",
      "the model\n",
      "coref\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "\n",
      "its summarization abilities\n",
      "we\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "the popular Llama 2 model\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "the Llama 2 model\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "the Llama 2 model\n",
      "not its instruction-tuned variant\n",
      "coref\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "not its instruction-tuned variant\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "shared_text\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "performance between Llama 2\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "While it is difficult to compare performance between Llama 2 and T5 due to the massive difference in model sizes (Llama 2: 7B vs. \\text{T5}_{\\textsc{LARGE}}: 770M parameters), the E2E model with Llama 2 substantially outperforms the latter on the Challenge aspect.\n",
      "\n",
      "\n",
      "Path 72: 51.009474142360816\n",
      "step chain-of-thought or end-to-end abstractive summarization\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "the model\n",
      "subj_obj\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the model\n",
      "the model\n",
      "coref\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "\n",
      "its summarization abilities\n",
      "we\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "the popular Llama 2 model\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "the Llama 2 model\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "the Llama 2 model\n",
      "not its instruction-tuned variant\n",
      "coref\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "not its instruction-tuned variant\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "shared_text\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "performance between Llama 2\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "While it is difficult to compare performance between Llama 2 and T5 due to the massive difference in model sizes (Llama 2: 7B vs. \\text{T5}_{\\textsc{LARGE}}: 770M parameters), the E2E model with Llama 2 substantially outperforms the latter on the Challenge aspect.\n",
      "\n",
      "\n",
      "Path 73: 51.38830022591823\n",
      "step chain-of-thought or end-to-end abstractive summarization\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "the model\n",
      "subj_obj\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the model\n",
      "the model\n",
      "coref\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "\n",
      "the popular Llama 2 model\n",
      "the Llama 2 model\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "the Llama 2 model\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "shared_text\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "We\n",
      "subj_obj\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "We\n",
      "zero-shot prompting\n",
      "subj_obj\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "zero-shot prompting\n",
      "zero-shot prompting\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "By comparing zero-shot prompting and end-to-end tuning, one can observe that even with LLMs that are shown to be strong in summarization without any training, our dataset can help to improve their performance.\n",
      "\n",
      "\n",
      "Path 74: 51.38830022591823\n",
      "step chain-of-thought or end-to-end abstractive summarization\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "the model\n",
      "subj_obj\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the model\n",
      "the model\n",
      "coref\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "\n",
      "the popular Llama 2 model\n",
      "the Llama 2 model\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "the Llama 2 model\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "shared_text\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "We\n",
      "subj_obj\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "We\n",
      "zero-shot prompting\n",
      "subj_obj\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "zero-shot prompting\n",
      "zero-shot prompting\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "By comparing zero-shot prompting and end-to-end tuning, one can observe that even with LLMs that are shown to be strong in summarization without any training, our dataset can help to improve their performance.\n",
      "\n",
      "\n",
      "Path 75: 51.46555598646964\n",
      "step chain-of-thought or end-to-end abstractive summarization\n",
      "our extractive and abstractive summarization annotations\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "our extractive and abstractive summarization annotations\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "this instruction-tuning dataset\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "this instruction-tuning dataset\n",
      "an instruction\n",
      "shared_text\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "\n",
      "an instruction\n",
      "The first strategy\n",
      "subj_obj\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "\n",
      "The first strategy\n",
      "a summary\n",
      "subj_obj\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "\n",
      "a summary\n",
      "a summary\n",
      "shared_text\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "a summary\n",
      "the summary\n",
      "coref\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the summary\n",
      "sentences\n",
      "subj_obj\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "sentences\n",
      "a sentence\n",
      "shared_text\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "To see if models’ outputs contain valid sequences for labels, we compute the average success rates by checking if (1) models predict at least one index to a sentence and (2) predicted indexes are in the valid range.\n",
      "\n",
      "\n",
      "Path 76: 51.46555598646964\n",
      "step chain-of-thought or end-to-end abstractive summarization\n",
      "our extractive and abstractive summarization annotations\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "our extractive and abstractive summarization annotations\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "this instruction-tuning dataset\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "this instruction-tuning dataset\n",
      "an instruction\n",
      "shared_text\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "\n",
      "an instruction\n",
      "The first strategy\n",
      "subj_obj\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "\n",
      "The first strategy\n",
      "a summary\n",
      "subj_obj\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "\n",
      "a summary\n",
      "a summary\n",
      "shared_text\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "a summary\n",
      "the summary\n",
      "coref\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the summary\n",
      "sentences\n",
      "subj_obj\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "sentences\n",
      "a sentence\n",
      "shared_text\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "To see if models’ outputs contain valid sequences for labels, we compute the average success rates by checking if (1) models predict at least one index to a sentence and (2) predicted indexes are in the valid range.\n",
      "\n",
      "\n",
      "Path 77: 51.71571610768878\n",
      "step chain-of-thought or end-to-end abstractive summarization\n",
      "our extractive and abstractive summarization annotations\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "our extractive and abstractive summarization annotations\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "we\n",
      "coref\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "the popular Llama 2 model\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "the Llama 2 model\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "the Llama 2 model\n",
      "not its instruction-tuned variant\n",
      "coref\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "not its instruction-tuned variant\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "shared_text\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "We\n",
      "subj_obj\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "We\n",
      "zero-shot prompting\n",
      "subj_obj\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "zero-shot prompting\n",
      "zero-shot prompting\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "By comparing zero-shot prompting and end-to-end tuning, one can observe that even with LLMs that are shown to be strong in summarization without any training, our dataset can help to improve their performance.\n",
      "\n",
      "\n",
      "Path 78: 51.71571610768878\n",
      "step chain-of-thought or end-to-end abstractive summarization\n",
      "our extractive and abstractive summarization annotations\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "our extractive and abstractive summarization annotations\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "we\n",
      "coref\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "the popular Llama 2 model\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "the Llama 2 model\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "the Llama 2 model\n",
      "not its instruction-tuned variant\n",
      "coref\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "not its instruction-tuned variant\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "shared_text\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "We\n",
      "subj_obj\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "We\n",
      "zero-shot prompting\n",
      "subj_obj\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "zero-shot prompting\n",
      "zero-shot prompting\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "By comparing zero-shot prompting and end-to-end tuning, one can observe that even with LLMs that are shown to be strong in summarization without any training, our dataset can help to improve their performance.\n",
      "\n",
      "\n",
      "Path 79: 51.71571610768878\n",
      "step chain-of-thought or end-to-end abstractive summarization\n",
      "our extractive and abstractive summarization annotations\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "our extractive and abstractive summarization annotations\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "we\n",
      "coref\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "the popular Llama 2 model\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "the Llama 2 model\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "the Llama 2 model\n",
      "not its instruction-tuned variant\n",
      "coref\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "not its instruction-tuned variant\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "shared_text\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "We\n",
      "subj_obj\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "We\n",
      "zero-shot prompting\n",
      "subj_obj\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "zero-shot prompting\n",
      "zero-shot prompting\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "By comparing zero-shot prompting and end-to-end tuning, one can observe that even with LLMs that are shown to be strong in summarization without any training, our dataset can help to improve their performance.\n",
      "\n",
      "\n",
      "Path 80: 51.71571610768878\n",
      "step chain-of-thought or end-to-end abstractive summarization\n",
      "our extractive and abstractive summarization annotations\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "our extractive and abstractive summarization annotations\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "we\n",
      "coref\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "the popular Llama 2 model\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "the Llama 2 model\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "the Llama 2 model\n",
      "not its instruction-tuned variant\n",
      "coref\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "not its instruction-tuned variant\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "shared_text\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "We\n",
      "subj_obj\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "We\n",
      "zero-shot prompting\n",
      "subj_obj\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "zero-shot prompting\n",
      "zero-shot prompting\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "By comparing zero-shot prompting and end-to-end tuning, one can observe that even with LLMs that are shown to be strong in summarization without any training, our dataset can help to improve their performance.\n",
      "\n",
      "\n",
      "Path 81: 52.086679112598034\n",
      "Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization,\n",
      "our extractive and abstractive summarization annotations\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "our extractive and abstractive summarization annotations\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "this instruction-tuning dataset\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "this instruction-tuning dataset\n",
      "an instruction\n",
      "shared_text\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "\n",
      "an instruction\n",
      "The first strategy\n",
      "subj_obj\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "\n",
      "The first strategy\n",
      "a summary\n",
      "subj_obj\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "\n",
      "a summary\n",
      "a summary\n",
      "shared_text\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "a summary\n",
      "the summary\n",
      "coref\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the summary\n",
      "sentences\n",
      "subj_obj\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "sentences\n",
      "a sentence\n",
      "shared_text\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "To see if models’ outputs contain valid sequences for labels, we compute the average success rates by checking if (1) models predict at least one index to a sentence and (2) predicted indexes are in the valid range.\n",
      "\n",
      "\n",
      "Path 82: 52.086679112598034\n",
      "Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization,\n",
      "our extractive and abstractive summarization annotations\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "our extractive and abstractive summarization annotations\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "this instruction-tuning dataset\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "this instruction-tuning dataset\n",
      "an instruction\n",
      "shared_text\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "\n",
      "an instruction\n",
      "The first strategy\n",
      "subj_obj\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "\n",
      "The first strategy\n",
      "a summary\n",
      "subj_obj\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "\n",
      "a summary\n",
      "a summary\n",
      "shared_text\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "a summary\n",
      "the summary\n",
      "coref\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the summary\n",
      "sentences\n",
      "subj_obj\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "sentences\n",
      "a sentence\n",
      "shared_text\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "To see if models’ outputs contain valid sequences for labels, we compute the average success rates by checking if (1) models predict at least one index to a sentence and (2) predicted indexes are in the valid range.\n",
      "\n",
      "\n",
      "Path 83: 52.21232357601612\n",
      "step chain-of-thought or end-to-end abstractive summarization\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "A training data sample used for EtA-CoT\n",
      "shared_text\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "A training data sample used for EtA-CoT is shown in Table 5.\n",
      "\n",
      "A training data sample used for EtA-CoT\n",
      "EtA-CoT models\n",
      "shared_text\n",
      "A training data sample used for EtA-CoT is shown in Table 5.\n",
      "Table 6 presents ROUGE scores, BERTScores, and extraction performance using our gold extractive labels measured by F1 for EtA-CoT models.\n",
      "\n",
      "\n",
      "Path 84: 52.216974498830076\n",
      "step chain-of-thought or end-to-end abstractive summarization\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "the model\n",
      "subj_obj\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the model\n",
      "the model\n",
      "coref\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "\n",
      "the popular Llama 2 model\n",
      "fine-tune the Llama 2 7B.\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "\n",
      "fine-tune the Llama 2 7B.\n",
      "the Llama 2 model\n",
      "coref\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "not its instruction-tuned variant\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "shared_text\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "performance between Llama 2\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "While it is difficult to compare performance between Llama 2 and T5 due to the massive difference in model sizes (Llama 2: 7B vs. \\text{T5}_{\\textsc{LARGE}}: 770M parameters), the E2E model with Llama 2 substantially outperforms the latter on the Challenge aspect.\n",
      "\n",
      "\n",
      "Path 85: 52.216974498830076\n",
      "step chain-of-thought or end-to-end abstractive summarization\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "the model\n",
      "subj_obj\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the model\n",
      "the model\n",
      "coref\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "\n",
      "the popular Llama 2 model\n",
      "fine-tune the Llama 2 7B.\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "\n",
      "fine-tune the Llama 2 7B.\n",
      "the Llama 2 model\n",
      "coref\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "not its instruction-tuned variant\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "shared_text\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "performance between Llama 2\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "While it is difficult to compare performance between Llama 2 and T5 due to the massive difference in model sizes (Llama 2: 7B vs. \\text{T5}_{\\textsc{LARGE}}: 770M parameters), the E2E model with Llama 2 substantially outperforms the latter on the Challenge aspect.\n",
      "\n",
      "\n",
      "Path 86: 52.216974498830076\n",
      "step chain-of-thought or end-to-end abstractive summarization\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "the model\n",
      "subj_obj\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the model\n",
      "the model\n",
      "coref\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "\n",
      "the popular Llama 2 model\n",
      "fine-tune the Llama 2 7B.\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "\n",
      "fine-tune the Llama 2 7B.\n",
      "the Llama 2 model\n",
      "coref\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "not its instruction-tuned variant\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "shared_text\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "performance between Llama 2\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "While it is difficult to compare performance between Llama 2 and T5 due to the massive difference in model sizes (Llama 2: 7B vs. \\text{T5}_{\\textsc{LARGE}}: 770M parameters), the E2E model with Llama 2 substantially outperforms the latter on the Challenge aspect.\n",
      "\n",
      "\n",
      "Path 87: 52.216974498830076\n",
      "step chain-of-thought or end-to-end abstractive summarization\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "the model\n",
      "subj_obj\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the model\n",
      "the model\n",
      "coref\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "\n",
      "the popular Llama 2 model\n",
      "fine-tune the Llama 2 7B.\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "\n",
      "fine-tune the Llama 2 7B.\n",
      "the Llama 2 model\n",
      "coref\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "not its instruction-tuned variant\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "shared_text\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "performance between Llama 2\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "While it is difficult to compare performance between Llama 2 and T5 due to the massive difference in model sizes (Llama 2: 7B vs. \\text{T5}_{\\textsc{LARGE}}: 770M parameters), the E2E model with Llama 2 substantially outperforms the latter on the Challenge aspect.\n",
      "\n",
      "\n",
      "Path 88: 52.216974498830076\n",
      "step chain-of-thought or end-to-end abstractive summarization\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "the model\n",
      "subj_obj\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the model\n",
      "the model\n",
      "coref\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "\n",
      "the popular Llama 2 model\n",
      "fine-tune the Llama 2 7B.\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "\n",
      "fine-tune the Llama 2 7B.\n",
      "the Llama 2 model\n",
      "coref\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "not its instruction-tuned variant\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "shared_text\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "performance between Llama 2\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "While it is difficult to compare performance between Llama 2 and T5 due to the massive difference in model sizes (Llama 2: 7B vs. \\text{T5}_{\\textsc{LARGE}}: 770M parameters), the E2E model with Llama 2 substantially outperforms the latter on the Challenge aspect.\n",
      "\n",
      "\n",
      "Path 89: 52.216974498830076\n",
      "step chain-of-thought or end-to-end abstractive summarization\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "the model\n",
      "subj_obj\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the model\n",
      "the model\n",
      "coref\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "\n",
      "the popular Llama 2 model\n",
      "fine-tune the Llama 2 7B.\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "\n",
      "fine-tune the Llama 2 7B.\n",
      "the Llama 2 model\n",
      "coref\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "not its instruction-tuned variant\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "shared_text\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "performance between Llama 2\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "While it is difficult to compare performance between Llama 2 and T5 due to the massive difference in model sizes (Llama 2: 7B vs. \\text{T5}_{\\textsc{LARGE}}: 770M parameters), the E2E model with Llama 2 substantially outperforms the latter on the Challenge aspect.\n",
      "\n",
      "\n",
      "Path 90: 52.216974498830076\n",
      "step chain-of-thought or end-to-end abstractive summarization\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "the model\n",
      "subj_obj\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the model\n",
      "the model\n",
      "coref\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "\n",
      "the popular Llama 2 model\n",
      "fine-tune the Llama 2 7B.\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "\n",
      "fine-tune the Llama 2 7B.\n",
      "the Llama 2 model\n",
      "coref\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "not its instruction-tuned variant\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "shared_text\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "performance between Llama 2\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "While it is difficult to compare performance between Llama 2 and T5 due to the massive difference in model sizes (Llama 2: 7B vs. \\text{T5}_{\\textsc{LARGE}}: 770M parameters), the E2E model with Llama 2 substantially outperforms the latter on the Challenge aspect.\n",
      "\n",
      "\n",
      "Path 91: 52.216974498830076\n",
      "step chain-of-thought or end-to-end abstractive summarization\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "the model\n",
      "subj_obj\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the model\n",
      "the model\n",
      "coref\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "\n",
      "the popular Llama 2 model\n",
      "fine-tune the Llama 2 7B.\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "\n",
      "fine-tune the Llama 2 7B.\n",
      "the Llama 2 model\n",
      "coref\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "not its instruction-tuned variant\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "shared_text\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "performance between Llama 2\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "While it is difficult to compare performance between Llama 2 and T5 due to the massive difference in model sizes (Llama 2: 7B vs. \\text{T5}_{\\textsc{LARGE}}: 770M parameters), the E2E model with Llama 2 substantially outperforms the latter on the Challenge aspect.\n",
      "\n",
      "\n",
      "Path 92: 52.33683923381717\n",
      "Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization,\n",
      "our extractive and abstractive summarization annotations\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "our extractive and abstractive summarization annotations\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "we\n",
      "coref\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "the popular Llama 2 model\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "the Llama 2 model\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "the Llama 2 model\n",
      "not its instruction-tuned variant\n",
      "coref\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "not its instruction-tuned variant\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "shared_text\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "We\n",
      "subj_obj\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "We\n",
      "zero-shot prompting\n",
      "subj_obj\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "zero-shot prompting\n",
      "zero-shot prompting\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "By comparing zero-shot prompting and end-to-end tuning, one can observe that even with LLMs that are shown to be strong in summarization without any training, our dataset can help to improve their performance.\n",
      "\n",
      "\n",
      "Path 93: 52.33683923381717\n",
      "Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization,\n",
      "our extractive and abstractive summarization annotations\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "our extractive and abstractive summarization annotations\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "we\n",
      "coref\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "the popular Llama 2 model\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "the Llama 2 model\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "the Llama 2 model\n",
      "not its instruction-tuned variant\n",
      "coref\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "not its instruction-tuned variant\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "shared_text\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "We\n",
      "subj_obj\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "We\n",
      "zero-shot prompting\n",
      "subj_obj\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "zero-shot prompting\n",
      "zero-shot prompting\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "By comparing zero-shot prompting and end-to-end tuning, one can observe that even with LLMs that are shown to be strong in summarization without any training, our dataset can help to improve their performance.\n",
      "\n",
      "\n",
      "Path 94: 52.33683923381717\n",
      "Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization,\n",
      "our extractive and abstractive summarization annotations\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "our extractive and abstractive summarization annotations\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "we\n",
      "coref\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "the popular Llama 2 model\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "the Llama 2 model\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "the Llama 2 model\n",
      "not its instruction-tuned variant\n",
      "coref\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "not its instruction-tuned variant\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "shared_text\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "We\n",
      "subj_obj\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "We\n",
      "zero-shot prompting\n",
      "subj_obj\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "zero-shot prompting\n",
      "zero-shot prompting\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "By comparing zero-shot prompting and end-to-end tuning, one can observe that even with LLMs that are shown to be strong in summarization without any training, our dataset can help to improve their performance.\n",
      "\n",
      "\n",
      "Path 95: 52.33683923381717\n",
      "Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization,\n",
      "our extractive and abstractive summarization annotations\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "our extractive and abstractive summarization annotations\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "we\n",
      "coref\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "the popular Llama 2 model\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "the Llama 2 model\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "the Llama 2 model\n",
      "not its instruction-tuned variant\n",
      "coref\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "not its instruction-tuned variant\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "shared_text\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "We\n",
      "subj_obj\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "We\n",
      "zero-shot prompting\n",
      "subj_obj\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "zero-shot prompting\n",
      "zero-shot prompting\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "By comparing zero-shot prompting and end-to-end tuning, one can observe that even with LLMs that are shown to be strong in summarization without any training, our dataset can help to improve their performance.\n",
      "\n",
      "\n",
      "Path 96: 52.46555598646964\n",
      "step chain-of-thought or end-to-end abstractive summarization\n",
      "our extractive and abstractive summarization annotations\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "our extractive and abstractive summarization annotations\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "this instruction-tuning dataset\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "this instruction-tuning dataset\n",
      "an instruction\n",
      "shared_text\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "\n",
      "an instruction\n",
      "The first strategy\n",
      "subj_obj\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "\n",
      "The first strategy\n",
      "a summary\n",
      "subj_obj\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "\n",
      "a summary\n",
      "a summary\n",
      "shared_text\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "a summary\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "subj_obj\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "sentences\n",
      "subj_obj\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "sentences\n",
      "a sentence\n",
      "shared_text\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "To see if models’ outputs contain valid sequences for labels, we compute the average success rates by checking if (1) models predict at least one index to a sentence and (2) predicted indexes are in the valid range.\n",
      "\n",
      "\n",
      "Path 97: 52.46555598646964\n",
      "step chain-of-thought or end-to-end abstractive summarization\n",
      "our extractive and abstractive summarization annotations\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "our extractive and abstractive summarization annotations\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "this instruction-tuning dataset\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "this instruction-tuning dataset\n",
      "an instruction\n",
      "shared_text\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "\n",
      "an instruction\n",
      "The first strategy\n",
      "subj_obj\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "\n",
      "The first strategy\n",
      "a summary\n",
      "subj_obj\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "\n",
      "a summary\n",
      "a summary\n",
      "shared_text\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "a summary\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "subj_obj\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "sentences\n",
      "subj_obj\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "sentences\n",
      "a sentence\n",
      "shared_text\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "To see if models’ outputs contain valid sequences for labels, we compute the average success rates by checking if (1) models predict at least one index to a sentence and (2) predicted indexes are in the valid range.\n",
      "\n",
      "\n",
      "Path 98: 52.54393487846285\n",
      "step chain-of-thought or end-to-end abstractive summarization\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "the model\n",
      "subj_obj\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the model\n",
      "the model\n",
      "coref\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "\n",
      "the model\n",
      "the popular Llama 2 model\n",
      "shared_text\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "the Llama 2 model\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "the Llama 2 model\n",
      "We\n",
      "subj_obj\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "We\n",
      "not its instruction-tuned variant\n",
      "subj_obj\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "not its instruction-tuned variant\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "coref\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "performance between Llama 2\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "While it is difficult to compare performance between Llama 2 and T5 due to the massive difference in model sizes (Llama 2: 7B vs. \\text{T5}_{\\textsc{LARGE}}: 770M parameters), the E2E model with Llama 2 substantially outperforms the latter on the Challenge aspect.\n",
      "\n",
      "\n",
      "Path 99: 52.54393487846285\n",
      "step chain-of-thought or end-to-end abstractive summarization\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "the model\n",
      "subj_obj\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the model\n",
      "the model\n",
      "coref\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "\n",
      "the model\n",
      "the popular Llama 2 model\n",
      "shared_text\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "the Llama 2 model\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "the Llama 2 model\n",
      "We\n",
      "subj_obj\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "We\n",
      "not its instruction-tuned variant\n",
      "subj_obj\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "not its instruction-tuned variant\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "coref\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "performance between Llama 2\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "While it is difficult to compare performance between Llama 2 and T5 due to the massive difference in model sizes (Llama 2: 7B vs. \\text{T5}_{\\textsc{LARGE}}: 770M parameters), the E2E model with Llama 2 substantially outperforms the latter on the Challenge aspect.\n",
      "\n",
      "\n",
      "Path 100: 52.54393487846285\n",
      "step chain-of-thought or end-to-end abstractive summarization\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "the model\n",
      "subj_obj\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the model\n",
      "the model\n",
      "coref\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "\n",
      "the model\n",
      "the popular Llama 2 model\n",
      "shared_text\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "the Llama 2 model\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "the Llama 2 model\n",
      "we\n",
      "subj_obj\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "we\n",
      "not its instruction-tuned variant\n",
      "subj_obj\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "not its instruction-tuned variant\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "coref\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "performance between Llama 2\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "While it is difficult to compare performance between Llama 2 and T5 due to the massive difference in model sizes (Llama 2: 7B vs. \\text{T5}_{\\textsc{LARGE}}: 770M parameters), the E2E model with Llama 2 substantially outperforms the latter on the Challenge aspect.\n",
      "\n",
      "\n",
      "Path 101: 52.54393487846285\n",
      "step chain-of-thought or end-to-end abstractive summarization\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "the model\n",
      "subj_obj\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the model\n",
      "the model\n",
      "coref\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "\n",
      "the model\n",
      "the popular Llama 2 model\n",
      "shared_text\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "the Llama 2 model\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "the Llama 2 model\n",
      "we\n",
      "subj_obj\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "we\n",
      "not its instruction-tuned variant\n",
      "subj_obj\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "not its instruction-tuned variant\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "coref\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "performance between Llama 2\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "While it is difficult to compare performance between Llama 2 and T5 due to the massive difference in model sizes (Llama 2: 7B vs. \\text{T5}_{\\textsc{LARGE}}: 770M parameters), the E2E model with Llama 2 substantially outperforms the latter on the Challenge aspect.\n",
      "\n",
      "\n",
      "Path 102: 52.54393487846285\n",
      "step chain-of-thought or end-to-end abstractive summarization\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "the model\n",
      "subj_obj\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the model\n",
      "the model\n",
      "coref\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "\n",
      "the model\n",
      "the popular Llama 2 model\n",
      "shared_text\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "the Llama 2 model\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "the Llama 2 model\n",
      "We\n",
      "subj_obj\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "We\n",
      "not its instruction-tuned variant\n",
      "subj_obj\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "not its instruction-tuned variant\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "coref\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "performance between Llama 2\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "While it is difficult to compare performance between Llama 2 and T5 due to the massive difference in model sizes (Llama 2: 7B vs. \\text{T5}_{\\textsc{LARGE}}: 770M parameters), the E2E model with Llama 2 substantially outperforms the latter on the Challenge aspect.\n",
      "\n",
      "\n",
      "Path 103: 52.54393487846285\n",
      "step chain-of-thought or end-to-end abstractive summarization\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "the model\n",
      "subj_obj\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the model\n",
      "the model\n",
      "coref\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "\n",
      "the model\n",
      "the popular Llama 2 model\n",
      "shared_text\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "the Llama 2 model\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "the Llama 2 model\n",
      "We\n",
      "subj_obj\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "We\n",
      "not its instruction-tuned variant\n",
      "subj_obj\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "not its instruction-tuned variant\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "coref\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "performance between Llama 2\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "While it is difficult to compare performance between Llama 2 and T5 due to the massive difference in model sizes (Llama 2: 7B vs. \\text{T5}_{\\textsc{LARGE}}: 770M parameters), the E2E model with Llama 2 substantially outperforms the latter on the Challenge aspect.\n",
      "\n",
      "\n",
      "Path 104: 52.54393487846285\n",
      "step chain-of-thought or end-to-end abstractive summarization\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "the model\n",
      "subj_obj\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the model\n",
      "the model\n",
      "coref\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "\n",
      "the model\n",
      "the popular Llama 2 model\n",
      "shared_text\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "the Llama 2 model\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "the Llama 2 model\n",
      "we\n",
      "subj_obj\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "we\n",
      "not its instruction-tuned variant\n",
      "subj_obj\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "not its instruction-tuned variant\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "coref\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "performance between Llama 2\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "While it is difficult to compare performance between Llama 2 and T5 due to the massive difference in model sizes (Llama 2: 7B vs. \\text{T5}_{\\textsc{LARGE}}: 770M parameters), the E2E model with Llama 2 substantially outperforms the latter on the Challenge aspect.\n",
      "\n",
      "\n",
      "Path 105: 52.54393487846285\n",
      "step chain-of-thought or end-to-end abstractive summarization\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "the model\n",
      "subj_obj\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the model\n",
      "the model\n",
      "coref\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "\n",
      "the model\n",
      "the popular Llama 2 model\n",
      "shared_text\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "the Llama 2 model\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "the Llama 2 model\n",
      "we\n",
      "subj_obj\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "we\n",
      "not its instruction-tuned variant\n",
      "subj_obj\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "not its instruction-tuned variant\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "coref\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "performance between Llama 2\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "While it is difficult to compare performance between Llama 2 and T5 due to the massive difference in model sizes (Llama 2: 7B vs. \\text{T5}_{\\textsc{LARGE}}: 770M parameters), the E2E model with Llama 2 substantially outperforms the latter on the Challenge aspect.\n",
      "\n",
      "\n",
      "Path 106: 52.92276096202026\n",
      "step chain-of-thought or end-to-end abstractive summarization\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "the model\n",
      "subj_obj\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the model\n",
      "the model\n",
      "coref\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "\n",
      "the model\n",
      "the popular Llama 2 model\n",
      "shared_text\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "the Llama 2 model\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "the Llama 2 model\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "shared_text\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "We\n",
      "subj_obj\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "We\n",
      "results\n",
      "subj_obj\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "results\n",
      "Results\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "Results and discussions.\n",
      "\n",
      "Results\n",
      "This result\n",
      "shared_text\n",
      "Results and discussions.\n",
      "This result shows that the models have learned the required output structure yet perform poorly on prediction.\n",
      "\n",
      "\n",
      "Path 107: 52.92276096202026\n",
      "step chain-of-thought or end-to-end abstractive summarization\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "the model\n",
      "subj_obj\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the model\n",
      "the model\n",
      "coref\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "\n",
      "the model\n",
      "the popular Llama 2 model\n",
      "shared_text\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "the Llama 2 model\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "the Llama 2 model\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "shared_text\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "We\n",
      "subj_obj\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "We\n",
      "results\n",
      "subj_obj\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "results\n",
      "Results\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "Results and discussions.\n",
      "\n",
      "Results\n",
      "This result\n",
      "shared_text\n",
      "Results and discussions.\n",
      "This result shows that the models have learned the required output structure yet perform poorly on prediction.\n",
      "\n",
      "\n",
      "Path 108: 52.92276096202026\n",
      "step chain-of-thought or end-to-end abstractive summarization\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "the model\n",
      "subj_obj\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the model\n",
      "the model\n",
      "coref\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "\n",
      "the model\n",
      "the popular Llama 2 model\n",
      "shared_text\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "the Llama 2 model\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "the Llama 2 model\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "shared_text\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "We\n",
      "subj_obj\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "We\n",
      "zero-shot prompting\n",
      "subj_obj\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "zero-shot prompting\n",
      "zero-shot prompting\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "By comparing zero-shot prompting and end-to-end tuning, one can observe that even with LLMs that are shown to be strong in summarization without any training, our dataset can help to improve their performance.\n",
      "\n",
      "\n",
      "Path 109: 52.92276096202026\n",
      "step chain-of-thought or end-to-end abstractive summarization\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "the model\n",
      "subj_obj\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the model\n",
      "the model\n",
      "coref\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "\n",
      "the model\n",
      "the popular Llama 2 model\n",
      "shared_text\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "the Llama 2 model\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "the Llama 2 model\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "shared_text\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "We\n",
      "subj_obj\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "We\n",
      "zero-shot prompting\n",
      "subj_obj\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "zero-shot prompting\n",
      "zero-shot prompting\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "By comparing zero-shot prompting and end-to-end tuning, one can observe that even with LLMs that are shown to be strong in summarization without any training, our dataset can help to improve their performance.\n",
      "\n",
      "\n",
      "Path 110: 53.08039177795709\n",
      "step chain-of-thought or end-to-end abstractive summarization\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "the model\n",
      "subj_obj\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the model\n",
      "the model\n",
      "coref\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "\n",
      "the popular Llama 2 model\n",
      "the Llama 2 model\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "the Llama 2 model\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "shared_text\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "performance between Llama 2\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "While it is difficult to compare performance between Llama 2 and T5 due to the massive difference in model sizes (Llama 2: 7B vs. \\text{T5}_{\\textsc{LARGE}}: 770M parameters), the E2E model with Llama 2 substantially outperforms the latter on the Challenge aspect.\n",
      "\n",
      "\n",
      "Path 111: 53.08039177795709\n",
      "step chain-of-thought or end-to-end abstractive summarization\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "the model\n",
      "subj_obj\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the model\n",
      "the model\n",
      "coref\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "\n",
      "the popular Llama 2 model\n",
      "the Llama 2 model\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "the Llama 2 model\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "shared_text\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "performance between Llama 2\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "While it is difficult to compare performance between Llama 2 and T5 due to the massive difference in model sizes (Llama 2: 7B vs. \\text{T5}_{\\textsc{LARGE}}: 770M parameters), the E2E model with Llama 2 substantially outperforms the latter on the Challenge aspect.\n",
      "\n",
      "\n",
      "Path 112: 53.086679112598034\n",
      "Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization,\n",
      "our extractive and abstractive summarization annotations\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "our extractive and abstractive summarization annotations\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "this instruction-tuning dataset\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "this instruction-tuning dataset\n",
      "an instruction\n",
      "shared_text\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "\n",
      "an instruction\n",
      "The first strategy\n",
      "subj_obj\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "\n",
      "The first strategy\n",
      "a summary\n",
      "subj_obj\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "\n",
      "a summary\n",
      "a summary\n",
      "shared_text\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "a summary\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "subj_obj\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "sentences\n",
      "subj_obj\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "sentences\n",
      "a sentence\n",
      "shared_text\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "To see if models’ outputs contain valid sequences for labels, we compute the average success rates by checking if (1) models predict at least one index to a sentence and (2) predicted indexes are in the valid range.\n",
      "\n",
      "\n",
      "Path 113: 53.086679112598034\n",
      "Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization,\n",
      "our extractive and abstractive summarization annotations\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "our extractive and abstractive summarization annotations\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "this instruction-tuning dataset\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "this instruction-tuning dataset\n",
      "an instruction\n",
      "shared_text\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "\n",
      "an instruction\n",
      "The first strategy\n",
      "subj_obj\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "\n",
      "The first strategy\n",
      "a summary\n",
      "subj_obj\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "\n",
      "a summary\n",
      "a summary\n",
      "shared_text\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "a summary\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "subj_obj\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "sentences\n",
      "subj_obj\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "sentences\n",
      "a sentence\n",
      "shared_text\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "To see if models’ outputs contain valid sequences for labels, we compute the average success rates by checking if (1) models predict at least one index to a sentence and (2) predicted indexes are in the valid range.\n",
      "\n",
      "\n",
      "Path 114: 53.40780765972764\n",
      "step chain-of-thought or end-to-end abstractive summarization\n",
      "our extractive and abstractive summarization annotations\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "our extractive and abstractive summarization annotations\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "we\n",
      "coref\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "the popular Llama 2 model\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "the Llama 2 model\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "the Llama 2 model\n",
      "not its instruction-tuned variant\n",
      "coref\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "not its instruction-tuned variant\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "shared_text\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "performance between Llama 2\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "While it is difficult to compare performance between Llama 2 and T5 due to the massive difference in model sizes (Llama 2: 7B vs. \\text{T5}_{\\textsc{LARGE}}: 770M parameters), the E2E model with Llama 2 substantially outperforms the latter on the Challenge aspect.\n",
      "\n",
      "\n",
      "Path 115: 53.40780765972764\n",
      "step chain-of-thought or end-to-end abstractive summarization\n",
      "our extractive and abstractive summarization annotations\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "our extractive and abstractive summarization annotations\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "we\n",
      "coref\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "the popular Llama 2 model\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "the Llama 2 model\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "the Llama 2 model\n",
      "not its instruction-tuned variant\n",
      "coref\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "not its instruction-tuned variant\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "shared_text\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "performance between Llama 2\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "While it is difficult to compare performance between Llama 2 and T5 due to the massive difference in model sizes (Llama 2: 7B vs. \\text{T5}_{\\textsc{LARGE}}: 770M parameters), the E2E model with Llama 2 substantially outperforms the latter on the Challenge aspect.\n",
      "\n",
      "\n",
      "Path 116: 53.40780765972764\n",
      "step chain-of-thought or end-to-end abstractive summarization\n",
      "our extractive and abstractive summarization annotations\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "our extractive and abstractive summarization annotations\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "we\n",
      "coref\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "its summarization abilities\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "its summarization abilities\n",
      "the popular Llama 2 model\n",
      "coref\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "the Llama 2 model\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "the Llama 2 model\n",
      "not its instruction-tuned variant\n",
      "coref\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "not its instruction-tuned variant\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "shared_text\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "performance between Llama 2\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "While it is difficult to compare performance between Llama 2 and T5 due to the massive difference in model sizes (Llama 2: 7B vs. \\text{T5}_{\\textsc{LARGE}}: 770M parameters), the E2E model with Llama 2 substantially outperforms the latter on the Challenge aspect.\n",
      "\n",
      "\n",
      "Path 117: 53.40780765972764\n",
      "step chain-of-thought or end-to-end abstractive summarization\n",
      "our extractive and abstractive summarization annotations\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "our extractive and abstractive summarization annotations\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "we\n",
      "coref\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "its summarization abilities\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "its summarization abilities\n",
      "the popular Llama 2 model\n",
      "coref\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "the Llama 2 model\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "the Llama 2 model\n",
      "not its instruction-tuned variant\n",
      "coref\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "not its instruction-tuned variant\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "shared_text\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "performance between Llama 2\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "While it is difficult to compare performance between Llama 2 and T5 due to the massive difference in model sizes (Llama 2: 7B vs. \\text{T5}_{\\textsc{LARGE}}: 770M parameters), the E2E model with Llama 2 substantially outperforms the latter on the Challenge aspect.\n",
      "\n",
      "\n",
      "Path 118: 53.40780765972764\n",
      "step chain-of-thought or end-to-end abstractive summarization\n",
      "our extractive and abstractive summarization annotations\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "our extractive and abstractive summarization annotations\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "we\n",
      "coref\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "the popular Llama 2 model\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "the Llama 2 model\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "the Llama 2 model\n",
      "not its instruction-tuned variant\n",
      "coref\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "not its instruction-tuned variant\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "shared_text\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "performance between Llama 2\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "While it is difficult to compare performance between Llama 2 and T5 due to the massive difference in model sizes (Llama 2: 7B vs. \\text{T5}_{\\textsc{LARGE}}: 770M parameters), the E2E model with Llama 2 substantially outperforms the latter on the Challenge aspect.\n",
      "\n",
      "\n",
      "Path 119: 53.40780765972764\n",
      "step chain-of-thought or end-to-end abstractive summarization\n",
      "our extractive and abstractive summarization annotations\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "our extractive and abstractive summarization annotations\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "we\n",
      "coref\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "the popular Llama 2 model\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "the Llama 2 model\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "the Llama 2 model\n",
      "not its instruction-tuned variant\n",
      "coref\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "not its instruction-tuned variant\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "shared_text\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "performance between Llama 2\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "While it is difficult to compare performance between Llama 2 and T5 due to the massive difference in model sizes (Llama 2: 7B vs. \\text{T5}_{\\textsc{LARGE}}: 770M parameters), the E2E model with Llama 2 substantially outperforms the latter on the Challenge aspect.\n",
      "\n",
      "\n",
      "Path 120: 53.40780765972764\n",
      "step chain-of-thought or end-to-end abstractive summarization\n",
      "our extractive and abstractive summarization annotations\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "our extractive and abstractive summarization annotations\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "we\n",
      "coref\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "its summarization abilities\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "its summarization abilities\n",
      "the popular Llama 2 model\n",
      "coref\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "the Llama 2 model\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "the Llama 2 model\n",
      "not its instruction-tuned variant\n",
      "coref\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "not its instruction-tuned variant\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "shared_text\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "performance between Llama 2\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "While it is difficult to compare performance between Llama 2 and T5 due to the massive difference in model sizes (Llama 2: 7B vs. \\text{T5}_{\\textsc{LARGE}}: 770M parameters), the E2E model with Llama 2 substantially outperforms the latter on the Challenge aspect.\n",
      "\n",
      "\n",
      "Path 121: 53.40780765972764\n",
      "step chain-of-thought or end-to-end abstractive summarization\n",
      "our extractive and abstractive summarization annotations\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "our extractive and abstractive summarization annotations\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "we\n",
      "coref\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "its summarization abilities\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "its summarization abilities\n",
      "the popular Llama 2 model\n",
      "coref\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "the Llama 2 model\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "the Llama 2 model\n",
      "not its instruction-tuned variant\n",
      "coref\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "not its instruction-tuned variant\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "shared_text\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "performance between Llama 2\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "While it is difficult to compare performance between Llama 2 and T5 due to the massive difference in model sizes (Llama 2: 7B vs. \\text{T5}_{\\textsc{LARGE}}: 770M parameters), the E2E model with Llama 2 substantially outperforms the latter on the Challenge aspect.\n",
      "\n",
      "\n",
      "Path 122: 53.54393487846285\n",
      "step chain-of-thought or end-to-end abstractive summarization\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "the model\n",
      "subj_obj\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the model\n",
      "the model\n",
      "coref\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "\n",
      "the model\n",
      "the popular Llama 2 model\n",
      "shared_text\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "the Llama 2 model\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "the Llama 2 model\n",
      "We\n",
      "subj_obj\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "We\n",
      "we\n",
      "subj_obj\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "we\n",
      "not its instruction-tuned variant\n",
      "subj_obj\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "not its instruction-tuned variant\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "coref\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "performance between Llama 2\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "While it is difficult to compare performance between Llama 2 and T5 due to the massive difference in model sizes (Llama 2: 7B vs. \\text{T5}_{\\textsc{LARGE}}: 770M parameters), the E2E model with Llama 2 substantially outperforms the latter on the Challenge aspect.\n",
      "\n",
      "\n",
      "Path 123: 53.54393487846285\n",
      "step chain-of-thought or end-to-end abstractive summarization\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "the model\n",
      "subj_obj\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the model\n",
      "the model\n",
      "coref\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "\n",
      "the model\n",
      "the popular Llama 2 model\n",
      "shared_text\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "the Llama 2 model\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "the Llama 2 model\n",
      "We\n",
      "subj_obj\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "We\n",
      "we\n",
      "subj_obj\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "we\n",
      "not its instruction-tuned variant\n",
      "subj_obj\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "not its instruction-tuned variant\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "coref\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "performance between Llama 2\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "While it is difficult to compare performance between Llama 2 and T5 due to the massive difference in model sizes (Llama 2: 7B vs. \\text{T5}_{\\textsc{LARGE}}: 770M parameters), the E2E model with Llama 2 substantially outperforms the latter on the Challenge aspect.\n",
      "\n",
      "\n",
      "Path 124: 53.54393487846285\n",
      "step chain-of-thought or end-to-end abstractive summarization\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "the model\n",
      "subj_obj\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the model\n",
      "the model\n",
      "coref\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "\n",
      "the model\n",
      "the popular Llama 2 model\n",
      "shared_text\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "the Llama 2 model\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "the Llama 2 model\n",
      "we\n",
      "subj_obj\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "we\n",
      "We\n",
      "subj_obj\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "We\n",
      "not its instruction-tuned variant\n",
      "subj_obj\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "not its instruction-tuned variant\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "coref\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "performance between Llama 2\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "While it is difficult to compare performance between Llama 2 and T5 due to the massive difference in model sizes (Llama 2: 7B vs. \\text{T5}_{\\textsc{LARGE}}: 770M parameters), the E2E model with Llama 2 substantially outperforms the latter on the Challenge aspect.\n",
      "\n",
      "\n",
      "Path 125: 53.54393487846285\n",
      "step chain-of-thought or end-to-end abstractive summarization\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "the model\n",
      "subj_obj\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the model\n",
      "the model\n",
      "coref\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "\n",
      "the model\n",
      "the popular Llama 2 model\n",
      "shared_text\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "the Llama 2 model\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "the Llama 2 model\n",
      "we\n",
      "subj_obj\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "we\n",
      "We\n",
      "subj_obj\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "We\n",
      "not its instruction-tuned variant\n",
      "subj_obj\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "not its instruction-tuned variant\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "coref\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "performance between Llama 2\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "While it is difficult to compare performance between Llama 2 and T5 due to the massive difference in model sizes (Llama 2: 7B vs. \\text{T5}_{\\textsc{LARGE}}: 770M parameters), the E2E model with Llama 2 substantially outperforms the latter on the Challenge aspect.\n",
      "\n",
      "\n",
      "Path 126: 53.54393487846285\n",
      "step chain-of-thought or end-to-end abstractive summarization\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "the model\n",
      "subj_obj\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the model\n",
      "the model\n",
      "coref\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "\n",
      "the model\n",
      "the popular Llama 2 model\n",
      "shared_text\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "the Llama 2 model\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "the Llama 2 model\n",
      "We\n",
      "subj_obj\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "We\n",
      "we\n",
      "subj_obj\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "we\n",
      "not its instruction-tuned variant\n",
      "subj_obj\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "not its instruction-tuned variant\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "coref\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "performance between Llama 2\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "While it is difficult to compare performance between Llama 2 and T5 due to the massive difference in model sizes (Llama 2: 7B vs. \\text{T5}_{\\textsc{LARGE}}: 770M parameters), the E2E model with Llama 2 substantially outperforms the latter on the Challenge aspect.\n",
      "\n",
      "\n",
      "Path 127: 53.54393487846285\n",
      "step chain-of-thought or end-to-end abstractive summarization\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "the model\n",
      "subj_obj\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the model\n",
      "the model\n",
      "coref\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "\n",
      "the model\n",
      "the popular Llama 2 model\n",
      "shared_text\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "the Llama 2 model\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "the Llama 2 model\n",
      "We\n",
      "subj_obj\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "We\n",
      "we\n",
      "subj_obj\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "we\n",
      "not its instruction-tuned variant\n",
      "subj_obj\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "not its instruction-tuned variant\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "coref\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "performance between Llama 2\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "While it is difficult to compare performance between Llama 2 and T5 due to the massive difference in model sizes (Llama 2: 7B vs. \\text{T5}_{\\textsc{LARGE}}: 770M parameters), the E2E model with Llama 2 substantially outperforms the latter on the Challenge aspect.\n",
      "\n",
      "\n",
      "Path 128: 53.54393487846285\n",
      "step chain-of-thought or end-to-end abstractive summarization\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "the model\n",
      "subj_obj\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the model\n",
      "the model\n",
      "coref\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "\n",
      "the model\n",
      "the popular Llama 2 model\n",
      "shared_text\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "the Llama 2 model\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "the Llama 2 model\n",
      "we\n",
      "subj_obj\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "we\n",
      "We\n",
      "subj_obj\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "We\n",
      "not its instruction-tuned variant\n",
      "subj_obj\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "not its instruction-tuned variant\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "coref\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "performance between Llama 2\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "While it is difficult to compare performance between Llama 2 and T5 due to the massive difference in model sizes (Llama 2: 7B vs. \\text{T5}_{\\textsc{LARGE}}: 770M parameters), the E2E model with Llama 2 substantially outperforms the latter on the Challenge aspect.\n",
      "\n",
      "\n",
      "Path 129: 53.54393487846285\n",
      "step chain-of-thought or end-to-end abstractive summarization\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "the model\n",
      "subj_obj\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the model\n",
      "the model\n",
      "coref\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "\n",
      "the model\n",
      "the popular Llama 2 model\n",
      "shared_text\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "the Llama 2 model\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "the Llama 2 model\n",
      "we\n",
      "subj_obj\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "we\n",
      "We\n",
      "subj_obj\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "We\n",
      "not its instruction-tuned variant\n",
      "subj_obj\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "not its instruction-tuned variant\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "coref\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "performance between Llama 2\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "While it is difficult to compare performance between Llama 2 and T5 due to the massive difference in model sizes (Llama 2: 7B vs. \\text{T5}_{\\textsc{LARGE}}: 770M parameters), the E2E model with Llama 2 substantially outperforms the latter on the Challenge aspect.\n",
      "\n",
      "\n",
      "Path 130: 53.75143523493211\n",
      "step chain-of-thought or end-to-end abstractive summarization\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "the model\n",
      "subj_obj\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the model\n",
      "the model\n",
      "coref\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "\n",
      "the model\n",
      "the popular Llama 2 model\n",
      "shared_text\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "fine-tune the Llama 2 7B.\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "\n",
      "fine-tune the Llama 2 7B.\n",
      "the Llama 2 model\n",
      "coref\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "not its instruction-tuned variant\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "shared_text\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "performance between Llama 2\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "While it is difficult to compare performance between Llama 2 and T5 due to the massive difference in model sizes (Llama 2: 7B vs. \\text{T5}_{\\textsc{LARGE}}: 770M parameters), the E2E model with Llama 2 substantially outperforms the latter on the Challenge aspect.\n",
      "\n",
      "\n",
      "Path 131: 53.75143523493211\n",
      "step chain-of-thought or end-to-end abstractive summarization\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "the model\n",
      "subj_obj\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the model\n",
      "the model\n",
      "coref\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "\n",
      "the model\n",
      "the popular Llama 2 model\n",
      "shared_text\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "fine-tune the Llama 2 7B.\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "\n",
      "fine-tune the Llama 2 7B.\n",
      "the Llama 2 model\n",
      "coref\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "not its instruction-tuned variant\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "shared_text\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "performance between Llama 2\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "While it is difficult to compare performance between Llama 2 and T5 due to the massive difference in model sizes (Llama 2: 7B vs. \\text{T5}_{\\textsc{LARGE}}: 770M parameters), the E2E model with Llama 2 substantially outperforms the latter on the Challenge aspect.\n",
      "\n",
      "\n",
      "Path 132: 53.75143523493211\n",
      "step chain-of-thought or end-to-end abstractive summarization\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "the model\n",
      "subj_obj\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the model\n",
      "the model\n",
      "coref\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "\n",
      "the model\n",
      "the popular Llama 2 model\n",
      "shared_text\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "fine-tune the Llama 2 7B.\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "\n",
      "fine-tune the Llama 2 7B.\n",
      "the Llama 2 model\n",
      "coref\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "not its instruction-tuned variant\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "shared_text\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "performance between Llama 2\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "While it is difficult to compare performance between Llama 2 and T5 due to the massive difference in model sizes (Llama 2: 7B vs. \\text{T5}_{\\textsc{LARGE}}: 770M parameters), the E2E model with Llama 2 substantially outperforms the latter on the Challenge aspect.\n",
      "\n",
      "\n",
      "Path 133: 53.75143523493211\n",
      "step chain-of-thought or end-to-end abstractive summarization\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "the model\n",
      "subj_obj\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the model\n",
      "the model\n",
      "coref\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "\n",
      "the model\n",
      "the popular Llama 2 model\n",
      "shared_text\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "fine-tune the Llama 2 7B.\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "\n",
      "fine-tune the Llama 2 7B.\n",
      "the Llama 2 model\n",
      "coref\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "not its instruction-tuned variant\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "shared_text\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "performance between Llama 2\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "While it is difficult to compare performance between Llama 2 and T5 due to the massive difference in model sizes (Llama 2: 7B vs. \\text{T5}_{\\textsc{LARGE}}: 770M parameters), the E2E model with Llama 2 substantially outperforms the latter on the Challenge aspect.\n",
      "\n",
      "\n",
      "Path 134: 53.75143523493211\n",
      "step chain-of-thought or end-to-end abstractive summarization\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "the model\n",
      "subj_obj\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the model\n",
      "the model\n",
      "coref\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "\n",
      "the model\n",
      "the popular Llama 2 model\n",
      "shared_text\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "fine-tune the Llama 2 7B.\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "\n",
      "fine-tune the Llama 2 7B.\n",
      "the Llama 2 model\n",
      "coref\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "not its instruction-tuned variant\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "shared_text\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "performance between Llama 2\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "While it is difficult to compare performance between Llama 2 and T5 due to the massive difference in model sizes (Llama 2: 7B vs. \\text{T5}_{\\textsc{LARGE}}: 770M parameters), the E2E model with Llama 2 substantially outperforms the latter on the Challenge aspect.\n",
      "\n",
      "\n",
      "Path 135: 53.75143523493211\n",
      "step chain-of-thought or end-to-end abstractive summarization\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "the model\n",
      "subj_obj\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the model\n",
      "the model\n",
      "coref\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "\n",
      "the model\n",
      "the popular Llama 2 model\n",
      "shared_text\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "fine-tune the Llama 2 7B.\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "\n",
      "fine-tune the Llama 2 7B.\n",
      "the Llama 2 model\n",
      "coref\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "not its instruction-tuned variant\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "shared_text\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "performance between Llama 2\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "While it is difficult to compare performance between Llama 2 and T5 due to the massive difference in model sizes (Llama 2: 7B vs. \\text{T5}_{\\textsc{LARGE}}: 770M parameters), the E2E model with Llama 2 substantially outperforms the latter on the Challenge aspect.\n",
      "\n",
      "\n",
      "Path 136: 53.75143523493211\n",
      "step chain-of-thought or end-to-end abstractive summarization\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "the model\n",
      "subj_obj\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the model\n",
      "the model\n",
      "coref\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "\n",
      "the model\n",
      "the popular Llama 2 model\n",
      "shared_text\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "fine-tune the Llama 2 7B.\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "\n",
      "fine-tune the Llama 2 7B.\n",
      "the Llama 2 model\n",
      "coref\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "not its instruction-tuned variant\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "shared_text\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "performance between Llama 2\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "While it is difficult to compare performance between Llama 2 and T5 due to the massive difference in model sizes (Llama 2: 7B vs. \\text{T5}_{\\textsc{LARGE}}: 770M parameters), the E2E model with Llama 2 substantially outperforms the latter on the Challenge aspect.\n",
      "\n",
      "\n",
      "Path 137: 53.75143523493211\n",
      "step chain-of-thought or end-to-end abstractive summarization\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "the model\n",
      "subj_obj\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the model\n",
      "the model\n",
      "coref\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "\n",
      "the model\n",
      "the popular Llama 2 model\n",
      "shared_text\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "fine-tune the Llama 2 7B.\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "\n",
      "fine-tune the Llama 2 7B.\n",
      "the Llama 2 model\n",
      "coref\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "not its instruction-tuned variant\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "shared_text\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "performance between Llama 2\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "While it is difficult to compare performance between Llama 2 and T5 due to the massive difference in model sizes (Llama 2: 7B vs. \\text{T5}_{\\textsc{LARGE}}: 770M parameters), the E2E model with Llama 2 substantially outperforms the latter on the Challenge aspect.\n",
      "\n",
      "\n",
      "Path 138: 54.02893078585603\n",
      "Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization,\n",
      "our extractive and abstractive summarization annotations\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "our extractive and abstractive summarization annotations\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "we\n",
      "coref\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "the popular Llama 2 model\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "the Llama 2 model\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "the Llama 2 model\n",
      "not its instruction-tuned variant\n",
      "coref\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "not its instruction-tuned variant\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "shared_text\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "performance between Llama 2\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "While it is difficult to compare performance between Llama 2 and T5 due to the massive difference in model sizes (Llama 2: 7B vs. \\text{T5}_{\\textsc{LARGE}}: 770M parameters), the E2E model with Llama 2 substantially outperforms the latter on the Challenge aspect.\n",
      "\n",
      "\n",
      "Path 139: 54.02893078585603\n",
      "Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization,\n",
      "our extractive and abstractive summarization annotations\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "our extractive and abstractive summarization annotations\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "we\n",
      "coref\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "the popular Llama 2 model\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "the Llama 2 model\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "the Llama 2 model\n",
      "not its instruction-tuned variant\n",
      "coref\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "not its instruction-tuned variant\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "shared_text\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "performance between Llama 2\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "While it is difficult to compare performance between Llama 2 and T5 due to the massive difference in model sizes (Llama 2: 7B vs. \\text{T5}_{\\textsc{LARGE}}: 770M parameters), the E2E model with Llama 2 substantially outperforms the latter on the Challenge aspect.\n",
      "\n",
      "\n",
      "Path 140: 54.02893078585603\n",
      "Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization,\n",
      "our extractive and abstractive summarization annotations\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "our extractive and abstractive summarization annotations\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "we\n",
      "coref\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "its summarization abilities\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "its summarization abilities\n",
      "the popular Llama 2 model\n",
      "coref\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "the Llama 2 model\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "the Llama 2 model\n",
      "not its instruction-tuned variant\n",
      "coref\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "not its instruction-tuned variant\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "shared_text\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "performance between Llama 2\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "While it is difficult to compare performance between Llama 2 and T5 due to the massive difference in model sizes (Llama 2: 7B vs. \\text{T5}_{\\textsc{LARGE}}: 770M parameters), the E2E model with Llama 2 substantially outperforms the latter on the Challenge aspect.\n",
      "\n",
      "\n",
      "Path 141: 54.02893078585603\n",
      "Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization,\n",
      "our extractive and abstractive summarization annotations\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "our extractive and abstractive summarization annotations\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "we\n",
      "coref\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "its summarization abilities\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "its summarization abilities\n",
      "the popular Llama 2 model\n",
      "coref\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "the Llama 2 model\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "the Llama 2 model\n",
      "not its instruction-tuned variant\n",
      "coref\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "not its instruction-tuned variant\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "shared_text\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "performance between Llama 2\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "While it is difficult to compare performance between Llama 2 and T5 due to the massive difference in model sizes (Llama 2: 7B vs. \\text{T5}_{\\textsc{LARGE}}: 770M parameters), the E2E model with Llama 2 substantially outperforms the latter on the Challenge aspect.\n",
      "\n",
      "\n",
      "Path 142: 54.02893078585603\n",
      "Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization,\n",
      "our extractive and abstractive summarization annotations\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "our extractive and abstractive summarization annotations\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "we\n",
      "coref\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "the popular Llama 2 model\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "the Llama 2 model\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "the Llama 2 model\n",
      "not its instruction-tuned variant\n",
      "coref\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "not its instruction-tuned variant\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "shared_text\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "performance between Llama 2\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "While it is difficult to compare performance between Llama 2 and T5 due to the massive difference in model sizes (Llama 2: 7B vs. \\text{T5}_{\\textsc{LARGE}}: 770M parameters), the E2E model with Llama 2 substantially outperforms the latter on the Challenge aspect.\n",
      "\n",
      "\n",
      "Path 143: 54.02893078585603\n",
      "Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization,\n",
      "our extractive and abstractive summarization annotations\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "our extractive and abstractive summarization annotations\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "we\n",
      "coref\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "the popular Llama 2 model\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "the Llama 2 model\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "the Llama 2 model\n",
      "not its instruction-tuned variant\n",
      "coref\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "not its instruction-tuned variant\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "shared_text\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "performance between Llama 2\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "While it is difficult to compare performance between Llama 2 and T5 due to the massive difference in model sizes (Llama 2: 7B vs. \\text{T5}_{\\textsc{LARGE}}: 770M parameters), the E2E model with Llama 2 substantially outperforms the latter on the Challenge aspect.\n",
      "\n",
      "\n",
      "Path 144: 54.02893078585603\n",
      "Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization,\n",
      "our extractive and abstractive summarization annotations\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "our extractive and abstractive summarization annotations\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "we\n",
      "coref\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "its summarization abilities\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "its summarization abilities\n",
      "the popular Llama 2 model\n",
      "coref\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "the Llama 2 model\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "the Llama 2 model\n",
      "not its instruction-tuned variant\n",
      "coref\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "not its instruction-tuned variant\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "shared_text\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "performance between Llama 2\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "While it is difficult to compare performance between Llama 2 and T5 due to the massive difference in model sizes (Llama 2: 7B vs. \\text{T5}_{\\textsc{LARGE}}: 770M parameters), the E2E model with Llama 2 substantially outperforms the latter on the Challenge aspect.\n",
      "\n",
      "\n",
      "Path 145: 54.02893078585603\n",
      "Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization,\n",
      "our extractive and abstractive summarization annotations\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "our extractive and abstractive summarization annotations\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "we\n",
      "coref\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "its summarization abilities\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "its summarization abilities\n",
      "the popular Llama 2 model\n",
      "coref\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "the Llama 2 model\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "the Llama 2 model\n",
      "not its instruction-tuned variant\n",
      "coref\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "not its instruction-tuned variant\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "shared_text\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "performance between Llama 2\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "While it is difficult to compare performance between Llama 2 and T5 due to the massive difference in model sizes (Llama 2: 7B vs. \\text{T5}_{\\textsc{LARGE}}: 770M parameters), the E2E model with Llama 2 substantially outperforms the latter on the Challenge aspect.\n",
      "\n",
      "\n",
      "Path 146: 54.61485251405912\n",
      "step chain-of-thought or end-to-end abstractive summarization\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "the model\n",
      "subj_obj\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the model\n",
      "the model\n",
      "coref\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "\n",
      "the model\n",
      "the popular Llama 2 model\n",
      "shared_text\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "the Llama 2 model\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "the Llama 2 model\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "shared_text\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "performance between Llama 2\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "While it is difficult to compare performance between Llama 2 and T5 due to the massive difference in model sizes (Llama 2: 7B vs. \\text{T5}_{\\textsc{LARGE}}: 770M parameters), the E2E model with Llama 2 substantially outperforms the latter on the Challenge aspect.\n",
      "\n",
      "\n",
      "Path 147: 54.61485251405912\n",
      "step chain-of-thought or end-to-end abstractive summarization\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "the model\n",
      "subj_obj\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the model\n",
      "the model\n",
      "coref\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "\n",
      "the model\n",
      "the popular Llama 2 model\n",
      "shared_text\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "the Llama 2 model\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "the Llama 2 model\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "shared_text\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "performance between Llama 2\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "While it is difficult to compare performance between Llama 2 and T5 due to the massive difference in model sizes (Llama 2: 7B vs. \\text{T5}_{\\textsc{LARGE}}: 770M parameters), the E2E model with Llama 2 substantially outperforms the latter on the Challenge aspect.\n",
      "\n",
      "\n",
      "Path 148: 54.94226839582967\n",
      "step chain-of-thought or end-to-end abstractive summarization\n",
      "our extractive and abstractive summarization annotations\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "our extractive and abstractive summarization annotations\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "we\n",
      "coref\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "its summarization abilities\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "its summarization abilities\n",
      "the model\n",
      "coref\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "\n",
      "the model\n",
      "the popular Llama 2 model\n",
      "shared_text\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "the Llama 2 model\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "the Llama 2 model\n",
      "not its instruction-tuned variant\n",
      "coref\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "not its instruction-tuned variant\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "shared_text\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "performance between Llama 2\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "While it is difficult to compare performance between Llama 2 and T5 due to the massive difference in model sizes (Llama 2: 7B vs. \\text{T5}_{\\textsc{LARGE}}: 770M parameters), the E2E model with Llama 2 substantially outperforms the latter on the Challenge aspect.\n",
      "\n",
      "\n",
      "Path 149: 54.94226839582967\n",
      "step chain-of-thought or end-to-end abstractive summarization\n",
      "our extractive and abstractive summarization annotations\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "our extractive and abstractive summarization annotations\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "we\n",
      "coref\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "its summarization abilities\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "its summarization abilities\n",
      "the model\n",
      "coref\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "\n",
      "the model\n",
      "the popular Llama 2 model\n",
      "shared_text\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "the Llama 2 model\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "the Llama 2 model\n",
      "not its instruction-tuned variant\n",
      "coref\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "not its instruction-tuned variant\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "shared_text\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "performance between Llama 2\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "While it is difficult to compare performance between Llama 2 and T5 due to the massive difference in model sizes (Llama 2: 7B vs. \\text{T5}_{\\textsc{LARGE}}: 770M parameters), the E2E model with Llama 2 substantially outperforms the latter on the Challenge aspect.\n",
      "\n",
      "\n",
      "Path 150: 54.94226839582967\n",
      "step chain-of-thought or end-to-end abstractive summarization\n",
      "our extractive and abstractive summarization annotations\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "our extractive and abstractive summarization annotations\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "we\n",
      "coref\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "its summarization abilities\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "its summarization abilities\n",
      "the model\n",
      "coref\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "\n",
      "the model\n",
      "the popular Llama 2 model\n",
      "shared_text\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "the Llama 2 model\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "the Llama 2 model\n",
      "not its instruction-tuned variant\n",
      "coref\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "not its instruction-tuned variant\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "shared_text\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "performance between Llama 2\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "While it is difficult to compare performance between Llama 2 and T5 due to the massive difference in model sizes (Llama 2: 7B vs. \\text{T5}_{\\textsc{LARGE}}: 770M parameters), the E2E model with Llama 2 substantially outperforms the latter on the Challenge aspect.\n",
      "\n",
      "\n",
      "Path 151: 54.94226839582967\n",
      "step chain-of-thought or end-to-end abstractive summarization\n",
      "our extractive and abstractive summarization annotations\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "our extractive and abstractive summarization annotations\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "we\n",
      "coref\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "its summarization abilities\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "its summarization abilities\n",
      "the model\n",
      "coref\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "\n",
      "the model\n",
      "the popular Llama 2 model\n",
      "shared_text\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "the Llama 2 model\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "the Llama 2 model\n",
      "not its instruction-tuned variant\n",
      "coref\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "not its instruction-tuned variant\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "shared_text\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "performance between Llama 2\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "While it is difficult to compare performance between Llama 2 and T5 due to the massive difference in model sizes (Llama 2: 7B vs. \\text{T5}_{\\textsc{LARGE}}: 770M parameters), the E2E model with Llama 2 substantially outperforms the latter on the Challenge aspect.\n",
      "\n",
      "\n",
      "Path 152: 54.97790053207475\n",
      "step chain-of-thought or end-to-end abstractive summarization\n",
      "our extractive and abstractive summarization annotations\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "our extractive and abstractive summarization annotations\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "we\n",
      "coref\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "its summarization abilities\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "its summarization abilities\n",
      "the model\n",
      "coref\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "\n",
      "the model\n",
      "the model\n",
      "shared_text\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the model\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "subj_obj\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "A training data sample used for EtA-CoT\n",
      "shared_text\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "A training data sample used for EtA-CoT is shown in Table 5.\n",
      "\n",
      "A training data sample used for EtA-CoT\n",
      "Table 5\n",
      "subj_obj\n",
      "A training data sample used for EtA-CoT is shown in Table 5.\n",
      "\n",
      "Table 5\n",
      "Table 6\n",
      "shared_text\n",
      "A training data sample used for EtA-CoT is shown in Table 5.\n",
      "Table 6 presents ROUGE scores, BERTScores, and extraction performance using our gold extractive labels measured by F1 for EtA-CoT models.\n",
      "\n",
      "\n",
      "Path 153: 54.97790053207475\n",
      "step chain-of-thought or end-to-end abstractive summarization\n",
      "our extractive and abstractive summarization annotations\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "our extractive and abstractive summarization annotations\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "we\n",
      "coref\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "its summarization abilities\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "its summarization abilities\n",
      "the model\n",
      "coref\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "\n",
      "the model\n",
      "the model\n",
      "shared_text\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the model\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "subj_obj\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "A training data sample used for EtA-CoT\n",
      "shared_text\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "A training data sample used for EtA-CoT is shown in Table 5.\n",
      "\n",
      "A training data sample used for EtA-CoT\n",
      "Table 5\n",
      "subj_obj\n",
      "A training data sample used for EtA-CoT is shown in Table 5.\n",
      "\n",
      "Table 5\n",
      "Table 6\n",
      "shared_text\n",
      "A training data sample used for EtA-CoT is shown in Table 5.\n",
      "Table 6 presents ROUGE scores, BERTScores, and extraction performance using our gold extractive labels measured by F1 for EtA-CoT models.\n",
      "\n",
      "\n",
      "Path 154: 54.97790053207475\n",
      "step chain-of-thought or end-to-end abstractive summarization\n",
      "our extractive and abstractive summarization annotations\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "our extractive and abstractive summarization annotations\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "we\n",
      "coref\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "its summarization abilities\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "its summarization abilities\n",
      "the model\n",
      "coref\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "\n",
      "the model\n",
      "the model\n",
      "shared_text\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the model\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "subj_obj\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "A training data sample used for EtA-CoT\n",
      "shared_text\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "A training data sample used for EtA-CoT is shown in Table 5.\n",
      "\n",
      "A training data sample used for EtA-CoT\n",
      "Table 5\n",
      "subj_obj\n",
      "A training data sample used for EtA-CoT is shown in Table 5.\n",
      "\n",
      "Table 5\n",
      "Table 6\n",
      "shared_text\n",
      "A training data sample used for EtA-CoT is shown in Table 5.\n",
      "Table 6 presents ROUGE scores, BERTScores, and extraction performance using our gold extractive labels measured by F1 for EtA-CoT models.\n",
      "\n",
      "\n",
      "Path 155: 54.97790053207475\n",
      "step chain-of-thought or end-to-end abstractive summarization\n",
      "our extractive and abstractive summarization annotations\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "our extractive and abstractive summarization annotations\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "we\n",
      "coref\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "its summarization abilities\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "its summarization abilities\n",
      "the model\n",
      "coref\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "\n",
      "the model\n",
      "the model\n",
      "shared_text\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the model\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "subj_obj\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "A training data sample used for EtA-CoT\n",
      "shared_text\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "A training data sample used for EtA-CoT is shown in Table 5.\n",
      "\n",
      "A training data sample used for EtA-CoT\n",
      "Table 5\n",
      "subj_obj\n",
      "A training data sample used for EtA-CoT is shown in Table 5.\n",
      "\n",
      "Table 5\n",
      "Table 6\n",
      "shared_text\n",
      "A training data sample used for EtA-CoT is shown in Table 5.\n",
      "Table 6 presents ROUGE scores, BERTScores, and extraction performance using our gold extractive labels measured by F1 for EtA-CoT models.\n",
      "\n",
      "\n",
      "Path 156: 55.08039177795709\n",
      "step chain-of-thought or end-to-end abstractive summarization\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "the model\n",
      "subj_obj\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the model\n",
      "the model\n",
      "coref\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "\n",
      "its summarization abilities\n",
      "we\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "the popular Llama 2 model\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "the Llama 2 model\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "the Llama 2 model\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "shared_text\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "performance between Llama 2\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "While it is difficult to compare performance between Llama 2 and T5 due to the massive difference in model sizes (Llama 2: 7B vs. \\text{T5}_{\\textsc{LARGE}}: 770M parameters), the E2E model with Llama 2 substantially outperforms the latter on the Challenge aspect.\n",
      "\n",
      "\n",
      "Path 157: 55.08039177795709\n",
      "step chain-of-thought or end-to-end abstractive summarization\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "the model\n",
      "subj_obj\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the model\n",
      "the model\n",
      "coref\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "\n",
      "its summarization abilities\n",
      "we\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "the popular Llama 2 model\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "the Llama 2 model\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "the Llama 2 model\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "shared_text\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "performance between Llama 2\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "While it is difficult to compare performance between Llama 2 and T5 due to the massive difference in model sizes (Llama 2: 7B vs. \\text{T5}_{\\textsc{LARGE}}: 770M parameters), the E2E model with Llama 2 substantially outperforms the latter on the Challenge aspect.\n",
      "\n",
      "\n",
      "Path 158: 55.40780765972764\n",
      "step chain-of-thought or end-to-end abstractive summarization\n",
      "our extractive and abstractive summarization annotations\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "our extractive and abstractive summarization annotations\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "we\n",
      "coref\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "the popular Llama 2 model\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "the Llama 2 model\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "the Llama 2 model\n",
      "We\n",
      "subj_obj\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "We\n",
      "not its instruction-tuned variant\n",
      "subj_obj\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "not its instruction-tuned variant\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "coref\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "performance between Llama 2\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "While it is difficult to compare performance between Llama 2 and T5 due to the massive difference in model sizes (Llama 2: 7B vs. \\text{T5}_{\\textsc{LARGE}}: 770M parameters), the E2E model with Llama 2 substantially outperforms the latter on the Challenge aspect.\n",
      "\n",
      "\n",
      "Path 159: 55.40780765972764\n",
      "step chain-of-thought or end-to-end abstractive summarization\n",
      "our extractive and abstractive summarization annotations\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "our extractive and abstractive summarization annotations\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "we\n",
      "coref\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "the popular Llama 2 model\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "the Llama 2 model\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "the Llama 2 model\n",
      "We\n",
      "subj_obj\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "We\n",
      "not its instruction-tuned variant\n",
      "subj_obj\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "not its instruction-tuned variant\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "coref\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "performance between Llama 2\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "While it is difficult to compare performance between Llama 2 and T5 due to the massive difference in model sizes (Llama 2: 7B vs. \\text{T5}_{\\textsc{LARGE}}: 770M parameters), the E2E model with Llama 2 substantially outperforms the latter on the Challenge aspect.\n",
      "\n",
      "\n",
      "Path 160: 55.40780765972764\n",
      "step chain-of-thought or end-to-end abstractive summarization\n",
      "our extractive and abstractive summarization annotations\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "our extractive and abstractive summarization annotations\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "we\n",
      "coref\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "the popular Llama 2 model\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "the Llama 2 model\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "the Llama 2 model\n",
      "we\n",
      "subj_obj\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "we\n",
      "not its instruction-tuned variant\n",
      "subj_obj\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "not its instruction-tuned variant\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "coref\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "performance between Llama 2\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "While it is difficult to compare performance between Llama 2 and T5 due to the massive difference in model sizes (Llama 2: 7B vs. \\text{T5}_{\\textsc{LARGE}}: 770M parameters), the E2E model with Llama 2 substantially outperforms the latter on the Challenge aspect.\n",
      "\n",
      "\n",
      "Path 161: 55.40780765972764\n",
      "step chain-of-thought or end-to-end abstractive summarization\n",
      "our extractive and abstractive summarization annotations\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "our extractive and abstractive summarization annotations\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "we\n",
      "coref\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "the popular Llama 2 model\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "the Llama 2 model\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "the Llama 2 model\n",
      "we\n",
      "subj_obj\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "we\n",
      "not its instruction-tuned variant\n",
      "subj_obj\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "not its instruction-tuned variant\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "coref\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "performance between Llama 2\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "While it is difficult to compare performance between Llama 2 and T5 due to the massive difference in model sizes (Llama 2: 7B vs. \\text{T5}_{\\textsc{LARGE}}: 770M parameters), the E2E model with Llama 2 substantially outperforms the latter on the Challenge aspect.\n",
      "\n",
      "\n",
      "Path 162: 55.40780765972764\n",
      "step chain-of-thought or end-to-end abstractive summarization\n",
      "our extractive and abstractive summarization annotations\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "our extractive and abstractive summarization annotations\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "we\n",
      "coref\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "its summarization abilities\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "its summarization abilities\n",
      "the popular Llama 2 model\n",
      "coref\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "the Llama 2 model\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "the Llama 2 model\n",
      "We\n",
      "subj_obj\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "We\n",
      "not its instruction-tuned variant\n",
      "subj_obj\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "not its instruction-tuned variant\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "coref\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "performance between Llama 2\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "While it is difficult to compare performance between Llama 2 and T5 due to the massive difference in model sizes (Llama 2: 7B vs. \\text{T5}_{\\textsc{LARGE}}: 770M parameters), the E2E model with Llama 2 substantially outperforms the latter on the Challenge aspect.\n",
      "\n",
      "\n",
      "Path 163: 55.40780765972764\n",
      "step chain-of-thought or end-to-end abstractive summarization\n",
      "our extractive and abstractive summarization annotations\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "our extractive and abstractive summarization annotations\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "we\n",
      "coref\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "its summarization abilities\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "its summarization abilities\n",
      "the popular Llama 2 model\n",
      "coref\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "the Llama 2 model\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "the Llama 2 model\n",
      "We\n",
      "subj_obj\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "We\n",
      "not its instruction-tuned variant\n",
      "subj_obj\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "not its instruction-tuned variant\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "coref\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "performance between Llama 2\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "While it is difficult to compare performance between Llama 2 and T5 due to the massive difference in model sizes (Llama 2: 7B vs. \\text{T5}_{\\textsc{LARGE}}: 770M parameters), the E2E model with Llama 2 substantially outperforms the latter on the Challenge aspect.\n",
      "\n",
      "\n",
      "Path 164: 55.40780765972764\n",
      "step chain-of-thought or end-to-end abstractive summarization\n",
      "our extractive and abstractive summarization annotations\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "our extractive and abstractive summarization annotations\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "we\n",
      "coref\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "its summarization abilities\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "its summarization abilities\n",
      "the popular Llama 2 model\n",
      "coref\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "the Llama 2 model\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "the Llama 2 model\n",
      "we\n",
      "subj_obj\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "we\n",
      "not its instruction-tuned variant\n",
      "subj_obj\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "not its instruction-tuned variant\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "coref\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "performance between Llama 2\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "While it is difficult to compare performance between Llama 2 and T5 due to the massive difference in model sizes (Llama 2: 7B vs. \\text{T5}_{\\textsc{LARGE}}: 770M parameters), the E2E model with Llama 2 substantially outperforms the latter on the Challenge aspect.\n",
      "\n",
      "\n",
      "Path 165: 55.40780765972764\n",
      "step chain-of-thought or end-to-end abstractive summarization\n",
      "our extractive and abstractive summarization annotations\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "our extractive and abstractive summarization annotations\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "we\n",
      "coref\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "its summarization abilities\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "its summarization abilities\n",
      "the popular Llama 2 model\n",
      "coref\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "the Llama 2 model\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "the Llama 2 model\n",
      "we\n",
      "subj_obj\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "we\n",
      "not its instruction-tuned variant\n",
      "subj_obj\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "not its instruction-tuned variant\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "coref\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "performance between Llama 2\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "While it is difficult to compare performance between Llama 2 and T5 due to the massive difference in model sizes (Llama 2: 7B vs. \\text{T5}_{\\textsc{LARGE}}: 770M parameters), the E2E model with Llama 2 substantially outperforms the latter on the Challenge aspect.\n",
      "\n",
      "\n",
      "Path 166: 55.40780765972764\n",
      "step chain-of-thought or end-to-end abstractive summarization\n",
      "our extractive and abstractive summarization annotations\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "our extractive and abstractive summarization annotations\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "we\n",
      "coref\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "the popular Llama 2 model\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "the Llama 2 model\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "the Llama 2 model\n",
      "We\n",
      "subj_obj\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "We\n",
      "not its instruction-tuned variant\n",
      "subj_obj\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "not its instruction-tuned variant\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "coref\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "performance between Llama 2\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "While it is difficult to compare performance between Llama 2 and T5 due to the massive difference in model sizes (Llama 2: 7B vs. \\text{T5}_{\\textsc{LARGE}}: 770M parameters), the E2E model with Llama 2 substantially outperforms the latter on the Challenge aspect.\n",
      "\n",
      "\n",
      "Path 167: 55.40780765972764\n",
      "step chain-of-thought or end-to-end abstractive summarization\n",
      "our extractive and abstractive summarization annotations\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "our extractive and abstractive summarization annotations\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "we\n",
      "coref\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "the popular Llama 2 model\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "the Llama 2 model\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "the Llama 2 model\n",
      "We\n",
      "subj_obj\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "We\n",
      "not its instruction-tuned variant\n",
      "subj_obj\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "not its instruction-tuned variant\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "coref\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "performance between Llama 2\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "While it is difficult to compare performance between Llama 2 and T5 due to the massive difference in model sizes (Llama 2: 7B vs. \\text{T5}_{\\textsc{LARGE}}: 770M parameters), the E2E model with Llama 2 substantially outperforms the latter on the Challenge aspect.\n",
      "\n",
      "\n",
      "Path 168: 55.40780765972764\n",
      "step chain-of-thought or end-to-end abstractive summarization\n",
      "our extractive and abstractive summarization annotations\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "our extractive and abstractive summarization annotations\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "we\n",
      "coref\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "the popular Llama 2 model\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "the Llama 2 model\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "the Llama 2 model\n",
      "we\n",
      "subj_obj\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "we\n",
      "not its instruction-tuned variant\n",
      "subj_obj\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "not its instruction-tuned variant\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "coref\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "performance between Llama 2\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "While it is difficult to compare performance between Llama 2 and T5 due to the massive difference in model sizes (Llama 2: 7B vs. \\text{T5}_{\\textsc{LARGE}}: 770M parameters), the E2E model with Llama 2 substantially outperforms the latter on the Challenge aspect.\n",
      "\n",
      "\n",
      "Path 169: 55.40780765972764\n",
      "step chain-of-thought or end-to-end abstractive summarization\n",
      "our extractive and abstractive summarization annotations\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "our extractive and abstractive summarization annotations\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "we\n",
      "coref\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "the popular Llama 2 model\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "the Llama 2 model\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "the Llama 2 model\n",
      "we\n",
      "subj_obj\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "we\n",
      "not its instruction-tuned variant\n",
      "subj_obj\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "not its instruction-tuned variant\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "coref\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "performance between Llama 2\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "While it is difficult to compare performance between Llama 2 and T5 due to the massive difference in model sizes (Llama 2: 7B vs. \\text{T5}_{\\textsc{LARGE}}: 770M parameters), the E2E model with Llama 2 substantially outperforms the latter on the Challenge aspect.\n",
      "\n",
      "\n",
      "Path 170: 55.40780765972764\n",
      "step chain-of-thought or end-to-end abstractive summarization\n",
      "our extractive and abstractive summarization annotations\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "our extractive and abstractive summarization annotations\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "we\n",
      "coref\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "its summarization abilities\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "its summarization abilities\n",
      "the popular Llama 2 model\n",
      "coref\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "the Llama 2 model\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "the Llama 2 model\n",
      "We\n",
      "subj_obj\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "We\n",
      "not its instruction-tuned variant\n",
      "subj_obj\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "not its instruction-tuned variant\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "coref\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "performance between Llama 2\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "While it is difficult to compare performance between Llama 2 and T5 due to the massive difference in model sizes (Llama 2: 7B vs. \\text{T5}_{\\textsc{LARGE}}: 770M parameters), the E2E model with Llama 2 substantially outperforms the latter on the Challenge aspect.\n",
      "\n",
      "\n",
      "Path 171: 55.40780765972764\n",
      "step chain-of-thought or end-to-end abstractive summarization\n",
      "our extractive and abstractive summarization annotations\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "our extractive and abstractive summarization annotations\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "we\n",
      "coref\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "its summarization abilities\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "its summarization abilities\n",
      "the popular Llama 2 model\n",
      "coref\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "the Llama 2 model\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "the Llama 2 model\n",
      "We\n",
      "subj_obj\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "We\n",
      "not its instruction-tuned variant\n",
      "subj_obj\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "not its instruction-tuned variant\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "coref\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "performance between Llama 2\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "While it is difficult to compare performance between Llama 2 and T5 due to the massive difference in model sizes (Llama 2: 7B vs. \\text{T5}_{\\textsc{LARGE}}: 770M parameters), the E2E model with Llama 2 substantially outperforms the latter on the Challenge aspect.\n",
      "\n",
      "\n",
      "Path 172: 55.40780765972764\n",
      "step chain-of-thought or end-to-end abstractive summarization\n",
      "our extractive and abstractive summarization annotations\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "our extractive and abstractive summarization annotations\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "we\n",
      "coref\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "its summarization abilities\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "its summarization abilities\n",
      "the popular Llama 2 model\n",
      "coref\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "the Llama 2 model\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "the Llama 2 model\n",
      "we\n",
      "subj_obj\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "we\n",
      "not its instruction-tuned variant\n",
      "subj_obj\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "not its instruction-tuned variant\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "coref\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "performance between Llama 2\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "While it is difficult to compare performance between Llama 2 and T5 due to the massive difference in model sizes (Llama 2: 7B vs. \\text{T5}_{\\textsc{LARGE}}: 770M parameters), the E2E model with Llama 2 substantially outperforms the latter on the Challenge aspect.\n",
      "\n",
      "\n",
      "Path 173: 55.40780765972764\n",
      "step chain-of-thought or end-to-end abstractive summarization\n",
      "our extractive and abstractive summarization annotations\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "our extractive and abstractive summarization annotations\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "we\n",
      "coref\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "its summarization abilities\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "its summarization abilities\n",
      "the popular Llama 2 model\n",
      "coref\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "the Llama 2 model\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "the Llama 2 model\n",
      "we\n",
      "subj_obj\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "we\n",
      "not its instruction-tuned variant\n",
      "subj_obj\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "not its instruction-tuned variant\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "coref\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "performance between Llama 2\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "While it is difficult to compare performance between Llama 2 and T5 due to the massive difference in model sizes (Llama 2: 7B vs. \\text{T5}_{\\textsc{LARGE}}: 770M parameters), the E2E model with Llama 2 substantially outperforms the latter on the Challenge aspect.\n",
      "\n",
      "\n",
      "Path 174: 55.56339152195807\n",
      "Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization,\n",
      "our extractive and abstractive summarization annotations\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "our extractive and abstractive summarization annotations\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "we\n",
      "coref\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "its summarization abilities\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "its summarization abilities\n",
      "the model\n",
      "coref\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "\n",
      "the model\n",
      "the popular Llama 2 model\n",
      "shared_text\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "the Llama 2 model\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "the Llama 2 model\n",
      "not its instruction-tuned variant\n",
      "coref\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "not its instruction-tuned variant\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "shared_text\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "performance between Llama 2\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "While it is difficult to compare performance between Llama 2 and T5 due to the massive difference in model sizes (Llama 2: 7B vs. \\text{T5}_{\\textsc{LARGE}}: 770M parameters), the E2E model with Llama 2 substantially outperforms the latter on the Challenge aspect.\n",
      "\n",
      "\n",
      "Path 175: 55.56339152195807\n",
      "Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization,\n",
      "our extractive and abstractive summarization annotations\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "our extractive and abstractive summarization annotations\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "we\n",
      "coref\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "its summarization abilities\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "its summarization abilities\n",
      "the model\n",
      "coref\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "\n",
      "the model\n",
      "the popular Llama 2 model\n",
      "shared_text\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "the Llama 2 model\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "the Llama 2 model\n",
      "not its instruction-tuned variant\n",
      "coref\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "not its instruction-tuned variant\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "shared_text\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "performance between Llama 2\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "While it is difficult to compare performance between Llama 2 and T5 due to the massive difference in model sizes (Llama 2: 7B vs. \\text{T5}_{\\textsc{LARGE}}: 770M parameters), the E2E model with Llama 2 substantially outperforms the latter on the Challenge aspect.\n",
      "\n",
      "\n",
      "Path 176: 55.56339152195807\n",
      "Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization,\n",
      "our extractive and abstractive summarization annotations\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "our extractive and abstractive summarization annotations\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "we\n",
      "coref\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "its summarization abilities\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "its summarization abilities\n",
      "the model\n",
      "coref\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "\n",
      "the model\n",
      "the popular Llama 2 model\n",
      "shared_text\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "the Llama 2 model\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "the Llama 2 model\n",
      "not its instruction-tuned variant\n",
      "coref\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "not its instruction-tuned variant\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "shared_text\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "performance between Llama 2\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "While it is difficult to compare performance between Llama 2 and T5 due to the massive difference in model sizes (Llama 2: 7B vs. \\text{T5}_{\\textsc{LARGE}}: 770M parameters), the E2E model with Llama 2 substantially outperforms the latter on the Challenge aspect.\n",
      "\n",
      "\n",
      "Path 177: 55.56339152195807\n",
      "Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization,\n",
      "our extractive and abstractive summarization annotations\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "our extractive and abstractive summarization annotations\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "we\n",
      "coref\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "its summarization abilities\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "its summarization abilities\n",
      "the model\n",
      "coref\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "\n",
      "the model\n",
      "the popular Llama 2 model\n",
      "shared_text\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "the Llama 2 model\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "the Llama 2 model\n",
      "not its instruction-tuned variant\n",
      "coref\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "not its instruction-tuned variant\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "shared_text\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "performance between Llama 2\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "While it is difficult to compare performance between Llama 2 and T5 due to the massive difference in model sizes (Llama 2: 7B vs. \\text{T5}_{\\textsc{LARGE}}: 770M parameters), the E2E model with Llama 2 substantially outperforms the latter on the Challenge aspect.\n",
      "\n",
      "\n",
      "Path 178: 55.599023658203144\n",
      "Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization,\n",
      "our extractive and abstractive summarization annotations\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "our extractive and abstractive summarization annotations\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "we\n",
      "coref\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "its summarization abilities\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "its summarization abilities\n",
      "the model\n",
      "coref\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "\n",
      "the model\n",
      "the model\n",
      "shared_text\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the model\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "subj_obj\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "A training data sample used for EtA-CoT\n",
      "shared_text\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "A training data sample used for EtA-CoT is shown in Table 5.\n",
      "\n",
      "A training data sample used for EtA-CoT\n",
      "Table 5\n",
      "subj_obj\n",
      "A training data sample used for EtA-CoT is shown in Table 5.\n",
      "\n",
      "Table 5\n",
      "Table 6\n",
      "shared_text\n",
      "A training data sample used for EtA-CoT is shown in Table 5.\n",
      "Table 6 presents ROUGE scores, BERTScores, and extraction performance using our gold extractive labels measured by F1 for EtA-CoT models.\n",
      "\n",
      "\n",
      "Path 179: 55.599023658203144\n",
      "Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization,\n",
      "our extractive and abstractive summarization annotations\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "our extractive and abstractive summarization annotations\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "we\n",
      "coref\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "its summarization abilities\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "its summarization abilities\n",
      "the model\n",
      "coref\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "\n",
      "the model\n",
      "the model\n",
      "shared_text\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the model\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "subj_obj\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "A training data sample used for EtA-CoT\n",
      "shared_text\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "A training data sample used for EtA-CoT is shown in Table 5.\n",
      "\n",
      "A training data sample used for EtA-CoT\n",
      "Table 5\n",
      "subj_obj\n",
      "A training data sample used for EtA-CoT is shown in Table 5.\n",
      "\n",
      "Table 5\n",
      "Table 6\n",
      "shared_text\n",
      "A training data sample used for EtA-CoT is shown in Table 5.\n",
      "Table 6 presents ROUGE scores, BERTScores, and extraction performance using our gold extractive labels measured by F1 for EtA-CoT models.\n",
      "\n",
      "\n",
      "Path 180: 55.599023658203144\n",
      "Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization,\n",
      "our extractive and abstractive summarization annotations\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "our extractive and abstractive summarization annotations\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "we\n",
      "coref\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "its summarization abilities\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "its summarization abilities\n",
      "the model\n",
      "coref\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "\n",
      "the model\n",
      "the model\n",
      "shared_text\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the model\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "subj_obj\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "A training data sample used for EtA-CoT\n",
      "shared_text\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "A training data sample used for EtA-CoT is shown in Table 5.\n",
      "\n",
      "A training data sample used for EtA-CoT\n",
      "Table 5\n",
      "subj_obj\n",
      "A training data sample used for EtA-CoT is shown in Table 5.\n",
      "\n",
      "Table 5\n",
      "Table 6\n",
      "shared_text\n",
      "A training data sample used for EtA-CoT is shown in Table 5.\n",
      "Table 6 presents ROUGE scores, BERTScores, and extraction performance using our gold extractive labels measured by F1 for EtA-CoT models.\n",
      "\n",
      "\n",
      "Path 181: 55.599023658203144\n",
      "Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization,\n",
      "our extractive and abstractive summarization annotations\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "our extractive and abstractive summarization annotations\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "we\n",
      "coref\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "its summarization abilities\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "its summarization abilities\n",
      "the model\n",
      "coref\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "\n",
      "the model\n",
      "the model\n",
      "shared_text\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the model\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "subj_obj\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "A training data sample used for EtA-CoT\n",
      "shared_text\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "A training data sample used for EtA-CoT is shown in Table 5.\n",
      "\n",
      "A training data sample used for EtA-CoT\n",
      "Table 5\n",
      "subj_obj\n",
      "A training data sample used for EtA-CoT is shown in Table 5.\n",
      "\n",
      "Table 5\n",
      "Table 6\n",
      "shared_text\n",
      "A training data sample used for EtA-CoT is shown in Table 5.\n",
      "Table 6 presents ROUGE scores, BERTScores, and extraction performance using our gold extractive labels measured by F1 for EtA-CoT models.\n",
      "\n",
      "\n",
      "Path 182: 55.75143523493211\n",
      "step chain-of-thought or end-to-end abstractive summarization\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "the model\n",
      "subj_obj\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the model\n",
      "the model\n",
      "coref\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "\n",
      "the model\n",
      "the popular Llama 2 model\n",
      "shared_text\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "fine-tune the Llama 2 7B.\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "\n",
      "fine-tune the Llama 2 7B.\n",
      "We\n",
      "subj_obj\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "\n",
      "We\n",
      "We\n",
      "coref\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "We\n",
      "not its instruction-tuned variant\n",
      "subj_obj\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "not its instruction-tuned variant\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "coref\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "performance between Llama 2\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "While it is difficult to compare performance between Llama 2 and T5 due to the massive difference in model sizes (Llama 2: 7B vs. \\text{T5}_{\\textsc{LARGE}}: 770M parameters), the E2E model with Llama 2 substantially outperforms the latter on the Challenge aspect.\n",
      "\n",
      "\n",
      "Path 183: 55.75143523493211\n",
      "step chain-of-thought or end-to-end abstractive summarization\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "the model\n",
      "subj_obj\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the model\n",
      "the model\n",
      "coref\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "\n",
      "the model\n",
      "the popular Llama 2 model\n",
      "shared_text\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "fine-tune the Llama 2 7B.\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "\n",
      "fine-tune the Llama 2 7B.\n",
      "We\n",
      "subj_obj\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "\n",
      "We\n",
      "We\n",
      "coref\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "We\n",
      "not its instruction-tuned variant\n",
      "subj_obj\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "not its instruction-tuned variant\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "coref\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "performance between Llama 2\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "While it is difficult to compare performance between Llama 2 and T5 due to the massive difference in model sizes (Llama 2: 7B vs. \\text{T5}_{\\textsc{LARGE}}: 770M parameters), the E2E model with Llama 2 substantially outperforms the latter on the Challenge aspect.\n",
      "\n",
      "\n",
      "Path 184: 55.75143523493211\n",
      "step chain-of-thought or end-to-end abstractive summarization\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "the model\n",
      "subj_obj\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the model\n",
      "the model\n",
      "coref\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "\n",
      "the model\n",
      "the popular Llama 2 model\n",
      "shared_text\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "fine-tune the Llama 2 7B.\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "\n",
      "fine-tune the Llama 2 7B.\n",
      "the Llama 2 model\n",
      "coref\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "the Llama 2 model\n",
      "We\n",
      "subj_obj\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "We\n",
      "not its instruction-tuned variant\n",
      "subj_obj\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "not its instruction-tuned variant\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "coref\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "performance between Llama 2\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "While it is difficult to compare performance between Llama 2 and T5 due to the massive difference in model sizes (Llama 2: 7B vs. \\text{T5}_{\\textsc{LARGE}}: 770M parameters), the E2E model with Llama 2 substantially outperforms the latter on the Challenge aspect.\n",
      "\n",
      "\n",
      "Path 185: 55.75143523493211\n",
      "step chain-of-thought or end-to-end abstractive summarization\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "the model\n",
      "subj_obj\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the model\n",
      "the model\n",
      "coref\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "\n",
      "the model\n",
      "the popular Llama 2 model\n",
      "shared_text\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "fine-tune the Llama 2 7B.\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "\n",
      "fine-tune the Llama 2 7B.\n",
      "the Llama 2 model\n",
      "coref\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "the Llama 2 model\n",
      "We\n",
      "subj_obj\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "We\n",
      "not its instruction-tuned variant\n",
      "subj_obj\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "not its instruction-tuned variant\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "coref\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "performance between Llama 2\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "While it is difficult to compare performance between Llama 2 and T5 due to the massive difference in model sizes (Llama 2: 7B vs. \\text{T5}_{\\textsc{LARGE}}: 770M parameters), the E2E model with Llama 2 substantially outperforms the latter on the Challenge aspect.\n",
      "\n",
      "\n",
      "Path 186: 55.75143523493211\n",
      "step chain-of-thought or end-to-end abstractive summarization\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "the model\n",
      "subj_obj\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the model\n",
      "the model\n",
      "coref\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "\n",
      "the model\n",
      "the popular Llama 2 model\n",
      "shared_text\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "fine-tune the Llama 2 7B.\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "\n",
      "fine-tune the Llama 2 7B.\n",
      "the Llama 2 model\n",
      "coref\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "the Llama 2 model\n",
      "we\n",
      "subj_obj\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "we\n",
      "not its instruction-tuned variant\n",
      "subj_obj\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "not its instruction-tuned variant\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "coref\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "performance between Llama 2\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "While it is difficult to compare performance between Llama 2 and T5 due to the massive difference in model sizes (Llama 2: 7B vs. \\text{T5}_{\\textsc{LARGE}}: 770M parameters), the E2E model with Llama 2 substantially outperforms the latter on the Challenge aspect.\n",
      "\n",
      "\n",
      "Path 187: 55.75143523493211\n",
      "step chain-of-thought or end-to-end abstractive summarization\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "the model\n",
      "subj_obj\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the model\n",
      "the model\n",
      "coref\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "\n",
      "the model\n",
      "the popular Llama 2 model\n",
      "shared_text\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "fine-tune the Llama 2 7B.\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "\n",
      "fine-tune the Llama 2 7B.\n",
      "the Llama 2 model\n",
      "coref\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "the Llama 2 model\n",
      "we\n",
      "subj_obj\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "we\n",
      "not its instruction-tuned variant\n",
      "subj_obj\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "not its instruction-tuned variant\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "coref\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "performance between Llama 2\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "While it is difficult to compare performance between Llama 2 and T5 due to the massive difference in model sizes (Llama 2: 7B vs. \\text{T5}_{\\textsc{LARGE}}: 770M parameters), the E2E model with Llama 2 substantially outperforms the latter on the Challenge aspect.\n",
      "\n",
      "\n",
      "Path 188: 55.75143523493211\n",
      "step chain-of-thought or end-to-end abstractive summarization\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "the model\n",
      "subj_obj\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the model\n",
      "the model\n",
      "coref\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "\n",
      "the model\n",
      "the popular Llama 2 model\n",
      "shared_text\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "fine-tune the Llama 2 7B.\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "\n",
      "fine-tune the Llama 2 7B.\n",
      "the Llama 2 model\n",
      "coref\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "the Llama 2 model\n",
      "We\n",
      "subj_obj\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "We\n",
      "not its instruction-tuned variant\n",
      "subj_obj\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "not its instruction-tuned variant\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "coref\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "performance between Llama 2\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "While it is difficult to compare performance between Llama 2 and T5 due to the massive difference in model sizes (Llama 2: 7B vs. \\text{T5}_{\\textsc{LARGE}}: 770M parameters), the E2E model with Llama 2 substantially outperforms the latter on the Challenge aspect.\n",
      "\n",
      "\n",
      "Path 189: 55.75143523493211\n",
      "step chain-of-thought or end-to-end abstractive summarization\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "the model\n",
      "subj_obj\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the model\n",
      "the model\n",
      "coref\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "\n",
      "the model\n",
      "the popular Llama 2 model\n",
      "shared_text\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "fine-tune the Llama 2 7B.\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "\n",
      "fine-tune the Llama 2 7B.\n",
      "the Llama 2 model\n",
      "coref\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "the Llama 2 model\n",
      "We\n",
      "subj_obj\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "We\n",
      "not its instruction-tuned variant\n",
      "subj_obj\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "not its instruction-tuned variant\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "coref\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "performance between Llama 2\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "While it is difficult to compare performance between Llama 2 and T5 due to the massive difference in model sizes (Llama 2: 7B vs. \\text{T5}_{\\textsc{LARGE}}: 770M parameters), the E2E model with Llama 2 substantially outperforms the latter on the Challenge aspect.\n",
      "\n",
      "\n",
      "Path 190: 55.75143523493211\n",
      "step chain-of-thought or end-to-end abstractive summarization\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "the model\n",
      "subj_obj\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the model\n",
      "the model\n",
      "coref\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "\n",
      "the model\n",
      "the popular Llama 2 model\n",
      "shared_text\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "fine-tune the Llama 2 7B.\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "\n",
      "fine-tune the Llama 2 7B.\n",
      "the Llama 2 model\n",
      "coref\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "the Llama 2 model\n",
      "we\n",
      "subj_obj\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "we\n",
      "not its instruction-tuned variant\n",
      "subj_obj\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "not its instruction-tuned variant\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "coref\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "performance between Llama 2\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "While it is difficult to compare performance between Llama 2 and T5 due to the massive difference in model sizes (Llama 2: 7B vs. \\text{T5}_{\\textsc{LARGE}}: 770M parameters), the E2E model with Llama 2 substantially outperforms the latter on the Challenge aspect.\n",
      "\n",
      "\n",
      "Path 191: 55.75143523493211\n",
      "step chain-of-thought or end-to-end abstractive summarization\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "the model\n",
      "subj_obj\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the model\n",
      "the model\n",
      "coref\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "\n",
      "the model\n",
      "the popular Llama 2 model\n",
      "shared_text\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "fine-tune the Llama 2 7B.\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "\n",
      "fine-tune the Llama 2 7B.\n",
      "the Llama 2 model\n",
      "coref\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "the Llama 2 model\n",
      "we\n",
      "subj_obj\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "we\n",
      "not its instruction-tuned variant\n",
      "subj_obj\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "not its instruction-tuned variant\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "coref\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "performance between Llama 2\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "While it is difficult to compare performance between Llama 2 and T5 due to the massive difference in model sizes (Llama 2: 7B vs. \\text{T5}_{\\textsc{LARGE}}: 770M parameters), the E2E model with Llama 2 substantially outperforms the latter on the Challenge aspect.\n",
      "\n",
      "\n",
      "Path 192: 55.75143523493211\n",
      "step chain-of-thought or end-to-end abstractive summarization\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "the model\n",
      "subj_obj\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the model\n",
      "the model\n",
      "coref\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "\n",
      "the model\n",
      "the popular Llama 2 model\n",
      "shared_text\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "fine-tune the Llama 2 7B.\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "\n",
      "fine-tune the Llama 2 7B.\n",
      "We\n",
      "subj_obj\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "\n",
      "We\n",
      "We\n",
      "coref\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "We\n",
      "not its instruction-tuned variant\n",
      "subj_obj\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "not its instruction-tuned variant\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "coref\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "performance between Llama 2\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "While it is difficult to compare performance between Llama 2 and T5 due to the massive difference in model sizes (Llama 2: 7B vs. \\text{T5}_{\\textsc{LARGE}}: 770M parameters), the E2E model with Llama 2 substantially outperforms the latter on the Challenge aspect.\n",
      "\n",
      "\n",
      "Path 193: 55.75143523493211\n",
      "step chain-of-thought or end-to-end abstractive summarization\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "the model\n",
      "subj_obj\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the model\n",
      "the model\n",
      "coref\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "\n",
      "the model\n",
      "the popular Llama 2 model\n",
      "shared_text\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "fine-tune the Llama 2 7B.\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "\n",
      "fine-tune the Llama 2 7B.\n",
      "We\n",
      "subj_obj\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "\n",
      "We\n",
      "We\n",
      "coref\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "We\n",
      "not its instruction-tuned variant\n",
      "subj_obj\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "not its instruction-tuned variant\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "coref\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "performance between Llama 2\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "While it is difficult to compare performance between Llama 2 and T5 due to the massive difference in model sizes (Llama 2: 7B vs. \\text{T5}_{\\textsc{LARGE}}: 770M parameters), the E2E model with Llama 2 substantially outperforms the latter on the Challenge aspect.\n",
      "\n",
      "\n",
      "Path 194: 55.75143523493211\n",
      "step chain-of-thought or end-to-end abstractive summarization\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "the model\n",
      "subj_obj\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the model\n",
      "the model\n",
      "coref\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "\n",
      "the model\n",
      "the popular Llama 2 model\n",
      "shared_text\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "fine-tune the Llama 2 7B.\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "\n",
      "fine-tune the Llama 2 7B.\n",
      "the Llama 2 model\n",
      "coref\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "the Llama 2 model\n",
      "We\n",
      "subj_obj\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "We\n",
      "not its instruction-tuned variant\n",
      "subj_obj\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "not its instruction-tuned variant\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "coref\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "performance between Llama 2\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "While it is difficult to compare performance between Llama 2 and T5 due to the massive difference in model sizes (Llama 2: 7B vs. \\text{T5}_{\\textsc{LARGE}}: 770M parameters), the E2E model with Llama 2 substantially outperforms the latter on the Challenge aspect.\n",
      "\n",
      "\n",
      "Path 195: 55.75143523493211\n",
      "step chain-of-thought or end-to-end abstractive summarization\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "the model\n",
      "subj_obj\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the model\n",
      "the model\n",
      "coref\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "\n",
      "the model\n",
      "the popular Llama 2 model\n",
      "shared_text\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "fine-tune the Llama 2 7B.\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "\n",
      "fine-tune the Llama 2 7B.\n",
      "the Llama 2 model\n",
      "coref\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "the Llama 2 model\n",
      "We\n",
      "subj_obj\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "We\n",
      "not its instruction-tuned variant\n",
      "subj_obj\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "not its instruction-tuned variant\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "coref\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "performance between Llama 2\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "While it is difficult to compare performance between Llama 2 and T5 due to the massive difference in model sizes (Llama 2: 7B vs. \\text{T5}_{\\textsc{LARGE}}: 770M parameters), the E2E model with Llama 2 substantially outperforms the latter on the Challenge aspect.\n",
      "\n",
      "\n",
      "Path 196: 55.75143523493211\n",
      "step chain-of-thought or end-to-end abstractive summarization\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "the model\n",
      "subj_obj\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the model\n",
      "the model\n",
      "coref\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "\n",
      "the model\n",
      "the popular Llama 2 model\n",
      "shared_text\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "fine-tune the Llama 2 7B.\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "\n",
      "fine-tune the Llama 2 7B.\n",
      "the Llama 2 model\n",
      "coref\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "the Llama 2 model\n",
      "we\n",
      "subj_obj\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "we\n",
      "not its instruction-tuned variant\n",
      "subj_obj\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "not its instruction-tuned variant\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "coref\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "performance between Llama 2\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "While it is difficult to compare performance between Llama 2 and T5 due to the massive difference in model sizes (Llama 2: 7B vs. \\text{T5}_{\\textsc{LARGE}}: 770M parameters), the E2E model with Llama 2 substantially outperforms the latter on the Challenge aspect.\n",
      "\n",
      "\n",
      "Path 197: 55.75143523493211\n",
      "step chain-of-thought or end-to-end abstractive summarization\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "the model\n",
      "subj_obj\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the model\n",
      "the model\n",
      "coref\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "\n",
      "the model\n",
      "the popular Llama 2 model\n",
      "shared_text\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "fine-tune the Llama 2 7B.\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "\n",
      "fine-tune the Llama 2 7B.\n",
      "the Llama 2 model\n",
      "coref\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "the Llama 2 model\n",
      "we\n",
      "subj_obj\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "we\n",
      "not its instruction-tuned variant\n",
      "subj_obj\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "not its instruction-tuned variant\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "coref\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "performance between Llama 2\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "While it is difficult to compare performance between Llama 2 and T5 due to the massive difference in model sizes (Llama 2: 7B vs. \\text{T5}_{\\textsc{LARGE}}: 770M parameters), the E2E model with Llama 2 substantially outperforms the latter on the Challenge aspect.\n",
      "\n",
      "\n",
      "Path 198: 55.75143523493211\n",
      "step chain-of-thought or end-to-end abstractive summarization\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "the model\n",
      "subj_obj\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the model\n",
      "the model\n",
      "coref\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "\n",
      "the model\n",
      "the popular Llama 2 model\n",
      "shared_text\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "fine-tune the Llama 2 7B.\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "\n",
      "fine-tune the Llama 2 7B.\n",
      "the Llama 2 model\n",
      "coref\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "the Llama 2 model\n",
      "We\n",
      "subj_obj\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "We\n",
      "not its instruction-tuned variant\n",
      "subj_obj\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "not its instruction-tuned variant\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "coref\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "performance between Llama 2\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "While it is difficult to compare performance between Llama 2 and T5 due to the massive difference in model sizes (Llama 2: 7B vs. \\text{T5}_{\\textsc{LARGE}}: 770M parameters), the E2E model with Llama 2 substantially outperforms the latter on the Challenge aspect.\n",
      "\n",
      "\n",
      "Path 199: 55.75143523493211\n",
      "step chain-of-thought or end-to-end abstractive summarization\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "the model\n",
      "subj_obj\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the model\n",
      "the model\n",
      "coref\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "\n",
      "the model\n",
      "the popular Llama 2 model\n",
      "shared_text\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "fine-tune the Llama 2 7B.\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "\n",
      "fine-tune the Llama 2 7B.\n",
      "the Llama 2 model\n",
      "coref\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "the Llama 2 model\n",
      "We\n",
      "subj_obj\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "We\n",
      "not its instruction-tuned variant\n",
      "subj_obj\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "not its instruction-tuned variant\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "coref\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "performance between Llama 2\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "While it is difficult to compare performance between Llama 2 and T5 due to the massive difference in model sizes (Llama 2: 7B vs. \\text{T5}_{\\textsc{LARGE}}: 770M parameters), the E2E model with Llama 2 substantially outperforms the latter on the Challenge aspect.\n",
      "\n",
      "\n",
      "Path 200: 55.75143523493211\n",
      "step chain-of-thought or end-to-end abstractive summarization\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "the model\n",
      "subj_obj\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the model\n",
      "the model\n",
      "coref\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "\n",
      "the model\n",
      "the popular Llama 2 model\n",
      "shared_text\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "fine-tune the Llama 2 7B.\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "\n",
      "fine-tune the Llama 2 7B.\n",
      "the Llama 2 model\n",
      "coref\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "the Llama 2 model\n",
      "we\n",
      "subj_obj\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "we\n",
      "not its instruction-tuned variant\n",
      "subj_obj\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "not its instruction-tuned variant\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "coref\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "performance between Llama 2\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "While it is difficult to compare performance between Llama 2 and T5 due to the massive difference in model sizes (Llama 2: 7B vs. \\text{T5}_{\\textsc{LARGE}}: 770M parameters), the E2E model with Llama 2 substantially outperforms the latter on the Challenge aspect.\n",
      "\n",
      "\n",
      "Path 201: 55.75143523493211\n",
      "step chain-of-thought or end-to-end abstractive summarization\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "the model\n",
      "subj_obj\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the model\n",
      "the model\n",
      "coref\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "\n",
      "the model\n",
      "the popular Llama 2 model\n",
      "shared_text\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "fine-tune the Llama 2 7B.\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "\n",
      "fine-tune the Llama 2 7B.\n",
      "the Llama 2 model\n",
      "coref\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "the Llama 2 model\n",
      "we\n",
      "subj_obj\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "we\n",
      "not its instruction-tuned variant\n",
      "subj_obj\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "not its instruction-tuned variant\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "coref\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "performance between Llama 2\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "While it is difficult to compare performance between Llama 2 and T5 due to the massive difference in model sizes (Llama 2: 7B vs. \\text{T5}_{\\textsc{LARGE}}: 770M parameters), the E2E model with Llama 2 substantially outperforms the latter on the Challenge aspect.\n",
      "\n",
      "\n",
      "Path 202: 55.78663374328505\n",
      "step chain-of-thought or end-to-end abstractive summarization\n",
      "our extractive and abstractive summarization annotations\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "our extractive and abstractive summarization annotations\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "we\n",
      "coref\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "the popular Llama 2 model\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "the Llama 2 model\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "the Llama 2 model\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "shared_text\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "We\n",
      "subj_obj\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "We\n",
      "results\n",
      "subj_obj\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "results\n",
      "Results\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "Results and discussions.\n",
      "\n",
      "Results\n",
      "This result\n",
      "shared_text\n",
      "Results and discussions.\n",
      "This result shows that the models have learned the required output structure yet perform poorly on prediction.\n",
      "\n",
      "\n",
      "Path 203: 55.78663374328505\n",
      "step chain-of-thought or end-to-end abstractive summarization\n",
      "our extractive and abstractive summarization annotations\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "our extractive and abstractive summarization annotations\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "we\n",
      "coref\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "the popular Llama 2 model\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "the Llama 2 model\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "the Llama 2 model\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "shared_text\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "We\n",
      "subj_obj\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "We\n",
      "results\n",
      "subj_obj\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "results\n",
      "Results\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "Results and discussions.\n",
      "\n",
      "Results\n",
      "This result\n",
      "shared_text\n",
      "Results and discussions.\n",
      "This result shows that the models have learned the required output structure yet perform poorly on prediction.\n",
      "\n",
      "\n",
      "Path 204: 55.78663374328505\n",
      "step chain-of-thought or end-to-end abstractive summarization\n",
      "our extractive and abstractive summarization annotations\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "our extractive and abstractive summarization annotations\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "we\n",
      "coref\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "the popular Llama 2 model\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "the Llama 2 model\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "the Llama 2 model\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "shared_text\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "We\n",
      "subj_obj\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "We\n",
      "zero-shot prompting\n",
      "subj_obj\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "zero-shot prompting\n",
      "zero-shot prompting\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "By comparing zero-shot prompting and end-to-end tuning, one can observe that even with LLMs that are shown to be strong in summarization without any training, our dataset can help to improve their performance.\n",
      "\n",
      "\n",
      "Path 205: 55.78663374328505\n",
      "step chain-of-thought or end-to-end abstractive summarization\n",
      "our extractive and abstractive summarization annotations\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "our extractive and abstractive summarization annotations\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "we\n",
      "coref\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "its summarization abilities\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "its summarization abilities\n",
      "the popular Llama 2 model\n",
      "coref\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "the Llama 2 model\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "the Llama 2 model\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "shared_text\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "We\n",
      "subj_obj\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "We\n",
      "zero-shot prompting\n",
      "subj_obj\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "zero-shot prompting\n",
      "zero-shot prompting\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "By comparing zero-shot prompting and end-to-end tuning, one can observe that even with LLMs that are shown to be strong in summarization without any training, our dataset can help to improve their performance.\n",
      "\n",
      "\n",
      "Path 206: 55.78663374328505\n",
      "step chain-of-thought or end-to-end abstractive summarization\n",
      "our extractive and abstractive summarization annotations\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "our extractive and abstractive summarization annotations\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "we\n",
      "coref\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "the popular Llama 2 model\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "the Llama 2 model\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "the Llama 2 model\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "shared_text\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "We\n",
      "subj_obj\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "We\n",
      "zero-shot prompting\n",
      "subj_obj\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "zero-shot prompting\n",
      "zero-shot prompting\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "By comparing zero-shot prompting and end-to-end tuning, one can observe that even with LLMs that are shown to be strong in summarization without any training, our dataset can help to improve their performance.\n",
      "\n",
      "\n",
      "Path 207: 55.78663374328505\n",
      "step chain-of-thought or end-to-end abstractive summarization\n",
      "our extractive and abstractive summarization annotations\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "our extractive and abstractive summarization annotations\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "we\n",
      "coref\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "its summarization abilities\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "its summarization abilities\n",
      "the popular Llama 2 model\n",
      "coref\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "the Llama 2 model\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "the Llama 2 model\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "shared_text\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "We\n",
      "subj_obj\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "We\n",
      "zero-shot prompting\n",
      "subj_obj\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "zero-shot prompting\n",
      "zero-shot prompting\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "By comparing zero-shot prompting and end-to-end tuning, one can observe that even with LLMs that are shown to be strong in summarization without any training, our dataset can help to improve their performance.\n",
      "\n",
      "\n",
      "Path 208: 56.02893078585603\n",
      "Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization,\n",
      "our extractive and abstractive summarization annotations\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "our extractive and abstractive summarization annotations\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "we\n",
      "coref\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "the popular Llama 2 model\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "the Llama 2 model\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "the Llama 2 model\n",
      "We\n",
      "subj_obj\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "We\n",
      "not its instruction-tuned variant\n",
      "subj_obj\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "not its instruction-tuned variant\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "coref\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "performance between Llama 2\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "While it is difficult to compare performance between Llama 2 and T5 due to the massive difference in model sizes (Llama 2: 7B vs. \\text{T5}_{\\textsc{LARGE}}: 770M parameters), the E2E model with Llama 2 substantially outperforms the latter on the Challenge aspect.\n",
      "\n",
      "\n",
      "Path 209: 56.02893078585603\n",
      "Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization,\n",
      "our extractive and abstractive summarization annotations\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "our extractive and abstractive summarization annotations\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "we\n",
      "coref\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "the popular Llama 2 model\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "the Llama 2 model\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "the Llama 2 model\n",
      "We\n",
      "subj_obj\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "We\n",
      "not its instruction-tuned variant\n",
      "subj_obj\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "not its instruction-tuned variant\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "coref\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "performance between Llama 2\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "While it is difficult to compare performance between Llama 2 and T5 due to the massive difference in model sizes (Llama 2: 7B vs. \\text{T5}_{\\textsc{LARGE}}: 770M parameters), the E2E model with Llama 2 substantially outperforms the latter on the Challenge aspect.\n",
      "\n",
      "\n",
      "Path 210: 56.02893078585603\n",
      "Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization,\n",
      "our extractive and abstractive summarization annotations\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "our extractive and abstractive summarization annotations\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "we\n",
      "coref\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "the popular Llama 2 model\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "the Llama 2 model\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "the Llama 2 model\n",
      "we\n",
      "subj_obj\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "we\n",
      "not its instruction-tuned variant\n",
      "subj_obj\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "not its instruction-tuned variant\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "coref\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "performance between Llama 2\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "While it is difficult to compare performance between Llama 2 and T5 due to the massive difference in model sizes (Llama 2: 7B vs. \\text{T5}_{\\textsc{LARGE}}: 770M parameters), the E2E model with Llama 2 substantially outperforms the latter on the Challenge aspect.\n",
      "\n",
      "\n",
      "Path 211: 56.02893078585603\n",
      "Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization,\n",
      "our extractive and abstractive summarization annotations\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "our extractive and abstractive summarization annotations\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "we\n",
      "coref\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "the popular Llama 2 model\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "the Llama 2 model\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "the Llama 2 model\n",
      "we\n",
      "subj_obj\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "we\n",
      "not its instruction-tuned variant\n",
      "subj_obj\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "not its instruction-tuned variant\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "coref\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "performance between Llama 2\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "While it is difficult to compare performance between Llama 2 and T5 due to the massive difference in model sizes (Llama 2: 7B vs. \\text{T5}_{\\textsc{LARGE}}: 770M parameters), the E2E model with Llama 2 substantially outperforms the latter on the Challenge aspect.\n",
      "\n",
      "\n",
      "Path 212: 56.02893078585603\n",
      "Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization,\n",
      "our extractive and abstractive summarization annotations\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "our extractive and abstractive summarization annotations\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "we\n",
      "coref\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "its summarization abilities\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "its summarization abilities\n",
      "the popular Llama 2 model\n",
      "coref\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "the Llama 2 model\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "the Llama 2 model\n",
      "We\n",
      "subj_obj\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "We\n",
      "not its instruction-tuned variant\n",
      "subj_obj\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "not its instruction-tuned variant\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "coref\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "performance between Llama 2\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "While it is difficult to compare performance between Llama 2 and T5 due to the massive difference in model sizes (Llama 2: 7B vs. \\text{T5}_{\\textsc{LARGE}}: 770M parameters), the E2E model with Llama 2 substantially outperforms the latter on the Challenge aspect.\n",
      "\n",
      "\n",
      "Path 213: 56.02893078585603\n",
      "Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization,\n",
      "our extractive and abstractive summarization annotations\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "our extractive and abstractive summarization annotations\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "we\n",
      "coref\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "its summarization abilities\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "its summarization abilities\n",
      "the popular Llama 2 model\n",
      "coref\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "the Llama 2 model\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "the Llama 2 model\n",
      "We\n",
      "subj_obj\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "We\n",
      "not its instruction-tuned variant\n",
      "subj_obj\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "not its instruction-tuned variant\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "coref\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "performance between Llama 2\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "While it is difficult to compare performance between Llama 2 and T5 due to the massive difference in model sizes (Llama 2: 7B vs. \\text{T5}_{\\textsc{LARGE}}: 770M parameters), the E2E model with Llama 2 substantially outperforms the latter on the Challenge aspect.\n",
      "\n",
      "\n",
      "Path 214: 56.02893078585603\n",
      "Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization,\n",
      "our extractive and abstractive summarization annotations\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "our extractive and abstractive summarization annotations\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "we\n",
      "coref\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "its summarization abilities\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "its summarization abilities\n",
      "the popular Llama 2 model\n",
      "coref\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "the Llama 2 model\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "the Llama 2 model\n",
      "we\n",
      "subj_obj\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "we\n",
      "not its instruction-tuned variant\n",
      "subj_obj\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "not its instruction-tuned variant\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "coref\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "performance between Llama 2\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "While it is difficult to compare performance between Llama 2 and T5 due to the massive difference in model sizes (Llama 2: 7B vs. \\text{T5}_{\\textsc{LARGE}}: 770M parameters), the E2E model with Llama 2 substantially outperforms the latter on the Challenge aspect.\n",
      "\n",
      "\n",
      "Path 215: 56.02893078585603\n",
      "Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization,\n",
      "our extractive and abstractive summarization annotations\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "our extractive and abstractive summarization annotations\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "we\n",
      "coref\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "its summarization abilities\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "its summarization abilities\n",
      "the popular Llama 2 model\n",
      "coref\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "the Llama 2 model\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "the Llama 2 model\n",
      "we\n",
      "subj_obj\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "we\n",
      "not its instruction-tuned variant\n",
      "subj_obj\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "not its instruction-tuned variant\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "coref\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "performance between Llama 2\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "While it is difficult to compare performance between Llama 2 and T5 due to the massive difference in model sizes (Llama 2: 7B vs. \\text{T5}_{\\textsc{LARGE}}: 770M parameters), the E2E model with Llama 2 substantially outperforms the latter on the Challenge aspect.\n",
      "\n",
      "\n",
      "Path 216: 56.02893078585603\n",
      "Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization,\n",
      "our extractive and abstractive summarization annotations\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "our extractive and abstractive summarization annotations\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "we\n",
      "coref\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "the popular Llama 2 model\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "the Llama 2 model\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "the Llama 2 model\n",
      "We\n",
      "subj_obj\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "We\n",
      "not its instruction-tuned variant\n",
      "subj_obj\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "not its instruction-tuned variant\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "coref\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "performance between Llama 2\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "While it is difficult to compare performance between Llama 2 and T5 due to the massive difference in model sizes (Llama 2: 7B vs. \\text{T5}_{\\textsc{LARGE}}: 770M parameters), the E2E model with Llama 2 substantially outperforms the latter on the Challenge aspect.\n",
      "\n",
      "\n",
      "Path 217: 56.02893078585603\n",
      "Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization,\n",
      "our extractive and abstractive summarization annotations\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "our extractive and abstractive summarization annotations\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "we\n",
      "coref\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "the popular Llama 2 model\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "the Llama 2 model\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "the Llama 2 model\n",
      "We\n",
      "subj_obj\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "We\n",
      "not its instruction-tuned variant\n",
      "subj_obj\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "not its instruction-tuned variant\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "coref\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "performance between Llama 2\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "While it is difficult to compare performance between Llama 2 and T5 due to the massive difference in model sizes (Llama 2: 7B vs. \\text{T5}_{\\textsc{LARGE}}: 770M parameters), the E2E model with Llama 2 substantially outperforms the latter on the Challenge aspect.\n",
      "\n",
      "\n",
      "Path 218: 56.02893078585603\n",
      "Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization,\n",
      "our extractive and abstractive summarization annotations\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "our extractive and abstractive summarization annotations\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "we\n",
      "coref\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "the popular Llama 2 model\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "the Llama 2 model\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "the Llama 2 model\n",
      "we\n",
      "subj_obj\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "we\n",
      "not its instruction-tuned variant\n",
      "subj_obj\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "not its instruction-tuned variant\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "coref\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "performance between Llama 2\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "While it is difficult to compare performance between Llama 2 and T5 due to the massive difference in model sizes (Llama 2: 7B vs. \\text{T5}_{\\textsc{LARGE}}: 770M parameters), the E2E model with Llama 2 substantially outperforms the latter on the Challenge aspect.\n",
      "\n",
      "\n",
      "Path 219: 56.02893078585603\n",
      "Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization,\n",
      "our extractive and abstractive summarization annotations\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "our extractive and abstractive summarization annotations\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "we\n",
      "coref\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "the popular Llama 2 model\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "the Llama 2 model\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "the Llama 2 model\n",
      "we\n",
      "subj_obj\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "we\n",
      "not its instruction-tuned variant\n",
      "subj_obj\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "not its instruction-tuned variant\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "coref\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "performance between Llama 2\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "While it is difficult to compare performance between Llama 2 and T5 due to the massive difference in model sizes (Llama 2: 7B vs. \\text{T5}_{\\textsc{LARGE}}: 770M parameters), the E2E model with Llama 2 substantially outperforms the latter on the Challenge aspect.\n",
      "\n",
      "\n",
      "Path 220: 56.02893078585603\n",
      "Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization,\n",
      "our extractive and abstractive summarization annotations\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "our extractive and abstractive summarization annotations\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "we\n",
      "coref\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "its summarization abilities\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "its summarization abilities\n",
      "the popular Llama 2 model\n",
      "coref\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "the Llama 2 model\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "the Llama 2 model\n",
      "We\n",
      "subj_obj\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "We\n",
      "not its instruction-tuned variant\n",
      "subj_obj\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "not its instruction-tuned variant\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "coref\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "performance between Llama 2\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "While it is difficult to compare performance between Llama 2 and T5 due to the massive difference in model sizes (Llama 2: 7B vs. \\text{T5}_{\\textsc{LARGE}}: 770M parameters), the E2E model with Llama 2 substantially outperforms the latter on the Challenge aspect.\n",
      "\n",
      "\n",
      "Path 221: 56.02893078585603\n",
      "Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization,\n",
      "our extractive and abstractive summarization annotations\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "our extractive and abstractive summarization annotations\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "we\n",
      "coref\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "its summarization abilities\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "its summarization abilities\n",
      "the popular Llama 2 model\n",
      "coref\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "the Llama 2 model\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "the Llama 2 model\n",
      "We\n",
      "subj_obj\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "We\n",
      "not its instruction-tuned variant\n",
      "subj_obj\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "not its instruction-tuned variant\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "coref\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "performance between Llama 2\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "While it is difficult to compare performance between Llama 2 and T5 due to the massive difference in model sizes (Llama 2: 7B vs. \\text{T5}_{\\textsc{LARGE}}: 770M parameters), the E2E model with Llama 2 substantially outperforms the latter on the Challenge aspect.\n",
      "\n",
      "\n",
      "Path 222: 56.02893078585603\n",
      "Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization,\n",
      "our extractive and abstractive summarization annotations\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "our extractive and abstractive summarization annotations\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "we\n",
      "coref\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "its summarization abilities\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "its summarization abilities\n",
      "the popular Llama 2 model\n",
      "coref\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "the Llama 2 model\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "the Llama 2 model\n",
      "we\n",
      "subj_obj\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "we\n",
      "not its instruction-tuned variant\n",
      "subj_obj\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "not its instruction-tuned variant\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "coref\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "performance between Llama 2\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "While it is difficult to compare performance between Llama 2 and T5 due to the massive difference in model sizes (Llama 2: 7B vs. \\text{T5}_{\\textsc{LARGE}}: 770M parameters), the E2E model with Llama 2 substantially outperforms the latter on the Challenge aspect.\n",
      "\n",
      "\n",
      "Path 223: 56.02893078585603\n",
      "Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization,\n",
      "our extractive and abstractive summarization annotations\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "our extractive and abstractive summarization annotations\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "we\n",
      "coref\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "its summarization abilities\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "its summarization abilities\n",
      "the popular Llama 2 model\n",
      "coref\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "the Llama 2 model\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "the Llama 2 model\n",
      "we\n",
      "subj_obj\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "we\n",
      "not its instruction-tuned variant\n",
      "subj_obj\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "not its instruction-tuned variant\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "coref\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "performance between Llama 2\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "While it is difficult to compare performance between Llama 2 and T5 due to the massive difference in model sizes (Llama 2: 7B vs. \\text{T5}_{\\textsc{LARGE}}: 770M parameters), the E2E model with Llama 2 substantially outperforms the latter on the Challenge aspect.\n",
      "\n",
      "\n",
      "Path 224: 56.130261318489524\n",
      "step chain-of-thought or end-to-end abstractive summarization\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "the model\n",
      "subj_obj\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the model\n",
      "the model\n",
      "coref\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "\n",
      "the model\n",
      "the popular Llama 2 model\n",
      "shared_text\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "fine-tune the Llama 2 7B.\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "\n",
      "fine-tune the Llama 2 7B.\n",
      "the Llama 2 model\n",
      "coref\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "the Llama 2 model\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "shared_text\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "We\n",
      "subj_obj\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "We\n",
      "zero-shot prompting\n",
      "subj_obj\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "zero-shot prompting\n",
      "zero-shot prompting\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "By comparing zero-shot prompting and end-to-end tuning, one can observe that even with LLMs that are shown to be strong in summarization without any training, our dataset can help to improve their performance.\n",
      "\n",
      "\n",
      "Path 225: 56.130261318489524\n",
      "step chain-of-thought or end-to-end abstractive summarization\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "the model\n",
      "subj_obj\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the model\n",
      "the model\n",
      "coref\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "\n",
      "the model\n",
      "the popular Llama 2 model\n",
      "shared_text\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "fine-tune the Llama 2 7B.\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "\n",
      "fine-tune the Llama 2 7B.\n",
      "the Llama 2 model\n",
      "coref\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "the Llama 2 model\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "shared_text\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "We\n",
      "subj_obj\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "We\n",
      "zero-shot prompting\n",
      "subj_obj\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "zero-shot prompting\n",
      "zero-shot prompting\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "By comparing zero-shot prompting and end-to-end tuning, one can observe that even with LLMs that are shown to be strong in summarization without any training, our dataset can help to improve their performance.\n",
      "\n",
      "\n",
      "Path 226: 56.130261318489524\n",
      "step chain-of-thought or end-to-end abstractive summarization\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "the model\n",
      "subj_obj\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the model\n",
      "the model\n",
      "coref\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "\n",
      "the model\n",
      "the popular Llama 2 model\n",
      "shared_text\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "fine-tune the Llama 2 7B.\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "\n",
      "fine-tune the Llama 2 7B.\n",
      "the Llama 2 model\n",
      "coref\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "the Llama 2 model\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "shared_text\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "We\n",
      "subj_obj\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "We\n",
      "zero-shot prompting\n",
      "subj_obj\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "zero-shot prompting\n",
      "zero-shot prompting\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "By comparing zero-shot prompting and end-to-end tuning, one can observe that even with LLMs that are shown to be strong in summarization without any training, our dataset can help to improve their performance.\n",
      "\n",
      "\n",
      "Path 227: 56.130261318489524\n",
      "step chain-of-thought or end-to-end abstractive summarization\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "the model\n",
      "subj_obj\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the model\n",
      "the model\n",
      "coref\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "\n",
      "the model\n",
      "the popular Llama 2 model\n",
      "shared_text\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "fine-tune the Llama 2 7B.\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "\n",
      "fine-tune the Llama 2 7B.\n",
      "the Llama 2 model\n",
      "coref\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "the Llama 2 model\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "shared_text\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "We\n",
      "subj_obj\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "We\n",
      "zero-shot prompting\n",
      "subj_obj\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "zero-shot prompting\n",
      "zero-shot prompting\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "By comparing zero-shot prompting and end-to-end tuning, one can observe that even with LLMs that are shown to be strong in summarization without any training, our dataset can help to improve their performance.\n",
      "\n",
      "\n",
      "Path 228: 56.28789213442635\n",
      "step chain-of-thought or end-to-end abstractive summarization\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "the model\n",
      "subj_obj\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the model\n",
      "the model\n",
      "coref\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "\n",
      "the popular Llama 2 model\n",
      "fine-tune the Llama 2 7B.\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "\n",
      "fine-tune the Llama 2 7B.\n",
      "the Llama 2 model\n",
      "coref\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "the Llama 2 model\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "shared_text\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "performance between Llama 2\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "While it is difficult to compare performance between Llama 2 and T5 due to the massive difference in model sizes (Llama 2: 7B vs. \\text{T5}_{\\textsc{LARGE}}: 770M parameters), the E2E model with Llama 2 substantially outperforms the latter on the Challenge aspect.\n",
      "\n",
      "\n",
      "Path 229: 56.28789213442635\n",
      "step chain-of-thought or end-to-end abstractive summarization\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "the model\n",
      "subj_obj\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the model\n",
      "the model\n",
      "coref\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "\n",
      "the popular Llama 2 model\n",
      "fine-tune the Llama 2 7B.\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "\n",
      "fine-tune the Llama 2 7B.\n",
      "the Llama 2 model\n",
      "coref\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "the Llama 2 model\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "shared_text\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "performance between Llama 2\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "While it is difficult to compare performance between Llama 2 and T5 due to the massive difference in model sizes (Llama 2: 7B vs. \\text{T5}_{\\textsc{LARGE}}: 770M parameters), the E2E model with Llama 2 substantially outperforms the latter on the Challenge aspect.\n",
      "\n",
      "\n",
      "Path 230: 56.28789213442635\n",
      "step chain-of-thought or end-to-end abstractive summarization\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "the model\n",
      "subj_obj\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the model\n",
      "the model\n",
      "coref\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "\n",
      "the popular Llama 2 model\n",
      "fine-tune the Llama 2 7B.\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "\n",
      "fine-tune the Llama 2 7B.\n",
      "the Llama 2 model\n",
      "coref\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "the Llama 2 model\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "shared_text\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "performance between Llama 2\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "While it is difficult to compare performance between Llama 2 and T5 due to the massive difference in model sizes (Llama 2: 7B vs. \\text{T5}_{\\textsc{LARGE}}: 770M parameters), the E2E model with Llama 2 substantially outperforms the latter on the Challenge aspect.\n",
      "\n",
      "\n",
      "Path 231: 56.28789213442635\n",
      "step chain-of-thought or end-to-end abstractive summarization\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "the model\n",
      "subj_obj\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the model\n",
      "the model\n",
      "coref\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "\n",
      "the popular Llama 2 model\n",
      "fine-tune the Llama 2 7B.\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "\n",
      "fine-tune the Llama 2 7B.\n",
      "the Llama 2 model\n",
      "coref\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "the Llama 2 model\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "shared_text\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "performance between Llama 2\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "While it is difficult to compare performance between Llama 2 and T5 due to the massive difference in model sizes (Llama 2: 7B vs. \\text{T5}_{\\textsc{LARGE}}: 770M parameters), the E2E model with Llama 2 substantially outperforms the latter on the Challenge aspect.\n",
      "\n",
      "\n",
      "Path 232: 56.40775686941345\n",
      "Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization,\n",
      "our extractive and abstractive summarization annotations\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "our extractive and abstractive summarization annotations\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "we\n",
      "coref\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "the popular Llama 2 model\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "the Llama 2 model\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "the Llama 2 model\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "shared_text\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "We\n",
      "subj_obj\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "We\n",
      "results\n",
      "subj_obj\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "results\n",
      "Results\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "Results and discussions.\n",
      "\n",
      "Results\n",
      "This result\n",
      "shared_text\n",
      "Results and discussions.\n",
      "This result shows that the models have learned the required output structure yet perform poorly on prediction.\n",
      "\n",
      "\n",
      "Path 233: 56.40775686941345\n",
      "Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization,\n",
      "our extractive and abstractive summarization annotations\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "our extractive and abstractive summarization annotations\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "we\n",
      "coref\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "the popular Llama 2 model\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "the Llama 2 model\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "the Llama 2 model\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "shared_text\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "We\n",
      "subj_obj\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "We\n",
      "results\n",
      "subj_obj\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "results\n",
      "Results\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "Results and discussions.\n",
      "\n",
      "Results\n",
      "This result\n",
      "shared_text\n",
      "Results and discussions.\n",
      "This result shows that the models have learned the required output structure yet perform poorly on prediction.\n",
      "\n",
      "\n",
      "Path 234: 56.40775686941345\n",
      "Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization,\n",
      "our extractive and abstractive summarization annotations\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "our extractive and abstractive summarization annotations\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "we\n",
      "coref\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "the popular Llama 2 model\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "the Llama 2 model\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "the Llama 2 model\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "shared_text\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "We\n",
      "subj_obj\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "We\n",
      "zero-shot prompting\n",
      "subj_obj\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "zero-shot prompting\n",
      "zero-shot prompting\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "By comparing zero-shot prompting and end-to-end tuning, one can observe that even with LLMs that are shown to be strong in summarization without any training, our dataset can help to improve their performance.\n",
      "\n",
      "\n",
      "Path 235: 56.40775686941345\n",
      "Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization,\n",
      "our extractive and abstractive summarization annotations\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "our extractive and abstractive summarization annotations\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "we\n",
      "coref\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "its summarization abilities\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "its summarization abilities\n",
      "the popular Llama 2 model\n",
      "coref\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "the Llama 2 model\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "the Llama 2 model\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "shared_text\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "We\n",
      "subj_obj\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "We\n",
      "zero-shot prompting\n",
      "subj_obj\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "zero-shot prompting\n",
      "zero-shot prompting\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "By comparing zero-shot prompting and end-to-end tuning, one can observe that even with LLMs that are shown to be strong in summarization without any training, our dataset can help to improve their performance.\n",
      "\n",
      "\n",
      "Path 236: 56.40775686941345\n",
      "Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization,\n",
      "our extractive and abstractive summarization annotations\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "our extractive and abstractive summarization annotations\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "we\n",
      "coref\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "the popular Llama 2 model\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "the Llama 2 model\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "the Llama 2 model\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "shared_text\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "We\n",
      "subj_obj\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "We\n",
      "zero-shot prompting\n",
      "subj_obj\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "zero-shot prompting\n",
      "zero-shot prompting\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "By comparing zero-shot prompting and end-to-end tuning, one can observe that even with LLMs that are shown to be strong in summarization without any training, our dataset can help to improve their performance.\n",
      "\n",
      "\n",
      "Path 237: 56.40775686941345\n",
      "Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization,\n",
      "our extractive and abstractive summarization annotations\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "our extractive and abstractive summarization annotations\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "we\n",
      "coref\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "its summarization abilities\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "its summarization abilities\n",
      "the popular Llama 2 model\n",
      "coref\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "the Llama 2 model\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "the Llama 2 model\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "shared_text\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "We\n",
      "subj_obj\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "We\n",
      "zero-shot prompting\n",
      "subj_obj\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "zero-shot prompting\n",
      "zero-shot prompting\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "By comparing zero-shot prompting and end-to-end tuning, one can observe that even with LLMs that are shown to be strong in summarization without any training, our dataset can help to improve their performance.\n",
      "\n",
      "\n",
      "Path 238: 56.40780765972764\n",
      "step chain-of-thought or end-to-end abstractive summarization\n",
      "our extractive and abstractive summarization annotations\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "our extractive and abstractive summarization annotations\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "we\n",
      "coref\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "the popular Llama 2 model\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "the Llama 2 model\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "the Llama 2 model\n",
      "We\n",
      "subj_obj\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "We\n",
      "we\n",
      "subj_obj\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "we\n",
      "not its instruction-tuned variant\n",
      "subj_obj\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "not its instruction-tuned variant\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "coref\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "performance between Llama 2\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "While it is difficult to compare performance between Llama 2 and T5 due to the massive difference in model sizes (Llama 2: 7B vs. \\text{T5}_{\\textsc{LARGE}}: 770M parameters), the E2E model with Llama 2 substantially outperforms the latter on the Challenge aspect.\n",
      "\n",
      "\n",
      "Path 239: 56.40780765972764\n",
      "step chain-of-thought or end-to-end abstractive summarization\n",
      "our extractive and abstractive summarization annotations\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "our extractive and abstractive summarization annotations\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "we\n",
      "coref\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "the popular Llama 2 model\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "the Llama 2 model\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "the Llama 2 model\n",
      "We\n",
      "subj_obj\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "We\n",
      "we\n",
      "subj_obj\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "we\n",
      "not its instruction-tuned variant\n",
      "subj_obj\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "not its instruction-tuned variant\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "coref\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "performance between Llama 2\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "While it is difficult to compare performance between Llama 2 and T5 due to the massive difference in model sizes (Llama 2: 7B vs. \\text{T5}_{\\textsc{LARGE}}: 770M parameters), the E2E model with Llama 2 substantially outperforms the latter on the Challenge aspect.\n",
      "\n",
      "\n",
      "Path 240: 56.40780765972764\n",
      "step chain-of-thought or end-to-end abstractive summarization\n",
      "our extractive and abstractive summarization annotations\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "our extractive and abstractive summarization annotations\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "we\n",
      "coref\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "the popular Llama 2 model\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "the Llama 2 model\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "the Llama 2 model\n",
      "we\n",
      "subj_obj\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "we\n",
      "We\n",
      "subj_obj\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "We\n",
      "not its instruction-tuned variant\n",
      "subj_obj\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "not its instruction-tuned variant\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "coref\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "performance between Llama 2\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "While it is difficult to compare performance between Llama 2 and T5 due to the massive difference in model sizes (Llama 2: 7B vs. \\text{T5}_{\\textsc{LARGE}}: 770M parameters), the E2E model with Llama 2 substantially outperforms the latter on the Challenge aspect.\n",
      "\n",
      "\n",
      "Path 241: 56.40780765972764\n",
      "step chain-of-thought or end-to-end abstractive summarization\n",
      "our extractive and abstractive summarization annotations\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "our extractive and abstractive summarization annotations\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "we\n",
      "coref\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "the popular Llama 2 model\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "the Llama 2 model\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "the Llama 2 model\n",
      "we\n",
      "subj_obj\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "we\n",
      "We\n",
      "subj_obj\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "We\n",
      "not its instruction-tuned variant\n",
      "subj_obj\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "not its instruction-tuned variant\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "coref\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "performance between Llama 2\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "While it is difficult to compare performance between Llama 2 and T5 due to the massive difference in model sizes (Llama 2: 7B vs. \\text{T5}_{\\textsc{LARGE}}: 770M parameters), the E2E model with Llama 2 substantially outperforms the latter on the Challenge aspect.\n",
      "\n",
      "\n",
      "Path 242: 56.40780765972764\n",
      "step chain-of-thought or end-to-end abstractive summarization\n",
      "our extractive and abstractive summarization annotations\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "our extractive and abstractive summarization annotations\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "we\n",
      "coref\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "the popular Llama 2 model\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "the Llama 2 model\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "the Llama 2 model\n",
      "We\n",
      "subj_obj\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "We\n",
      "we\n",
      "subj_obj\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "we\n",
      "not its instruction-tuned variant\n",
      "subj_obj\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "not its instruction-tuned variant\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "coref\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "performance between Llama 2\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "While it is difficult to compare performance between Llama 2 and T5 due to the massive difference in model sizes (Llama 2: 7B vs. \\text{T5}_{\\textsc{LARGE}}: 770M parameters), the E2E model with Llama 2 substantially outperforms the latter on the Challenge aspect.\n",
      "\n",
      "\n",
      "Path 243: 56.40780765972764\n",
      "step chain-of-thought or end-to-end abstractive summarization\n",
      "our extractive and abstractive summarization annotations\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "our extractive and abstractive summarization annotations\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "we\n",
      "coref\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "the popular Llama 2 model\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "the Llama 2 model\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "the Llama 2 model\n",
      "We\n",
      "subj_obj\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "We\n",
      "we\n",
      "subj_obj\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "we\n",
      "not its instruction-tuned variant\n",
      "subj_obj\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "not its instruction-tuned variant\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "coref\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "performance between Llama 2\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "While it is difficult to compare performance between Llama 2 and T5 due to the massive difference in model sizes (Llama 2: 7B vs. \\text{T5}_{\\textsc{LARGE}}: 770M parameters), the E2E model with Llama 2 substantially outperforms the latter on the Challenge aspect.\n",
      "\n",
      "\n",
      "Path 244: 56.40780765972764\n",
      "step chain-of-thought or end-to-end abstractive summarization\n",
      "our extractive and abstractive summarization annotations\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "our extractive and abstractive summarization annotations\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "we\n",
      "coref\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "the popular Llama 2 model\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "the Llama 2 model\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "the Llama 2 model\n",
      "we\n",
      "subj_obj\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "we\n",
      "We\n",
      "subj_obj\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "We\n",
      "not its instruction-tuned variant\n",
      "subj_obj\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "not its instruction-tuned variant\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "coref\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "performance between Llama 2\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "While it is difficult to compare performance between Llama 2 and T5 due to the massive difference in model sizes (Llama 2: 7B vs. \\text{T5}_{\\textsc{LARGE}}: 770M parameters), the E2E model with Llama 2 substantially outperforms the latter on the Challenge aspect.\n",
      "\n",
      "\n",
      "Path 245: 56.40780765972764\n",
      "step chain-of-thought or end-to-end abstractive summarization\n",
      "our extractive and abstractive summarization annotations\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "our extractive and abstractive summarization annotations\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "we\n",
      "coref\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "the popular Llama 2 model\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "the Llama 2 model\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "the Llama 2 model\n",
      "we\n",
      "subj_obj\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "we\n",
      "We\n",
      "subj_obj\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "We\n",
      "not its instruction-tuned variant\n",
      "subj_obj\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "not its instruction-tuned variant\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "coref\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "performance between Llama 2\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "While it is difficult to compare performance between Llama 2 and T5 due to the massive difference in model sizes (Llama 2: 7B vs. \\text{T5}_{\\textsc{LARGE}}: 770M parameters), the E2E model with Llama 2 substantially outperforms the latter on the Challenge aspect.\n",
      "\n",
      "\n",
      "Path 246: 56.51236126817678\n",
      "step chain-of-thought or end-to-end abstractive summarization\n",
      "our extractive and abstractive summarization annotations\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "our extractive and abstractive summarization annotations\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "we\n",
      "coref\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "the popular Llama 2 model\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "the model\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "\n",
      "the model\n",
      "the model\n",
      "coref\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the model\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "subj_obj\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "A training data sample used for EtA-CoT\n",
      "shared_text\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "A training data sample used for EtA-CoT is shown in Table 5.\n",
      "\n",
      "A training data sample used for EtA-CoT\n",
      "Table 5\n",
      "subj_obj\n",
      "A training data sample used for EtA-CoT is shown in Table 5.\n",
      "\n",
      "Table 5\n",
      "Table 6\n",
      "shared_text\n",
      "A training data sample used for EtA-CoT is shown in Table 5.\n",
      "Table 6 presents ROUGE scores, BERTScores, and extraction performance using our gold extractive labels measured by F1 for EtA-CoT models.\n",
      "\n",
      "\n",
      "Path 247: 56.51236126817678\n",
      "step chain-of-thought or end-to-end abstractive summarization\n",
      "our extractive and abstractive summarization annotations\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "our extractive and abstractive summarization annotations\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "we\n",
      "coref\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "the popular Llama 2 model\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "the model\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "\n",
      "the model\n",
      "the model\n",
      "coref\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the model\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "subj_obj\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "A training data sample used for EtA-CoT\n",
      "shared_text\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "A training data sample used for EtA-CoT is shown in Table 5.\n",
      "\n",
      "A training data sample used for EtA-CoT\n",
      "Table 5\n",
      "subj_obj\n",
      "A training data sample used for EtA-CoT is shown in Table 5.\n",
      "\n",
      "Table 5\n",
      "Table 6\n",
      "shared_text\n",
      "A training data sample used for EtA-CoT is shown in Table 5.\n",
      "Table 6 presents ROUGE scores, BERTScores, and extraction performance using our gold extractive labels measured by F1 for EtA-CoT models.\n",
      "\n",
      "\n",
      "Path 248: 56.51236126817678\n",
      "step chain-of-thought or end-to-end abstractive summarization\n",
      "our extractive and abstractive summarization annotations\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "our extractive and abstractive summarization annotations\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "we\n",
      "coref\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "the popular Llama 2 model\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "the model\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "\n",
      "the model\n",
      "the model\n",
      "coref\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the model\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "subj_obj\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "A training data sample used for EtA-CoT\n",
      "shared_text\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "A training data sample used for EtA-CoT is shown in Table 5.\n",
      "\n",
      "A training data sample used for EtA-CoT\n",
      "Table 5\n",
      "subj_obj\n",
      "A training data sample used for EtA-CoT is shown in Table 5.\n",
      "\n",
      "Table 5\n",
      "Table 6\n",
      "shared_text\n",
      "A training data sample used for EtA-CoT is shown in Table 5.\n",
      "Table 6 presents ROUGE scores, BERTScores, and extraction performance using our gold extractive labels measured by F1 for EtA-CoT models.\n",
      "\n",
      "\n",
      "Path 249: 56.51236126817678\n",
      "step chain-of-thought or end-to-end abstractive summarization\n",
      "our extractive and abstractive summarization annotations\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "our extractive and abstractive summarization annotations\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "we\n",
      "coref\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "the popular Llama 2 model\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "the model\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "\n",
      "the model\n",
      "the model\n",
      "coref\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the model\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "subj_obj\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "A training data sample used for EtA-CoT\n",
      "shared_text\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "A training data sample used for EtA-CoT is shown in Table 5.\n",
      "\n",
      "A training data sample used for EtA-CoT\n",
      "Table 5\n",
      "subj_obj\n",
      "A training data sample used for EtA-CoT is shown in Table 5.\n",
      "\n",
      "Table 5\n",
      "Table 6\n",
      "shared_text\n",
      "A training data sample used for EtA-CoT is shown in Table 5.\n",
      "Table 6 presents ROUGE scores, BERTScores, and extraction performance using our gold extractive labels measured by F1 for EtA-CoT models.\n",
      "\n",
      "\n",
      "Path 250: 56.6153080161969\n",
      "step chain-of-thought or end-to-end abstractive summarization\n",
      "our extractive and abstractive summarization annotations\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "our extractive and abstractive summarization annotations\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "we\n",
      "coref\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "the popular Llama 2 model\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "fine-tune the Llama 2 7B.\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "\n",
      "fine-tune the Llama 2 7B.\n",
      "the Llama 2 model\n",
      "coref\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "not its instruction-tuned variant\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "shared_text\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "performance between Llama 2\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "While it is difficult to compare performance between Llama 2 and T5 due to the massive difference in model sizes (Llama 2: 7B vs. \\text{T5}_{\\textsc{LARGE}}: 770M parameters), the E2E model with Llama 2 substantially outperforms the latter on the Challenge aspect.\n",
      "\n",
      "\n",
      "Path 251: 56.6153080161969\n",
      "step chain-of-thought or end-to-end abstractive summarization\n",
      "our extractive and abstractive summarization annotations\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "our extractive and abstractive summarization annotations\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "we\n",
      "coref\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "the popular Llama 2 model\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "fine-tune the Llama 2 7B.\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "\n",
      "fine-tune the Llama 2 7B.\n",
      "the Llama 2 model\n",
      "coref\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "not its instruction-tuned variant\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "shared_text\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "performance between Llama 2\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "While it is difficult to compare performance between Llama 2 and T5 due to the massive difference in model sizes (Llama 2: 7B vs. \\text{T5}_{\\textsc{LARGE}}: 770M parameters), the E2E model with Llama 2 substantially outperforms the latter on the Challenge aspect.\n",
      "\n",
      "\n",
      "Path 252: 56.6153080161969\n",
      "step chain-of-thought or end-to-end abstractive summarization\n",
      "our extractive and abstractive summarization annotations\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "our extractive and abstractive summarization annotations\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "we\n",
      "coref\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "the popular Llama 2 model\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "fine-tune the Llama 2 7B.\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "\n",
      "fine-tune the Llama 2 7B.\n",
      "the Llama 2 model\n",
      "coref\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "not its instruction-tuned variant\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "shared_text\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "performance between Llama 2\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "While it is difficult to compare performance between Llama 2 and T5 due to the massive difference in model sizes (Llama 2: 7B vs. \\text{T5}_{\\textsc{LARGE}}: 770M parameters), the E2E model with Llama 2 substantially outperforms the latter on the Challenge aspect.\n",
      "\n",
      "\n",
      "Path 253: 56.6153080161969\n",
      "step chain-of-thought or end-to-end abstractive summarization\n",
      "our extractive and abstractive summarization annotations\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "our extractive and abstractive summarization annotations\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "we\n",
      "coref\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "the popular Llama 2 model\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "fine-tune the Llama 2 7B.\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "\n",
      "fine-tune the Llama 2 7B.\n",
      "the Llama 2 model\n",
      "coref\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "not its instruction-tuned variant\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "shared_text\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "performance between Llama 2\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "While it is difficult to compare performance between Llama 2 and T5 due to the massive difference in model sizes (Llama 2: 7B vs. \\text{T5}_{\\textsc{LARGE}}: 770M parameters), the E2E model with Llama 2 substantially outperforms the latter on the Challenge aspect.\n",
      "\n",
      "\n",
      "Path 254: 56.6153080161969\n",
      "step chain-of-thought or end-to-end abstractive summarization\n",
      "our extractive and abstractive summarization annotations\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "our extractive and abstractive summarization annotations\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "we\n",
      "coref\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "its summarization abilities\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "its summarization abilities\n",
      "the popular Llama 2 model\n",
      "coref\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "fine-tune the Llama 2 7B.\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "\n",
      "fine-tune the Llama 2 7B.\n",
      "the Llama 2 model\n",
      "coref\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "not its instruction-tuned variant\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "shared_text\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "performance between Llama 2\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "While it is difficult to compare performance between Llama 2 and T5 due to the massive difference in model sizes (Llama 2: 7B vs. \\text{T5}_{\\textsc{LARGE}}: 770M parameters), the E2E model with Llama 2 substantially outperforms the latter on the Challenge aspect.\n",
      "\n",
      "\n",
      "Path 255: 56.6153080161969\n",
      "step chain-of-thought or end-to-end abstractive summarization\n",
      "our extractive and abstractive summarization annotations\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "our extractive and abstractive summarization annotations\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "we\n",
      "coref\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "its summarization abilities\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "its summarization abilities\n",
      "the popular Llama 2 model\n",
      "coref\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "fine-tune the Llama 2 7B.\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "\n",
      "fine-tune the Llama 2 7B.\n",
      "the Llama 2 model\n",
      "coref\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "not its instruction-tuned variant\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "shared_text\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "performance between Llama 2\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "While it is difficult to compare performance between Llama 2 and T5 due to the massive difference in model sizes (Llama 2: 7B vs. \\text{T5}_{\\textsc{LARGE}}: 770M parameters), the E2E model with Llama 2 substantially outperforms the latter on the Challenge aspect.\n",
      "\n",
      "\n",
      "Path 256: 56.6153080161969\n",
      "step chain-of-thought or end-to-end abstractive summarization\n",
      "our extractive and abstractive summarization annotations\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "our extractive and abstractive summarization annotations\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "we\n",
      "coref\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "its summarization abilities\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "its summarization abilities\n",
      "the popular Llama 2 model\n",
      "coref\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "fine-tune the Llama 2 7B.\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "\n",
      "fine-tune the Llama 2 7B.\n",
      "the Llama 2 model\n",
      "coref\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "not its instruction-tuned variant\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "shared_text\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "performance between Llama 2\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "While it is difficult to compare performance between Llama 2 and T5 due to the massive difference in model sizes (Llama 2: 7B vs. \\text{T5}_{\\textsc{LARGE}}: 770M parameters), the E2E model with Llama 2 substantially outperforms the latter on the Challenge aspect.\n",
      "\n",
      "\n",
      "Path 257: 56.6153080161969\n",
      "step chain-of-thought or end-to-end abstractive summarization\n",
      "our extractive and abstractive summarization annotations\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "our extractive and abstractive summarization annotations\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "we\n",
      "coref\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "its summarization abilities\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "its summarization abilities\n",
      "the popular Llama 2 model\n",
      "coref\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "fine-tune the Llama 2 7B.\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "\n",
      "fine-tune the Llama 2 7B.\n",
      "the Llama 2 model\n",
      "coref\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "not its instruction-tuned variant\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "shared_text\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "performance between Llama 2\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "While it is difficult to compare performance between Llama 2 and T5 due to the massive difference in model sizes (Llama 2: 7B vs. \\text{T5}_{\\textsc{LARGE}}: 770M parameters), the E2E model with Llama 2 substantially outperforms the latter on the Challenge aspect.\n",
      "\n",
      "\n",
      "Path 258: 56.6153080161969\n",
      "step chain-of-thought or end-to-end abstractive summarization\n",
      "our extractive and abstractive summarization annotations\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "our extractive and abstractive summarization annotations\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "we\n",
      "coref\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "the popular Llama 2 model\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "fine-tune the Llama 2 7B.\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "\n",
      "fine-tune the Llama 2 7B.\n",
      "the Llama 2 model\n",
      "coref\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "not its instruction-tuned variant\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "shared_text\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "performance between Llama 2\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "While it is difficult to compare performance between Llama 2 and T5 due to the massive difference in model sizes (Llama 2: 7B vs. \\text{T5}_{\\textsc{LARGE}}: 770M parameters), the E2E model with Llama 2 substantially outperforms the latter on the Challenge aspect.\n",
      "\n",
      "\n",
      "Path 259: 56.6153080161969\n",
      "step chain-of-thought or end-to-end abstractive summarization\n",
      "our extractive and abstractive summarization annotations\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "our extractive and abstractive summarization annotations\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "we\n",
      "coref\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "the popular Llama 2 model\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "fine-tune the Llama 2 7B.\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "\n",
      "fine-tune the Llama 2 7B.\n",
      "the Llama 2 model\n",
      "coref\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "not its instruction-tuned variant\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "shared_text\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "performance between Llama 2\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "While it is difficult to compare performance between Llama 2 and T5 due to the massive difference in model sizes (Llama 2: 7B vs. \\text{T5}_{\\textsc{LARGE}}: 770M parameters), the E2E model with Llama 2 substantially outperforms the latter on the Challenge aspect.\n",
      "\n",
      "\n",
      "Path 260: 56.6153080161969\n",
      "step chain-of-thought or end-to-end abstractive summarization\n",
      "our extractive and abstractive summarization annotations\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "our extractive and abstractive summarization annotations\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "we\n",
      "coref\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "the popular Llama 2 model\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "fine-tune the Llama 2 7B.\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "\n",
      "fine-tune the Llama 2 7B.\n",
      "the Llama 2 model\n",
      "coref\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "not its instruction-tuned variant\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "shared_text\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "performance between Llama 2\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "While it is difficult to compare performance between Llama 2 and T5 due to the massive difference in model sizes (Llama 2: 7B vs. \\text{T5}_{\\textsc{LARGE}}: 770M parameters), the E2E model with Llama 2 substantially outperforms the latter on the Challenge aspect.\n",
      "\n",
      "\n",
      "Path 261: 56.6153080161969\n",
      "step chain-of-thought or end-to-end abstractive summarization\n",
      "our extractive and abstractive summarization annotations\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "our extractive and abstractive summarization annotations\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "we\n",
      "coref\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "the popular Llama 2 model\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "fine-tune the Llama 2 7B.\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "\n",
      "fine-tune the Llama 2 7B.\n",
      "the Llama 2 model\n",
      "coref\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "not its instruction-tuned variant\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "shared_text\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "performance between Llama 2\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "While it is difficult to compare performance between Llama 2 and T5 due to the massive difference in model sizes (Llama 2: 7B vs. \\text{T5}_{\\textsc{LARGE}}: 770M parameters), the E2E model with Llama 2 substantially outperforms the latter on the Challenge aspect.\n",
      "\n",
      "\n",
      "Path 262: 56.6153080161969\n",
      "step chain-of-thought or end-to-end abstractive summarization\n",
      "our extractive and abstractive summarization annotations\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "our extractive and abstractive summarization annotations\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "we\n",
      "coref\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "its summarization abilities\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "its summarization abilities\n",
      "the popular Llama 2 model\n",
      "coref\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "fine-tune the Llama 2 7B.\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "\n",
      "fine-tune the Llama 2 7B.\n",
      "the Llama 2 model\n",
      "coref\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "not its instruction-tuned variant\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "shared_text\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "performance between Llama 2\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "While it is difficult to compare performance between Llama 2 and T5 due to the massive difference in model sizes (Llama 2: 7B vs. \\text{T5}_{\\textsc{LARGE}}: 770M parameters), the E2E model with Llama 2 substantially outperforms the latter on the Challenge aspect.\n",
      "\n",
      "\n",
      "Path 263: 56.6153080161969\n",
      "step chain-of-thought or end-to-end abstractive summarization\n",
      "our extractive and abstractive summarization annotations\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "our extractive and abstractive summarization annotations\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "we\n",
      "coref\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "its summarization abilities\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "its summarization abilities\n",
      "the popular Llama 2 model\n",
      "coref\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "fine-tune the Llama 2 7B.\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "\n",
      "fine-tune the Llama 2 7B.\n",
      "the Llama 2 model\n",
      "coref\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "not its instruction-tuned variant\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "shared_text\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "performance between Llama 2\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "While it is difficult to compare performance between Llama 2 and T5 due to the massive difference in model sizes (Llama 2: 7B vs. \\text{T5}_{\\textsc{LARGE}}: 770M parameters), the E2E model with Llama 2 substantially outperforms the latter on the Challenge aspect.\n",
      "\n",
      "\n",
      "Path 264: 56.6153080161969\n",
      "step chain-of-thought or end-to-end abstractive summarization\n",
      "our extractive and abstractive summarization annotations\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "our extractive and abstractive summarization annotations\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "we\n",
      "coref\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "its summarization abilities\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "its summarization abilities\n",
      "the popular Llama 2 model\n",
      "coref\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "fine-tune the Llama 2 7B.\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "\n",
      "fine-tune the Llama 2 7B.\n",
      "the Llama 2 model\n",
      "coref\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "not its instruction-tuned variant\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "shared_text\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "performance between Llama 2\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "While it is difficult to compare performance between Llama 2 and T5 due to the massive difference in model sizes (Llama 2: 7B vs. \\text{T5}_{\\textsc{LARGE}}: 770M parameters), the E2E model with Llama 2 substantially outperforms the latter on the Challenge aspect.\n",
      "\n",
      "\n",
      "Path 265: 56.6153080161969\n",
      "step chain-of-thought or end-to-end abstractive summarization\n",
      "our extractive and abstractive summarization annotations\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "our extractive and abstractive summarization annotations\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "we\n",
      "coref\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "its summarization abilities\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "its summarization abilities\n",
      "the popular Llama 2 model\n",
      "coref\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "fine-tune the Llama 2 7B.\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "\n",
      "fine-tune the Llama 2 7B.\n",
      "the Llama 2 model\n",
      "coref\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "not its instruction-tuned variant\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "shared_text\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "performance between Llama 2\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "While it is difficult to compare performance between Llama 2 and T5 due to the massive difference in model sizes (Llama 2: 7B vs. \\text{T5}_{\\textsc{LARGE}}: 770M parameters), the E2E model with Llama 2 substantially outperforms the latter on the Challenge aspect.\n",
      "\n",
      "\n",
      "Path 266: 57.02893078585603\n",
      "Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization,\n",
      "our extractive and abstractive summarization annotations\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "our extractive and abstractive summarization annotations\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "we\n",
      "coref\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "the popular Llama 2 model\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "the Llama 2 model\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "the Llama 2 model\n",
      "We\n",
      "subj_obj\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "We\n",
      "we\n",
      "subj_obj\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "we\n",
      "not its instruction-tuned variant\n",
      "subj_obj\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "not its instruction-tuned variant\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "coref\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "performance between Llama 2\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "While it is difficult to compare performance between Llama 2 and T5 due to the massive difference in model sizes (Llama 2: 7B vs. \\text{T5}_{\\textsc{LARGE}}: 770M parameters), the E2E model with Llama 2 substantially outperforms the latter on the Challenge aspect.\n",
      "\n",
      "\n",
      "Path 267: 57.02893078585603\n",
      "Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization,\n",
      "our extractive and abstractive summarization annotations\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "our extractive and abstractive summarization annotations\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "we\n",
      "coref\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "the popular Llama 2 model\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "the Llama 2 model\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "the Llama 2 model\n",
      "We\n",
      "subj_obj\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "We\n",
      "we\n",
      "subj_obj\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "we\n",
      "not its instruction-tuned variant\n",
      "subj_obj\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "not its instruction-tuned variant\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "coref\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "performance between Llama 2\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "While it is difficult to compare performance between Llama 2 and T5 due to the massive difference in model sizes (Llama 2: 7B vs. \\text{T5}_{\\textsc{LARGE}}: 770M parameters), the E2E model with Llama 2 substantially outperforms the latter on the Challenge aspect.\n",
      "\n",
      "\n",
      "Path 268: 57.02893078585603\n",
      "Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization,\n",
      "our extractive and abstractive summarization annotations\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "our extractive and abstractive summarization annotations\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "we\n",
      "coref\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "the popular Llama 2 model\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "the Llama 2 model\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "the Llama 2 model\n",
      "we\n",
      "subj_obj\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "we\n",
      "We\n",
      "subj_obj\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "We\n",
      "not its instruction-tuned variant\n",
      "subj_obj\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "not its instruction-tuned variant\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "coref\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "performance between Llama 2\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "While it is difficult to compare performance between Llama 2 and T5 due to the massive difference in model sizes (Llama 2: 7B vs. \\text{T5}_{\\textsc{LARGE}}: 770M parameters), the E2E model with Llama 2 substantially outperforms the latter on the Challenge aspect.\n",
      "\n",
      "\n",
      "Path 269: 57.02893078585603\n",
      "Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization,\n",
      "our extractive and abstractive summarization annotations\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "our extractive and abstractive summarization annotations\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "we\n",
      "coref\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "the popular Llama 2 model\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "the Llama 2 model\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "the Llama 2 model\n",
      "we\n",
      "subj_obj\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "we\n",
      "We\n",
      "subj_obj\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "We\n",
      "not its instruction-tuned variant\n",
      "subj_obj\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "not its instruction-tuned variant\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "coref\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "performance between Llama 2\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "While it is difficult to compare performance between Llama 2 and T5 due to the massive difference in model sizes (Llama 2: 7B vs. \\text{T5}_{\\textsc{LARGE}}: 770M parameters), the E2E model with Llama 2 substantially outperforms the latter on the Challenge aspect.\n",
      "\n",
      "\n",
      "Path 270: 57.02893078585603\n",
      "Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization,\n",
      "our extractive and abstractive summarization annotations\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "our extractive and abstractive summarization annotations\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "we\n",
      "coref\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "the popular Llama 2 model\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "the Llama 2 model\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "the Llama 2 model\n",
      "We\n",
      "subj_obj\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "We\n",
      "we\n",
      "subj_obj\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "we\n",
      "not its instruction-tuned variant\n",
      "subj_obj\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "not its instruction-tuned variant\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "coref\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "performance between Llama 2\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "While it is difficult to compare performance between Llama 2 and T5 due to the massive difference in model sizes (Llama 2: 7B vs. \\text{T5}_{\\textsc{LARGE}}: 770M parameters), the E2E model with Llama 2 substantially outperforms the latter on the Challenge aspect.\n",
      "\n",
      "\n",
      "Path 271: 57.02893078585603\n",
      "Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization,\n",
      "our extractive and abstractive summarization annotations\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "our extractive and abstractive summarization annotations\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "we\n",
      "coref\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "the popular Llama 2 model\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "the Llama 2 model\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "the Llama 2 model\n",
      "We\n",
      "subj_obj\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "We\n",
      "we\n",
      "subj_obj\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "we\n",
      "not its instruction-tuned variant\n",
      "subj_obj\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "not its instruction-tuned variant\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "coref\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "performance between Llama 2\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "While it is difficult to compare performance between Llama 2 and T5 due to the massive difference in model sizes (Llama 2: 7B vs. \\text{T5}_{\\textsc{LARGE}}: 770M parameters), the E2E model with Llama 2 substantially outperforms the latter on the Challenge aspect.\n",
      "\n",
      "\n",
      "Path 272: 57.02893078585603\n",
      "Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization,\n",
      "our extractive and abstractive summarization annotations\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "our extractive and abstractive summarization annotations\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "we\n",
      "coref\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "the popular Llama 2 model\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "the Llama 2 model\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "the Llama 2 model\n",
      "we\n",
      "subj_obj\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "we\n",
      "We\n",
      "subj_obj\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "We\n",
      "not its instruction-tuned variant\n",
      "subj_obj\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "not its instruction-tuned variant\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "coref\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "performance between Llama 2\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "While it is difficult to compare performance between Llama 2 and T5 due to the massive difference in model sizes (Llama 2: 7B vs. \\text{T5}_{\\textsc{LARGE}}: 770M parameters), the E2E model with Llama 2 substantially outperforms the latter on the Challenge aspect.\n",
      "\n",
      "\n",
      "Path 273: 57.02893078585603\n",
      "Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization,\n",
      "our extractive and abstractive summarization annotations\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "our extractive and abstractive summarization annotations\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "we\n",
      "coref\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "the popular Llama 2 model\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "the Llama 2 model\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "the Llama 2 model\n",
      "we\n",
      "subj_obj\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "we\n",
      "We\n",
      "subj_obj\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "We\n",
      "not its instruction-tuned variant\n",
      "subj_obj\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "not its instruction-tuned variant\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "coref\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "performance between Llama 2\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "While it is difficult to compare performance between Llama 2 and T5 due to the massive difference in model sizes (Llama 2: 7B vs. \\text{T5}_{\\textsc{LARGE}}: 770M parameters), the E2E model with Llama 2 substantially outperforms the latter on the Challenge aspect.\n",
      "\n",
      "\n",
      "Path 274: 57.13348439430518\n",
      "Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization,\n",
      "our extractive and abstractive summarization annotations\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "our extractive and abstractive summarization annotations\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "we\n",
      "coref\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "the popular Llama 2 model\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "the model\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "\n",
      "the model\n",
      "the model\n",
      "coref\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the model\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "subj_obj\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "A training data sample used for EtA-CoT\n",
      "shared_text\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "A training data sample used for EtA-CoT is shown in Table 5.\n",
      "\n",
      "A training data sample used for EtA-CoT\n",
      "Table 5\n",
      "subj_obj\n",
      "A training data sample used for EtA-CoT is shown in Table 5.\n",
      "\n",
      "Table 5\n",
      "Table 6\n",
      "shared_text\n",
      "A training data sample used for EtA-CoT is shown in Table 5.\n",
      "Table 6 presents ROUGE scores, BERTScores, and extraction performance using our gold extractive labels measured by F1 for EtA-CoT models.\n",
      "\n",
      "\n",
      "Path 275: 57.13348439430518\n",
      "Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization,\n",
      "our extractive and abstractive summarization annotations\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "our extractive and abstractive summarization annotations\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "we\n",
      "coref\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "the popular Llama 2 model\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "the model\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "\n",
      "the model\n",
      "the model\n",
      "coref\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the model\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "subj_obj\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "A training data sample used for EtA-CoT\n",
      "shared_text\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "A training data sample used for EtA-CoT is shown in Table 5.\n",
      "\n",
      "A training data sample used for EtA-CoT\n",
      "Table 5\n",
      "subj_obj\n",
      "A training data sample used for EtA-CoT is shown in Table 5.\n",
      "\n",
      "Table 5\n",
      "Table 6\n",
      "shared_text\n",
      "A training data sample used for EtA-CoT is shown in Table 5.\n",
      "Table 6 presents ROUGE scores, BERTScores, and extraction performance using our gold extractive labels measured by F1 for EtA-CoT models.\n",
      "\n",
      "\n",
      "Path 276: 57.13348439430518\n",
      "Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization,\n",
      "our extractive and abstractive summarization annotations\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "our extractive and abstractive summarization annotations\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "we\n",
      "coref\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "the popular Llama 2 model\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "the model\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "\n",
      "the model\n",
      "the model\n",
      "coref\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the model\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "subj_obj\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "A training data sample used for EtA-CoT\n",
      "shared_text\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "A training data sample used for EtA-CoT is shown in Table 5.\n",
      "\n",
      "A training data sample used for EtA-CoT\n",
      "Table 5\n",
      "subj_obj\n",
      "A training data sample used for EtA-CoT is shown in Table 5.\n",
      "\n",
      "Table 5\n",
      "Table 6\n",
      "shared_text\n",
      "A training data sample used for EtA-CoT is shown in Table 5.\n",
      "Table 6 presents ROUGE scores, BERTScores, and extraction performance using our gold extractive labels measured by F1 for EtA-CoT models.\n",
      "\n",
      "\n",
      "Path 277: 57.13348439430518\n",
      "Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization,\n",
      "our extractive and abstractive summarization annotations\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "our extractive and abstractive summarization annotations\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "we\n",
      "coref\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "the popular Llama 2 model\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "the model\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "\n",
      "the model\n",
      "the model\n",
      "coref\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the model\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "subj_obj\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "A training data sample used for EtA-CoT\n",
      "shared_text\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "A training data sample used for EtA-CoT is shown in Table 5.\n",
      "\n",
      "A training data sample used for EtA-CoT\n",
      "Table 5\n",
      "subj_obj\n",
      "A training data sample used for EtA-CoT is shown in Table 5.\n",
      "\n",
      "Table 5\n",
      "Table 6\n",
      "shared_text\n",
      "A training data sample used for EtA-CoT is shown in Table 5.\n",
      "Table 6 presents ROUGE scores, BERTScores, and extraction performance using our gold extractive labels measured by F1 for EtA-CoT models.\n",
      "\n",
      "\n",
      "Path 278: 57.236431142325294\n",
      "Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization,\n",
      "our extractive and abstractive summarization annotations\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "our extractive and abstractive summarization annotations\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "we\n",
      "coref\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "the popular Llama 2 model\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "fine-tune the Llama 2 7B.\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "\n",
      "fine-tune the Llama 2 7B.\n",
      "the Llama 2 model\n",
      "coref\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "not its instruction-tuned variant\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "shared_text\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "performance between Llama 2\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "While it is difficult to compare performance between Llama 2 and T5 due to the massive difference in model sizes (Llama 2: 7B vs. \\text{T5}_{\\textsc{LARGE}}: 770M parameters), the E2E model with Llama 2 substantially outperforms the latter on the Challenge aspect.\n",
      "\n",
      "\n",
      "Path 279: 57.236431142325294\n",
      "Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization,\n",
      "our extractive and abstractive summarization annotations\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "our extractive and abstractive summarization annotations\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "we\n",
      "coref\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "the popular Llama 2 model\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "fine-tune the Llama 2 7B.\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "\n",
      "fine-tune the Llama 2 7B.\n",
      "the Llama 2 model\n",
      "coref\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "not its instruction-tuned variant\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "shared_text\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "performance between Llama 2\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "While it is difficult to compare performance between Llama 2 and T5 due to the massive difference in model sizes (Llama 2: 7B vs. \\text{T5}_{\\textsc{LARGE}}: 770M parameters), the E2E model with Llama 2 substantially outperforms the latter on the Challenge aspect.\n",
      "\n",
      "\n",
      "Path 280: 57.236431142325294\n",
      "Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization,\n",
      "our extractive and abstractive summarization annotations\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "our extractive and abstractive summarization annotations\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "we\n",
      "coref\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "the popular Llama 2 model\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "fine-tune the Llama 2 7B.\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "\n",
      "fine-tune the Llama 2 7B.\n",
      "the Llama 2 model\n",
      "coref\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "not its instruction-tuned variant\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "shared_text\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "performance between Llama 2\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "While it is difficult to compare performance between Llama 2 and T5 due to the massive difference in model sizes (Llama 2: 7B vs. \\text{T5}_{\\textsc{LARGE}}: 770M parameters), the E2E model with Llama 2 substantially outperforms the latter on the Challenge aspect.\n",
      "\n",
      "\n",
      "Path 281: 57.236431142325294\n",
      "Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization,\n",
      "our extractive and abstractive summarization annotations\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "our extractive and abstractive summarization annotations\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "we\n",
      "coref\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "the popular Llama 2 model\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "fine-tune the Llama 2 7B.\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "\n",
      "fine-tune the Llama 2 7B.\n",
      "the Llama 2 model\n",
      "coref\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "not its instruction-tuned variant\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "shared_text\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "performance between Llama 2\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "While it is difficult to compare performance between Llama 2 and T5 due to the massive difference in model sizes (Llama 2: 7B vs. \\text{T5}_{\\textsc{LARGE}}: 770M parameters), the E2E model with Llama 2 substantially outperforms the latter on the Challenge aspect.\n",
      "\n",
      "\n",
      "Path 282: 57.236431142325294\n",
      "Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization,\n",
      "our extractive and abstractive summarization annotations\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "our extractive and abstractive summarization annotations\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "we\n",
      "coref\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "its summarization abilities\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "its summarization abilities\n",
      "the popular Llama 2 model\n",
      "coref\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "fine-tune the Llama 2 7B.\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "\n",
      "fine-tune the Llama 2 7B.\n",
      "the Llama 2 model\n",
      "coref\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "not its instruction-tuned variant\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "shared_text\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "performance between Llama 2\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "While it is difficult to compare performance between Llama 2 and T5 due to the massive difference in model sizes (Llama 2: 7B vs. \\text{T5}_{\\textsc{LARGE}}: 770M parameters), the E2E model with Llama 2 substantially outperforms the latter on the Challenge aspect.\n",
      "\n",
      "\n",
      "Path 283: 57.236431142325294\n",
      "Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization,\n",
      "our extractive and abstractive summarization annotations\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "our extractive and abstractive summarization annotations\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "we\n",
      "coref\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "its summarization abilities\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "its summarization abilities\n",
      "the popular Llama 2 model\n",
      "coref\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "fine-tune the Llama 2 7B.\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "\n",
      "fine-tune the Llama 2 7B.\n",
      "the Llama 2 model\n",
      "coref\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "not its instruction-tuned variant\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "shared_text\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "performance between Llama 2\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "While it is difficult to compare performance between Llama 2 and T5 due to the massive difference in model sizes (Llama 2: 7B vs. \\text{T5}_{\\textsc{LARGE}}: 770M parameters), the E2E model with Llama 2 substantially outperforms the latter on the Challenge aspect.\n",
      "\n",
      "\n",
      "Path 284: 57.236431142325294\n",
      "Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization,\n",
      "our extractive and abstractive summarization annotations\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "our extractive and abstractive summarization annotations\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "we\n",
      "coref\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "its summarization abilities\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "its summarization abilities\n",
      "the popular Llama 2 model\n",
      "coref\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "fine-tune the Llama 2 7B.\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "\n",
      "fine-tune the Llama 2 7B.\n",
      "the Llama 2 model\n",
      "coref\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "not its instruction-tuned variant\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "shared_text\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "performance between Llama 2\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "While it is difficult to compare performance between Llama 2 and T5 due to the massive difference in model sizes (Llama 2: 7B vs. \\text{T5}_{\\textsc{LARGE}}: 770M parameters), the E2E model with Llama 2 substantially outperforms the latter on the Challenge aspect.\n",
      "\n",
      "\n",
      "Path 285: 57.236431142325294\n",
      "Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization,\n",
      "our extractive and abstractive summarization annotations\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "our extractive and abstractive summarization annotations\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "we\n",
      "coref\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "its summarization abilities\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "its summarization abilities\n",
      "the popular Llama 2 model\n",
      "coref\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "fine-tune the Llama 2 7B.\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "\n",
      "fine-tune the Llama 2 7B.\n",
      "the Llama 2 model\n",
      "coref\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "not its instruction-tuned variant\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "shared_text\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "performance between Llama 2\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "While it is difficult to compare performance between Llama 2 and T5 due to the massive difference in model sizes (Llama 2: 7B vs. \\text{T5}_{\\textsc{LARGE}}: 770M parameters), the E2E model with Llama 2 substantially outperforms the latter on the Challenge aspect.\n",
      "\n",
      "\n",
      "Path 286: 57.236431142325294\n",
      "Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization,\n",
      "our extractive and abstractive summarization annotations\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "our extractive and abstractive summarization annotations\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "we\n",
      "coref\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "the popular Llama 2 model\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "fine-tune the Llama 2 7B.\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "\n",
      "fine-tune the Llama 2 7B.\n",
      "the Llama 2 model\n",
      "coref\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "not its instruction-tuned variant\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "shared_text\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "performance between Llama 2\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "While it is difficult to compare performance between Llama 2 and T5 due to the massive difference in model sizes (Llama 2: 7B vs. \\text{T5}_{\\textsc{LARGE}}: 770M parameters), the E2E model with Llama 2 substantially outperforms the latter on the Challenge aspect.\n",
      "\n",
      "\n",
      "Path 287: 57.236431142325294\n",
      "Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization,\n",
      "our extractive and abstractive summarization annotations\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "our extractive and abstractive summarization annotations\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "we\n",
      "coref\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "the popular Llama 2 model\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "fine-tune the Llama 2 7B.\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "\n",
      "fine-tune the Llama 2 7B.\n",
      "the Llama 2 model\n",
      "coref\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "not its instruction-tuned variant\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "shared_text\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "performance between Llama 2\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "While it is difficult to compare performance between Llama 2 and T5 due to the massive difference in model sizes (Llama 2: 7B vs. \\text{T5}_{\\textsc{LARGE}}: 770M parameters), the E2E model with Llama 2 substantially outperforms the latter on the Challenge aspect.\n",
      "\n",
      "\n",
      "Path 288: 57.236431142325294\n",
      "Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization,\n",
      "our extractive and abstractive summarization annotations\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "our extractive and abstractive summarization annotations\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "we\n",
      "coref\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "the popular Llama 2 model\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "fine-tune the Llama 2 7B.\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "\n",
      "fine-tune the Llama 2 7B.\n",
      "the Llama 2 model\n",
      "coref\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "not its instruction-tuned variant\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "shared_text\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "performance between Llama 2\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "While it is difficult to compare performance between Llama 2 and T5 due to the massive difference in model sizes (Llama 2: 7B vs. \\text{T5}_{\\textsc{LARGE}}: 770M parameters), the E2E model with Llama 2 substantially outperforms the latter on the Challenge aspect.\n",
      "\n",
      "\n",
      "Path 289: 57.236431142325294\n",
      "Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization,\n",
      "our extractive and abstractive summarization annotations\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "our extractive and abstractive summarization annotations\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "we\n",
      "coref\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "the popular Llama 2 model\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "fine-tune the Llama 2 7B.\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "\n",
      "fine-tune the Llama 2 7B.\n",
      "the Llama 2 model\n",
      "coref\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "not its instruction-tuned variant\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "shared_text\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "performance between Llama 2\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "While it is difficult to compare performance between Llama 2 and T5 due to the massive difference in model sizes (Llama 2: 7B vs. \\text{T5}_{\\textsc{LARGE}}: 770M parameters), the E2E model with Llama 2 substantially outperforms the latter on the Challenge aspect.\n",
      "\n",
      "\n",
      "Path 290: 57.236431142325294\n",
      "Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization,\n",
      "our extractive and abstractive summarization annotations\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "our extractive and abstractive summarization annotations\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "we\n",
      "coref\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "its summarization abilities\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "its summarization abilities\n",
      "the popular Llama 2 model\n",
      "coref\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "fine-tune the Llama 2 7B.\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "\n",
      "fine-tune the Llama 2 7B.\n",
      "the Llama 2 model\n",
      "coref\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "not its instruction-tuned variant\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "shared_text\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "performance between Llama 2\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "While it is difficult to compare performance between Llama 2 and T5 due to the massive difference in model sizes (Llama 2: 7B vs. \\text{T5}_{\\textsc{LARGE}}: 770M parameters), the E2E model with Llama 2 substantially outperforms the latter on the Challenge aspect.\n",
      "\n",
      "\n",
      "Path 291: 57.236431142325294\n",
      "Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization,\n",
      "our extractive and abstractive summarization annotations\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "our extractive and abstractive summarization annotations\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "we\n",
      "coref\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "its summarization abilities\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "its summarization abilities\n",
      "the popular Llama 2 model\n",
      "coref\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "fine-tune the Llama 2 7B.\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "\n",
      "fine-tune the Llama 2 7B.\n",
      "the Llama 2 model\n",
      "coref\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "not its instruction-tuned variant\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "shared_text\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "performance between Llama 2\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "While it is difficult to compare performance between Llama 2 and T5 due to the massive difference in model sizes (Llama 2: 7B vs. \\text{T5}_{\\textsc{LARGE}}: 770M parameters), the E2E model with Llama 2 substantially outperforms the latter on the Challenge aspect.\n",
      "\n",
      "\n",
      "Path 292: 57.236431142325294\n",
      "Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization,\n",
      "our extractive and abstractive summarization annotations\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "our extractive and abstractive summarization annotations\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "we\n",
      "coref\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "its summarization abilities\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "its summarization abilities\n",
      "the popular Llama 2 model\n",
      "coref\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "fine-tune the Llama 2 7B.\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "\n",
      "fine-tune the Llama 2 7B.\n",
      "the Llama 2 model\n",
      "coref\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "not its instruction-tuned variant\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "shared_text\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "performance between Llama 2\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "While it is difficult to compare performance between Llama 2 and T5 due to the massive difference in model sizes (Llama 2: 7B vs. \\text{T5}_{\\textsc{LARGE}}: 770M parameters), the E2E model with Llama 2 substantially outperforms the latter on the Challenge aspect.\n",
      "\n",
      "\n",
      "Path 293: 57.236431142325294\n",
      "Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization,\n",
      "our extractive and abstractive summarization annotations\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "our extractive and abstractive summarization annotations\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "we\n",
      "coref\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "its summarization abilities\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "its summarization abilities\n",
      "the popular Llama 2 model\n",
      "coref\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "fine-tune the Llama 2 7B.\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "\n",
      "fine-tune the Llama 2 7B.\n",
      "the Llama 2 model\n",
      "coref\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "not its instruction-tuned variant\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "shared_text\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "performance between Llama 2\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "While it is difficult to compare performance between Llama 2 and T5 due to the massive difference in model sizes (Llama 2: 7B vs. \\text{T5}_{\\textsc{LARGE}}: 770M parameters), the E2E model with Llama 2 substantially outperforms the latter on the Challenge aspect.\n",
      "\n",
      "\n",
      "Path 294: 57.47872529532391\n",
      "step chain-of-thought or end-to-end abstractive summarization\n",
      "our extractive and abstractive summarization annotations\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "our extractive and abstractive summarization annotations\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "we\n",
      "coref\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "the popular Llama 2 model\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "the Llama 2 model\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "the Llama 2 model\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "shared_text\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "performance between Llama 2\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "While it is difficult to compare performance between Llama 2 and T5 due to the massive difference in model sizes (Llama 2: 7B vs. \\text{T5}_{\\textsc{LARGE}}: 770M parameters), the E2E model with Llama 2 substantially outperforms the latter on the Challenge aspect.\n",
      "\n",
      "\n",
      "Path 295: 57.47872529532391\n",
      "step chain-of-thought or end-to-end abstractive summarization\n",
      "our extractive and abstractive summarization annotations\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "our extractive and abstractive summarization annotations\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "we\n",
      "coref\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "its summarization abilities\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "its summarization abilities\n",
      "the popular Llama 2 model\n",
      "coref\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "the Llama 2 model\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "the Llama 2 model\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "shared_text\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "performance between Llama 2\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "While it is difficult to compare performance between Llama 2 and T5 due to the massive difference in model sizes (Llama 2: 7B vs. \\text{T5}_{\\textsc{LARGE}}: 770M parameters), the E2E model with Llama 2 substantially outperforms the latter on the Challenge aspect.\n",
      "\n",
      "\n",
      "Path 296: 57.47872529532391\n",
      "step chain-of-thought or end-to-end abstractive summarization\n",
      "our extractive and abstractive summarization annotations\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "our extractive and abstractive summarization annotations\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "we\n",
      "coref\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "the popular Llama 2 model\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "the Llama 2 model\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "the Llama 2 model\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "shared_text\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "performance between Llama 2\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "While it is difficult to compare performance between Llama 2 and T5 due to the massive difference in model sizes (Llama 2: 7B vs. \\text{T5}_{\\textsc{LARGE}}: 770M parameters), the E2E model with Llama 2 substantially outperforms the latter on the Challenge aspect.\n",
      "\n",
      "\n",
      "Path 297: 57.47872529532391\n",
      "step chain-of-thought or end-to-end abstractive summarization\n",
      "our extractive and abstractive summarization annotations\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "our extractive and abstractive summarization annotations\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "we\n",
      "coref\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "its summarization abilities\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "its summarization abilities\n",
      "the popular Llama 2 model\n",
      "coref\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "the Llama 2 model\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "the Llama 2 model\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "shared_text\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "performance between Llama 2\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "While it is difficult to compare performance between Llama 2 and T5 due to the massive difference in model sizes (Llama 2: 7B vs. \\text{T5}_{\\textsc{LARGE}}: 770M parameters), the E2E model with Llama 2 substantially outperforms the latter on the Challenge aspect.\n",
      "\n",
      "\n",
      "Path 298: 57.822352870528384\n",
      "step chain-of-thought or end-to-end abstractive summarization\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "the model\n",
      "subj_obj\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the model\n",
      "the model\n",
      "coref\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "\n",
      "the model\n",
      "the popular Llama 2 model\n",
      "shared_text\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "fine-tune the Llama 2 7B.\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "\n",
      "fine-tune the Llama 2 7B.\n",
      "the Llama 2 model\n",
      "coref\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "the Llama 2 model\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "shared_text\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "performance between Llama 2\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "While it is difficult to compare performance between Llama 2 and T5 due to the massive difference in model sizes (Llama 2: 7B vs. \\text{T5}_{\\textsc{LARGE}}: 770M parameters), the E2E model with Llama 2 substantially outperforms the latter on the Challenge aspect.\n",
      "\n",
      "\n",
      "Path 299: 57.822352870528384\n",
      "step chain-of-thought or end-to-end abstractive summarization\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "the model\n",
      "subj_obj\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the model\n",
      "the model\n",
      "coref\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "\n",
      "the model\n",
      "the popular Llama 2 model\n",
      "shared_text\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "fine-tune the Llama 2 7B.\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "\n",
      "fine-tune the Llama 2 7B.\n",
      "the Llama 2 model\n",
      "coref\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "the Llama 2 model\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "shared_text\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "performance between Llama 2\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "While it is difficult to compare performance between Llama 2 and T5 due to the massive difference in model sizes (Llama 2: 7B vs. \\text{T5}_{\\textsc{LARGE}}: 770M parameters), the E2E model with Llama 2 substantially outperforms the latter on the Challenge aspect.\n",
      "\n",
      "\n",
      "Path 300: 57.822352870528384\n",
      "step chain-of-thought or end-to-end abstractive summarization\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "the model\n",
      "subj_obj\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the model\n",
      "the model\n",
      "coref\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "\n",
      "the model\n",
      "the popular Llama 2 model\n",
      "shared_text\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "fine-tune the Llama 2 7B.\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "\n",
      "fine-tune the Llama 2 7B.\n",
      "the Llama 2 model\n",
      "coref\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "the Llama 2 model\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "shared_text\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "performance between Llama 2\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "While it is difficult to compare performance between Llama 2 and T5 due to the massive difference in model sizes (Llama 2: 7B vs. \\text{T5}_{\\textsc{LARGE}}: 770M parameters), the E2E model with Llama 2 substantially outperforms the latter on the Challenge aspect.\n",
      "\n",
      "\n",
      "Path 301: 57.822352870528384\n",
      "step chain-of-thought or end-to-end abstractive summarization\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "the model\n",
      "subj_obj\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the model\n",
      "the model\n",
      "coref\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "\n",
      "the model\n",
      "the popular Llama 2 model\n",
      "shared_text\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "fine-tune the Llama 2 7B.\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "\n",
      "fine-tune the Llama 2 7B.\n",
      "the Llama 2 model\n",
      "coref\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "the Llama 2 model\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "shared_text\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "performance between Llama 2\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "While it is difficult to compare performance between Llama 2 and T5 due to the massive difference in model sizes (Llama 2: 7B vs. \\text{T5}_{\\textsc{LARGE}}: 770M parameters), the E2E model with Llama 2 substantially outperforms the latter on the Challenge aspect.\n",
      "\n",
      "\n",
      "Path 302: 58.09984842145231\n",
      "Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization,\n",
      "our extractive and abstractive summarization annotations\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "our extractive and abstractive summarization annotations\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "we\n",
      "coref\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "the popular Llama 2 model\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "the Llama 2 model\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "the Llama 2 model\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "shared_text\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "performance between Llama 2\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "While it is difficult to compare performance between Llama 2 and T5 due to the massive difference in model sizes (Llama 2: 7B vs. \\text{T5}_{\\textsc{LARGE}}: 770M parameters), the E2E model with Llama 2 substantially outperforms the latter on the Challenge aspect.\n",
      "\n",
      "\n",
      "Path 303: 58.09984842145231\n",
      "Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization,\n",
      "our extractive and abstractive summarization annotations\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "our extractive and abstractive summarization annotations\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "we\n",
      "coref\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "its summarization abilities\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "its summarization abilities\n",
      "the popular Llama 2 model\n",
      "coref\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "the Llama 2 model\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "the Llama 2 model\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "shared_text\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "performance between Llama 2\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "While it is difficult to compare performance between Llama 2 and T5 due to the massive difference in model sizes (Llama 2: 7B vs. \\text{T5}_{\\textsc{LARGE}}: 770M parameters), the E2E model with Llama 2 substantially outperforms the latter on the Challenge aspect.\n",
      "\n",
      "\n",
      "Path 304: 58.09984842145231\n",
      "Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization,\n",
      "our extractive and abstractive summarization annotations\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "our extractive and abstractive summarization annotations\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "we\n",
      "coref\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "the popular Llama 2 model\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "the Llama 2 model\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "the Llama 2 model\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "shared_text\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "performance between Llama 2\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "While it is difficult to compare performance between Llama 2 and T5 due to the massive difference in model sizes (Llama 2: 7B vs. \\text{T5}_{\\textsc{LARGE}}: 770M parameters), the E2E model with Llama 2 substantially outperforms the latter on the Challenge aspect.\n",
      "\n",
      "\n",
      "Path 305: 58.09984842145231\n",
      "Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization,\n",
      "our extractive and abstractive summarization annotations\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "our extractive and abstractive summarization annotations\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "we\n",
      "coref\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "its summarization abilities\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "its summarization abilities\n",
      "the popular Llama 2 model\n",
      "coref\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "the Llama 2 model\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "the Llama 2 model\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "shared_text\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "performance between Llama 2\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "While it is difficult to compare performance between Llama 2 and T5 due to the massive difference in model sizes (Llama 2: 7B vs. \\text{T5}_{\\textsc{LARGE}}: 770M parameters), the E2E model with Llama 2 substantially outperforms the latter on the Challenge aspect.\n",
      "\n",
      "\n",
      "Path 306: 58.28789213442635\n",
      "step chain-of-thought or end-to-end abstractive summarization\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "the model\n",
      "subj_obj\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the model\n",
      "the model\n",
      "coref\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "\n",
      "its summarization abilities\n",
      "we\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "the popular Llama 2 model\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "fine-tune the Llama 2 7B.\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "\n",
      "fine-tune the Llama 2 7B.\n",
      "the Llama 2 model\n",
      "coref\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "the Llama 2 model\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "shared_text\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "performance between Llama 2\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "While it is difficult to compare performance between Llama 2 and T5 due to the massive difference in model sizes (Llama 2: 7B vs. \\text{T5}_{\\textsc{LARGE}}: 770M parameters), the E2E model with Llama 2 substantially outperforms the latter on the Challenge aspect.\n",
      "\n",
      "\n",
      "Path 307: 58.28789213442635\n",
      "step chain-of-thought or end-to-end abstractive summarization\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "the model\n",
      "subj_obj\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the model\n",
      "the model\n",
      "coref\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "\n",
      "its summarization abilities\n",
      "we\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "the popular Llama 2 model\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "fine-tune the Llama 2 7B.\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "\n",
      "fine-tune the Llama 2 7B.\n",
      "the Llama 2 model\n",
      "coref\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "the Llama 2 model\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "shared_text\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "performance between Llama 2\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "While it is difficult to compare performance between Llama 2 and T5 due to the massive difference in model sizes (Llama 2: 7B vs. \\text{T5}_{\\textsc{LARGE}}: 770M parameters), the E2E model with Llama 2 substantially outperforms the latter on the Challenge aspect.\n",
      "\n",
      "\n",
      "Path 308: 58.28789213442635\n",
      "step chain-of-thought or end-to-end abstractive summarization\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "the model\n",
      "subj_obj\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the model\n",
      "the model\n",
      "coref\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "\n",
      "its summarization abilities\n",
      "we\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "the popular Llama 2 model\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "fine-tune the Llama 2 7B.\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "\n",
      "fine-tune the Llama 2 7B.\n",
      "the Llama 2 model\n",
      "coref\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "the Llama 2 model\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "shared_text\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "performance between Llama 2\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "While it is difficult to compare performance between Llama 2 and T5 due to the massive difference in model sizes (Llama 2: 7B vs. \\text{T5}_{\\textsc{LARGE}}: 770M parameters), the E2E model with Llama 2 substantially outperforms the latter on the Challenge aspect.\n",
      "\n",
      "\n",
      "Path 309: 58.28789213442635\n",
      "step chain-of-thought or end-to-end abstractive summarization\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "the model\n",
      "subj_obj\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the model\n",
      "the model\n",
      "coref\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "\n",
      "its summarization abilities\n",
      "we\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "the popular Llama 2 model\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "fine-tune the Llama 2 7B.\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "\n",
      "fine-tune the Llama 2 7B.\n",
      "the Llama 2 model\n",
      "coref\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "the Llama 2 model\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "shared_text\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "performance between Llama 2\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "While it is difficult to compare performance between Llama 2 and T5 due to the massive difference in model sizes (Llama 2: 7B vs. \\text{T5}_{\\textsc{LARGE}}: 770M parameters), the E2E model with Llama 2 substantially outperforms the latter on the Challenge aspect.\n",
      "\n",
      "\n",
      "Path 310: 58.61065709338294\n",
      "step chain-of-thought or end-to-end abstractive summarization\n",
      "our extractive and abstractive summarization annotations\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "our extractive and abstractive summarization annotations\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "we\n",
      "coref\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "the popular Llama 2 model\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "its summarization abilities\n",
      "coref\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the model\n",
      "the model\n",
      "shared_text\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the model\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "subj_obj\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "A training data sample used for EtA-CoT\n",
      "shared_text\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "A training data sample used for EtA-CoT is shown in Table 5.\n",
      "\n",
      "A training data sample used for EtA-CoT\n",
      "EtA-CoT models\n",
      "shared_text\n",
      "A training data sample used for EtA-CoT is shown in Table 5.\n",
      "Table 6 presents ROUGE scores, BERTScores, and extraction performance using our gold extractive labels measured by F1 for EtA-CoT models.\n",
      "\n",
      "\n",
      "Path 311: 58.61065709338294\n",
      "step chain-of-thought or end-to-end abstractive summarization\n",
      "our extractive and abstractive summarization annotations\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "our extractive and abstractive summarization annotations\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "we\n",
      "coref\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "the popular Llama 2 model\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "its summarization abilities\n",
      "coref\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the model\n",
      "the model\n",
      "shared_text\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the model\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "subj_obj\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "A training data sample used for EtA-CoT\n",
      "shared_text\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "A training data sample used for EtA-CoT is shown in Table 5.\n",
      "\n",
      "A training data sample used for EtA-CoT\n",
      "EtA-CoT models\n",
      "shared_text\n",
      "A training data sample used for EtA-CoT is shown in Table 5.\n",
      "Table 6 presents ROUGE scores, BERTScores, and extraction performance using our gold extractive labels measured by F1 for EtA-CoT models.\n",
      "\n",
      "\n",
      "Path 312: 58.61065709338294\n",
      "step chain-of-thought or end-to-end abstractive summarization\n",
      "our extractive and abstractive summarization annotations\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "our extractive and abstractive summarization annotations\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "we\n",
      "coref\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "its summarization abilities\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "its summarization abilities\n",
      "the model\n",
      "coref\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "\n",
      "the model\n",
      "the model\n",
      "shared_text\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the model\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "subj_obj\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "A training data sample used for EtA-CoT\n",
      "shared_text\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "A training data sample used for EtA-CoT is shown in Table 5.\n",
      "\n",
      "A training data sample used for EtA-CoT\n",
      "EtA-CoT models\n",
      "shared_text\n",
      "A training data sample used for EtA-CoT is shown in Table 5.\n",
      "Table 6 presents ROUGE scores, BERTScores, and extraction performance using our gold extractive labels measured by F1 for EtA-CoT models.\n",
      "\n",
      "\n",
      "Path 313: 58.61065709338294\n",
      "step chain-of-thought or end-to-end abstractive summarization\n",
      "our extractive and abstractive summarization annotations\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "our extractive and abstractive summarization annotations\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "we\n",
      "coref\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "its summarization abilities\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "its summarization abilities\n",
      "the model\n",
      "coref\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "\n",
      "the model\n",
      "the model\n",
      "shared_text\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the model\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "subj_obj\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "A training data sample used for EtA-CoT\n",
      "shared_text\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "A training data sample used for EtA-CoT is shown in Table 5.\n",
      "\n",
      "A training data sample used for EtA-CoT\n",
      "EtA-CoT models\n",
      "shared_text\n",
      "A training data sample used for EtA-CoT is shown in Table 5.\n",
      "Table 6 presents ROUGE scores, BERTScores, and extraction performance using our gold extractive labels measured by F1 for EtA-CoT models.\n",
      "\n",
      "\n",
      "Path 314: 58.61065709338294\n",
      "step chain-of-thought or end-to-end abstractive summarization\n",
      "our extractive and abstractive summarization annotations\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "our extractive and abstractive summarization annotations\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "we\n",
      "coref\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "the popular Llama 2 model\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "its summarization abilities\n",
      "coref\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the model\n",
      "the model\n",
      "shared_text\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the model\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "subj_obj\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "A training data sample used for EtA-CoT\n",
      "shared_text\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "A training data sample used for EtA-CoT is shown in Table 5.\n",
      "\n",
      "A training data sample used for EtA-CoT\n",
      "EtA-CoT models\n",
      "shared_text\n",
      "A training data sample used for EtA-CoT is shown in Table 5.\n",
      "Table 6 presents ROUGE scores, BERTScores, and extraction performance using our gold extractive labels measured by F1 for EtA-CoT models.\n",
      "\n",
      "\n",
      "Path 315: 58.61065709338294\n",
      "step chain-of-thought or end-to-end abstractive summarization\n",
      "our extractive and abstractive summarization annotations\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "our extractive and abstractive summarization annotations\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "we\n",
      "coref\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "the popular Llama 2 model\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "its summarization abilities\n",
      "coref\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the model\n",
      "the model\n",
      "shared_text\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the model\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "subj_obj\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "A training data sample used for EtA-CoT\n",
      "shared_text\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "A training data sample used for EtA-CoT is shown in Table 5.\n",
      "\n",
      "A training data sample used for EtA-CoT\n",
      "EtA-CoT models\n",
      "shared_text\n",
      "A training data sample used for EtA-CoT is shown in Table 5.\n",
      "Table 6 presents ROUGE scores, BERTScores, and extraction performance using our gold extractive labels measured by F1 for EtA-CoT models.\n",
      "\n",
      "\n",
      "Path 316: 58.61065709338294\n",
      "step chain-of-thought or end-to-end abstractive summarization\n",
      "our extractive and abstractive summarization annotations\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "our extractive and abstractive summarization annotations\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "we\n",
      "coref\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "its summarization abilities\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "its summarization abilities\n",
      "the model\n",
      "coref\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "\n",
      "the model\n",
      "the model\n",
      "shared_text\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the model\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "subj_obj\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "A training data sample used for EtA-CoT\n",
      "shared_text\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "A training data sample used for EtA-CoT is shown in Table 5.\n",
      "\n",
      "A training data sample used for EtA-CoT\n",
      "EtA-CoT models\n",
      "shared_text\n",
      "A training data sample used for EtA-CoT is shown in Table 5.\n",
      "Table 6 presents ROUGE scores, BERTScores, and extraction performance using our gold extractive labels measured by F1 for EtA-CoT models.\n",
      "\n",
      "\n",
      "Path 317: 58.61065709338294\n",
      "step chain-of-thought or end-to-end abstractive summarization\n",
      "our extractive and abstractive summarization annotations\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "our extractive and abstractive summarization annotations\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "we\n",
      "coref\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "its summarization abilities\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "its summarization abilities\n",
      "the model\n",
      "coref\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "\n",
      "the model\n",
      "the model\n",
      "shared_text\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the model\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "subj_obj\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "A training data sample used for EtA-CoT\n",
      "shared_text\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "A training data sample used for EtA-CoT is shown in Table 5.\n",
      "\n",
      "A training data sample used for EtA-CoT\n",
      "EtA-CoT models\n",
      "shared_text\n",
      "A training data sample used for EtA-CoT is shown in Table 5.\n",
      "Table 6 presents ROUGE scores, BERTScores, and extraction performance using our gold extractive labels measured by F1 for EtA-CoT models.\n",
      "\n",
      "\n",
      "Path 318: 58.6153080161969\n",
      "step chain-of-thought or end-to-end abstractive summarization\n",
      "our extractive and abstractive summarization annotations\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "our extractive and abstractive summarization annotations\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "we\n",
      "coref\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "the popular Llama 2 model\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "fine-tune the Llama 2 7B.\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "\n",
      "fine-tune the Llama 2 7B.\n",
      "We\n",
      "subj_obj\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "\n",
      "We\n",
      "We\n",
      "coref\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "We\n",
      "not its instruction-tuned variant\n",
      "subj_obj\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "not its instruction-tuned variant\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "coref\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "performance between Llama 2\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "While it is difficult to compare performance between Llama 2 and T5 due to the massive difference in model sizes (Llama 2: 7B vs. \\text{T5}_{\\textsc{LARGE}}: 770M parameters), the E2E model with Llama 2 substantially outperforms the latter on the Challenge aspect.\n",
      "\n",
      "\n",
      "Path 319: 58.6153080161969\n",
      "step chain-of-thought or end-to-end abstractive summarization\n",
      "our extractive and abstractive summarization annotations\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "our extractive and abstractive summarization annotations\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "we\n",
      "coref\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "the popular Llama 2 model\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "fine-tune the Llama 2 7B.\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "\n",
      "fine-tune the Llama 2 7B.\n",
      "We\n",
      "subj_obj\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "\n",
      "We\n",
      "We\n",
      "coref\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "We\n",
      "not its instruction-tuned variant\n",
      "subj_obj\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "not its instruction-tuned variant\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "coref\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "performance between Llama 2\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "While it is difficult to compare performance between Llama 2 and T5 due to the massive difference in model sizes (Llama 2: 7B vs. \\text{T5}_{\\textsc{LARGE}}: 770M parameters), the E2E model with Llama 2 substantially outperforms the latter on the Challenge aspect.\n",
      "\n",
      "\n",
      "Path 320: 58.6153080161969\n",
      "step chain-of-thought or end-to-end abstractive summarization\n",
      "our extractive and abstractive summarization annotations\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "our extractive and abstractive summarization annotations\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "we\n",
      "coref\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "the popular Llama 2 model\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "fine-tune the Llama 2 7B.\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "\n",
      "fine-tune the Llama 2 7B.\n",
      "the Llama 2 model\n",
      "coref\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "the Llama 2 model\n",
      "We\n",
      "subj_obj\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "We\n",
      "not its instruction-tuned variant\n",
      "subj_obj\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "not its instruction-tuned variant\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "coref\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "performance between Llama 2\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "While it is difficult to compare performance between Llama 2 and T5 due to the massive difference in model sizes (Llama 2: 7B vs. \\text{T5}_{\\textsc{LARGE}}: 770M parameters), the E2E model with Llama 2 substantially outperforms the latter on the Challenge aspect.\n",
      "\n",
      "\n",
      "Path 321: 58.6153080161969\n",
      "step chain-of-thought or end-to-end abstractive summarization\n",
      "our extractive and abstractive summarization annotations\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "our extractive and abstractive summarization annotations\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "we\n",
      "coref\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "the popular Llama 2 model\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "fine-tune the Llama 2 7B.\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "\n",
      "fine-tune the Llama 2 7B.\n",
      "the Llama 2 model\n",
      "coref\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "the Llama 2 model\n",
      "We\n",
      "subj_obj\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "We\n",
      "not its instruction-tuned variant\n",
      "subj_obj\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "not its instruction-tuned variant\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "coref\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "performance between Llama 2\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "While it is difficult to compare performance between Llama 2 and T5 due to the massive difference in model sizes (Llama 2: 7B vs. \\text{T5}_{\\textsc{LARGE}}: 770M parameters), the E2E model with Llama 2 substantially outperforms the latter on the Challenge aspect.\n",
      "\n",
      "\n",
      "Path 322: 58.6153080161969\n",
      "step chain-of-thought or end-to-end abstractive summarization\n",
      "our extractive and abstractive summarization annotations\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "our extractive and abstractive summarization annotations\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "we\n",
      "coref\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "the popular Llama 2 model\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "fine-tune the Llama 2 7B.\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "\n",
      "fine-tune the Llama 2 7B.\n",
      "the Llama 2 model\n",
      "coref\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "the Llama 2 model\n",
      "we\n",
      "subj_obj\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "we\n",
      "not its instruction-tuned variant\n",
      "subj_obj\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "not its instruction-tuned variant\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "coref\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "performance between Llama 2\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "While it is difficult to compare performance between Llama 2 and T5 due to the massive difference in model sizes (Llama 2: 7B vs. \\text{T5}_{\\textsc{LARGE}}: 770M parameters), the E2E model with Llama 2 substantially outperforms the latter on the Challenge aspect.\n",
      "\n",
      "\n",
      "Path 323: 58.6153080161969\n",
      "step chain-of-thought or end-to-end abstractive summarization\n",
      "our extractive and abstractive summarization annotations\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "our extractive and abstractive summarization annotations\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "we\n",
      "coref\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "the popular Llama 2 model\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "fine-tune the Llama 2 7B.\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "\n",
      "fine-tune the Llama 2 7B.\n",
      "the Llama 2 model\n",
      "coref\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "the Llama 2 model\n",
      "we\n",
      "subj_obj\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "we\n",
      "not its instruction-tuned variant\n",
      "subj_obj\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "not its instruction-tuned variant\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "coref\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "performance between Llama 2\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "While it is difficult to compare performance between Llama 2 and T5 due to the massive difference in model sizes (Llama 2: 7B vs. \\text{T5}_{\\textsc{LARGE}}: 770M parameters), the E2E model with Llama 2 substantially outperforms the latter on the Challenge aspect.\n",
      "\n",
      "\n",
      "Path 324: 58.6153080161969\n",
      "step chain-of-thought or end-to-end abstractive summarization\n",
      "our extractive and abstractive summarization annotations\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "our extractive and abstractive summarization annotations\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "we\n",
      "coref\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "the popular Llama 2 model\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "fine-tune the Llama 2 7B.\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "\n",
      "fine-tune the Llama 2 7B.\n",
      "the Llama 2 model\n",
      "coref\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "the Llama 2 model\n",
      "We\n",
      "subj_obj\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "We\n",
      "not its instruction-tuned variant\n",
      "subj_obj\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "not its instruction-tuned variant\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "coref\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "performance between Llama 2\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "While it is difficult to compare performance between Llama 2 and T5 due to the massive difference in model sizes (Llama 2: 7B vs. \\text{T5}_{\\textsc{LARGE}}: 770M parameters), the E2E model with Llama 2 substantially outperforms the latter on the Challenge aspect.\n",
      "\n",
      "\n",
      "Path 325: 58.6153080161969\n",
      "step chain-of-thought or end-to-end abstractive summarization\n",
      "our extractive and abstractive summarization annotations\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "our extractive and abstractive summarization annotations\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "we\n",
      "coref\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "the popular Llama 2 model\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "fine-tune the Llama 2 7B.\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "\n",
      "fine-tune the Llama 2 7B.\n",
      "the Llama 2 model\n",
      "coref\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "the Llama 2 model\n",
      "We\n",
      "subj_obj\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "We\n",
      "not its instruction-tuned variant\n",
      "subj_obj\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "not its instruction-tuned variant\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "coref\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "performance between Llama 2\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "While it is difficult to compare performance between Llama 2 and T5 due to the massive difference in model sizes (Llama 2: 7B vs. \\text{T5}_{\\textsc{LARGE}}: 770M parameters), the E2E model with Llama 2 substantially outperforms the latter on the Challenge aspect.\n",
      "\n",
      "\n",
      "Path 326: 58.6153080161969\n",
      "step chain-of-thought or end-to-end abstractive summarization\n",
      "our extractive and abstractive summarization annotations\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "our extractive and abstractive summarization annotations\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "we\n",
      "coref\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "the popular Llama 2 model\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "fine-tune the Llama 2 7B.\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "\n",
      "fine-tune the Llama 2 7B.\n",
      "the Llama 2 model\n",
      "coref\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "the Llama 2 model\n",
      "we\n",
      "subj_obj\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "we\n",
      "not its instruction-tuned variant\n",
      "subj_obj\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "not its instruction-tuned variant\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "coref\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "performance between Llama 2\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "While it is difficult to compare performance between Llama 2 and T5 due to the massive difference in model sizes (Llama 2: 7B vs. \\text{T5}_{\\textsc{LARGE}}: 770M parameters), the E2E model with Llama 2 substantially outperforms the latter on the Challenge aspect.\n",
      "\n",
      "\n",
      "Path 327: 58.6153080161969\n",
      "step chain-of-thought or end-to-end abstractive summarization\n",
      "our extractive and abstractive summarization annotations\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "our extractive and abstractive summarization annotations\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "we\n",
      "coref\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "the popular Llama 2 model\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "fine-tune the Llama 2 7B.\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "\n",
      "fine-tune the Llama 2 7B.\n",
      "the Llama 2 model\n",
      "coref\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "the Llama 2 model\n",
      "we\n",
      "subj_obj\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "we\n",
      "not its instruction-tuned variant\n",
      "subj_obj\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "not its instruction-tuned variant\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "coref\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "performance between Llama 2\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "While it is difficult to compare performance between Llama 2 and T5 due to the massive difference in model sizes (Llama 2: 7B vs. \\text{T5}_{\\textsc{LARGE}}: 770M parameters), the E2E model with Llama 2 substantially outperforms the latter on the Challenge aspect.\n",
      "\n",
      "\n",
      "Path 328: 58.6153080161969\n",
      "step chain-of-thought or end-to-end abstractive summarization\n",
      "our extractive and abstractive summarization annotations\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "our extractive and abstractive summarization annotations\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "we\n",
      "coref\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "the popular Llama 2 model\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "fine-tune the Llama 2 7B.\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "\n",
      "fine-tune the Llama 2 7B.\n",
      "We\n",
      "subj_obj\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "\n",
      "We\n",
      "We\n",
      "coref\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "We\n",
      "not its instruction-tuned variant\n",
      "subj_obj\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "not its instruction-tuned variant\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "coref\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "performance between Llama 2\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "While it is difficult to compare performance between Llama 2 and T5 due to the massive difference in model sizes (Llama 2: 7B vs. \\text{T5}_{\\textsc{LARGE}}: 770M parameters), the E2E model with Llama 2 substantially outperforms the latter on the Challenge aspect.\n",
      "\n",
      "\n",
      "Path 329: 58.6153080161969\n",
      "step chain-of-thought or end-to-end abstractive summarization\n",
      "our extractive and abstractive summarization annotations\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "our extractive and abstractive summarization annotations\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "we\n",
      "coref\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "the popular Llama 2 model\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "fine-tune the Llama 2 7B.\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "\n",
      "fine-tune the Llama 2 7B.\n",
      "We\n",
      "subj_obj\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "\n",
      "We\n",
      "We\n",
      "coref\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "We\n",
      "not its instruction-tuned variant\n",
      "subj_obj\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "not its instruction-tuned variant\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "coref\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "performance between Llama 2\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "While it is difficult to compare performance between Llama 2 and T5 due to the massive difference in model sizes (Llama 2: 7B vs. \\text{T5}_{\\textsc{LARGE}}: 770M parameters), the E2E model with Llama 2 substantially outperforms the latter on the Challenge aspect.\n",
      "\n",
      "\n",
      "Path 330: 58.6153080161969\n",
      "step chain-of-thought or end-to-end abstractive summarization\n",
      "our extractive and abstractive summarization annotations\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "our extractive and abstractive summarization annotations\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "we\n",
      "coref\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "the popular Llama 2 model\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "fine-tune the Llama 2 7B.\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "\n",
      "fine-tune the Llama 2 7B.\n",
      "the Llama 2 model\n",
      "coref\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "the Llama 2 model\n",
      "We\n",
      "subj_obj\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "We\n",
      "not its instruction-tuned variant\n",
      "subj_obj\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "not its instruction-tuned variant\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "coref\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "performance between Llama 2\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "While it is difficult to compare performance between Llama 2 and T5 due to the massive difference in model sizes (Llama 2: 7B vs. \\text{T5}_{\\textsc{LARGE}}: 770M parameters), the E2E model with Llama 2 substantially outperforms the latter on the Challenge aspect.\n",
      "\n",
      "\n",
      "Path 331: 58.6153080161969\n",
      "step chain-of-thought or end-to-end abstractive summarization\n",
      "our extractive and abstractive summarization annotations\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "our extractive and abstractive summarization annotations\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "we\n",
      "coref\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "the popular Llama 2 model\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "fine-tune the Llama 2 7B.\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "\n",
      "fine-tune the Llama 2 7B.\n",
      "the Llama 2 model\n",
      "coref\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "the Llama 2 model\n",
      "We\n",
      "subj_obj\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "We\n",
      "not its instruction-tuned variant\n",
      "subj_obj\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "not its instruction-tuned variant\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "coref\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "performance between Llama 2\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "While it is difficult to compare performance between Llama 2 and T5 due to the massive difference in model sizes (Llama 2: 7B vs. \\text{T5}_{\\textsc{LARGE}}: 770M parameters), the E2E model with Llama 2 substantially outperforms the latter on the Challenge aspect.\n",
      "\n",
      "\n",
      "Path 332: 58.6153080161969\n",
      "step chain-of-thought or end-to-end abstractive summarization\n",
      "our extractive and abstractive summarization annotations\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "our extractive and abstractive summarization annotations\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "we\n",
      "coref\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "the popular Llama 2 model\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "fine-tune the Llama 2 7B.\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "\n",
      "fine-tune the Llama 2 7B.\n",
      "the Llama 2 model\n",
      "coref\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "the Llama 2 model\n",
      "we\n",
      "subj_obj\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "we\n",
      "not its instruction-tuned variant\n",
      "subj_obj\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "not its instruction-tuned variant\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "coref\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "performance between Llama 2\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "While it is difficult to compare performance between Llama 2 and T5 due to the massive difference in model sizes (Llama 2: 7B vs. \\text{T5}_{\\textsc{LARGE}}: 770M parameters), the E2E model with Llama 2 substantially outperforms the latter on the Challenge aspect.\n",
      "\n",
      "\n",
      "Path 333: 58.6153080161969\n",
      "step chain-of-thought or end-to-end abstractive summarization\n",
      "our extractive and abstractive summarization annotations\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "our extractive and abstractive summarization annotations\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "we\n",
      "coref\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "the popular Llama 2 model\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "fine-tune the Llama 2 7B.\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "\n",
      "fine-tune the Llama 2 7B.\n",
      "the Llama 2 model\n",
      "coref\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "the Llama 2 model\n",
      "we\n",
      "subj_obj\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "we\n",
      "not its instruction-tuned variant\n",
      "subj_obj\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "not its instruction-tuned variant\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "coref\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "performance between Llama 2\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "While it is difficult to compare performance between Llama 2 and T5 due to the massive difference in model sizes (Llama 2: 7B vs. \\text{T5}_{\\textsc{LARGE}}: 770M parameters), the E2E model with Llama 2 substantially outperforms the latter on the Challenge aspect.\n",
      "\n",
      "\n",
      "Path 334: 58.6153080161969\n",
      "step chain-of-thought or end-to-end abstractive summarization\n",
      "our extractive and abstractive summarization annotations\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "our extractive and abstractive summarization annotations\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "we\n",
      "coref\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "the popular Llama 2 model\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "fine-tune the Llama 2 7B.\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "\n",
      "fine-tune the Llama 2 7B.\n",
      "the Llama 2 model\n",
      "coref\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "the Llama 2 model\n",
      "We\n",
      "subj_obj\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "We\n",
      "not its instruction-tuned variant\n",
      "subj_obj\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "not its instruction-tuned variant\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "coref\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "performance between Llama 2\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "While it is difficult to compare performance between Llama 2 and T5 due to the massive difference in model sizes (Llama 2: 7B vs. \\text{T5}_{\\textsc{LARGE}}: 770M parameters), the E2E model with Llama 2 substantially outperforms the latter on the Challenge aspect.\n",
      "\n",
      "\n",
      "Path 335: 58.6153080161969\n",
      "step chain-of-thought or end-to-end abstractive summarization\n",
      "our extractive and abstractive summarization annotations\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "our extractive and abstractive summarization annotations\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "we\n",
      "coref\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "the popular Llama 2 model\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "fine-tune the Llama 2 7B.\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "\n",
      "fine-tune the Llama 2 7B.\n",
      "the Llama 2 model\n",
      "coref\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "the Llama 2 model\n",
      "We\n",
      "subj_obj\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "We\n",
      "not its instruction-tuned variant\n",
      "subj_obj\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "not its instruction-tuned variant\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "coref\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "performance between Llama 2\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "While it is difficult to compare performance between Llama 2 and T5 due to the massive difference in model sizes (Llama 2: 7B vs. \\text{T5}_{\\textsc{LARGE}}: 770M parameters), the E2E model with Llama 2 substantially outperforms the latter on the Challenge aspect.\n",
      "\n",
      "\n",
      "Path 336: 58.6153080161969\n",
      "step chain-of-thought or end-to-end abstractive summarization\n",
      "our extractive and abstractive summarization annotations\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "our extractive and abstractive summarization annotations\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "we\n",
      "coref\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "the popular Llama 2 model\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "fine-tune the Llama 2 7B.\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "\n",
      "fine-tune the Llama 2 7B.\n",
      "the Llama 2 model\n",
      "coref\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "the Llama 2 model\n",
      "we\n",
      "subj_obj\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "we\n",
      "not its instruction-tuned variant\n",
      "subj_obj\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "not its instruction-tuned variant\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "coref\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "performance between Llama 2\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "While it is difficult to compare performance between Llama 2 and T5 due to the massive difference in model sizes (Llama 2: 7B vs. \\text{T5}_{\\textsc{LARGE}}: 770M parameters), the E2E model with Llama 2 substantially outperforms the latter on the Challenge aspect.\n",
      "\n",
      "\n",
      "Path 337: 58.6153080161969\n",
      "step chain-of-thought or end-to-end abstractive summarization\n",
      "our extractive and abstractive summarization annotations\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "our extractive and abstractive summarization annotations\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "we\n",
      "coref\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "the popular Llama 2 model\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "fine-tune the Llama 2 7B.\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "\n",
      "fine-tune the Llama 2 7B.\n",
      "the Llama 2 model\n",
      "coref\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "the Llama 2 model\n",
      "we\n",
      "subj_obj\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "we\n",
      "not its instruction-tuned variant\n",
      "subj_obj\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "not its instruction-tuned variant\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "coref\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "performance between Llama 2\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "While it is difficult to compare performance between Llama 2 and T5 due to the massive difference in model sizes (Llama 2: 7B vs. \\text{T5}_{\\textsc{LARGE}}: 770M parameters), the E2E model with Llama 2 substantially outperforms the latter on the Challenge aspect.\n",
      "\n",
      "\n",
      "Path 338: 58.99413409975431\n",
      "step chain-of-thought or end-to-end abstractive summarization\n",
      "our extractive and abstractive summarization annotations\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "our extractive and abstractive summarization annotations\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "we\n",
      "coref\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "the popular Llama 2 model\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "fine-tune the Llama 2 7B.\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "\n",
      "fine-tune the Llama 2 7B.\n",
      "the Llama 2 model\n",
      "coref\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "the Llama 2 model\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "shared_text\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "We\n",
      "subj_obj\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "We\n",
      "zero-shot prompting\n",
      "subj_obj\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "zero-shot prompting\n",
      "zero-shot prompting\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "By comparing zero-shot prompting and end-to-end tuning, one can observe that even with LLMs that are shown to be strong in summarization without any training, our dataset can help to improve their performance.\n",
      "\n",
      "\n",
      "Path 339: 58.99413409975431\n",
      "step chain-of-thought or end-to-end abstractive summarization\n",
      "our extractive and abstractive summarization annotations\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "our extractive and abstractive summarization annotations\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "we\n",
      "coref\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "the popular Llama 2 model\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "fine-tune the Llama 2 7B.\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "\n",
      "fine-tune the Llama 2 7B.\n",
      "the Llama 2 model\n",
      "coref\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "the Llama 2 model\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "shared_text\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "We\n",
      "subj_obj\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "We\n",
      "zero-shot prompting\n",
      "subj_obj\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "zero-shot prompting\n",
      "zero-shot prompting\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "By comparing zero-shot prompting and end-to-end tuning, one can observe that even with LLMs that are shown to be strong in summarization without any training, our dataset can help to improve their performance.\n",
      "\n",
      "\n",
      "Path 340: 58.99413409975431\n",
      "step chain-of-thought or end-to-end abstractive summarization\n",
      "our extractive and abstractive summarization annotations\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "our extractive and abstractive summarization annotations\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "we\n",
      "coref\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "the popular Llama 2 model\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "fine-tune the Llama 2 7B.\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "\n",
      "fine-tune the Llama 2 7B.\n",
      "the Llama 2 model\n",
      "coref\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "the Llama 2 model\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "shared_text\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "We\n",
      "subj_obj\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "We\n",
      "zero-shot prompting\n",
      "subj_obj\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "zero-shot prompting\n",
      "zero-shot prompting\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "By comparing zero-shot prompting and end-to-end tuning, one can observe that even with LLMs that are shown to be strong in summarization without any training, our dataset can help to improve their performance.\n",
      "\n",
      "\n",
      "Path 341: 58.99413409975431\n",
      "step chain-of-thought or end-to-end abstractive summarization\n",
      "our extractive and abstractive summarization annotations\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "our extractive and abstractive summarization annotations\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "we\n",
      "coref\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "the popular Llama 2 model\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "fine-tune the Llama 2 7B.\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "\n",
      "fine-tune the Llama 2 7B.\n",
      "the Llama 2 model\n",
      "coref\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "the Llama 2 model\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "shared_text\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "We\n",
      "subj_obj\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "We\n",
      "zero-shot prompting\n",
      "subj_obj\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "zero-shot prompting\n",
      "zero-shot prompting\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "By comparing zero-shot prompting and end-to-end tuning, one can observe that even with LLMs that are shown to be strong in summarization without any training, our dataset can help to improve their performance.\n",
      "\n",
      "\n",
      "Path 342: 59.013186031425946\n",
      "step chain-of-thought or end-to-end abstractive summarization\n",
      "our extractive and abstractive summarization annotations\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "our extractive and abstractive summarization annotations\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "we\n",
      "coref\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "its summarization abilities\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "its summarization abilities\n",
      "the model\n",
      "coref\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "\n",
      "the model\n",
      "the popular Llama 2 model\n",
      "shared_text\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "the Llama 2 model\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "the Llama 2 model\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "shared_text\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "performance between Llama 2\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "While it is difficult to compare performance between Llama 2 and T5 due to the massive difference in model sizes (Llama 2: 7B vs. \\text{T5}_{\\textsc{LARGE}}: 770M parameters), the E2E model with Llama 2 substantially outperforms the latter on the Challenge aspect.\n",
      "\n",
      "\n",
      "Path 343: 59.013186031425946\n",
      "step chain-of-thought or end-to-end abstractive summarization\n",
      "our extractive and abstractive summarization annotations\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "our extractive and abstractive summarization annotations\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "we\n",
      "coref\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "its summarization abilities\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "its summarization abilities\n",
      "the model\n",
      "coref\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "\n",
      "the model\n",
      "the popular Llama 2 model\n",
      "shared_text\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "the Llama 2 model\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "the Llama 2 model\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "shared_text\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "performance between Llama 2\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "While it is difficult to compare performance between Llama 2 and T5 due to the massive difference in model sizes (Llama 2: 7B vs. \\text{T5}_{\\textsc{LARGE}}: 770M parameters), the E2E model with Llama 2 substantially outperforms the latter on the Challenge aspect.\n",
      "\n",
      "\n",
      "Path 344: 59.231780219511336\n",
      "Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization,\n",
      "our extractive and abstractive summarization annotations\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "our extractive and abstractive summarization annotations\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "we\n",
      "coref\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "the popular Llama 2 model\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "its summarization abilities\n",
      "coref\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the model\n",
      "the model\n",
      "shared_text\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the model\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "subj_obj\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "A training data sample used for EtA-CoT\n",
      "shared_text\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "A training data sample used for EtA-CoT is shown in Table 5.\n",
      "\n",
      "A training data sample used for EtA-CoT\n",
      "EtA-CoT models\n",
      "shared_text\n",
      "A training data sample used for EtA-CoT is shown in Table 5.\n",
      "Table 6 presents ROUGE scores, BERTScores, and extraction performance using our gold extractive labels measured by F1 for EtA-CoT models.\n",
      "\n",
      "\n",
      "Path 345: 59.231780219511336\n",
      "Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization,\n",
      "our extractive and abstractive summarization annotations\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "our extractive and abstractive summarization annotations\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "we\n",
      "coref\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "the popular Llama 2 model\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "its summarization abilities\n",
      "coref\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the model\n",
      "the model\n",
      "shared_text\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the model\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "subj_obj\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "A training data sample used for EtA-CoT\n",
      "shared_text\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "A training data sample used for EtA-CoT is shown in Table 5.\n",
      "\n",
      "A training data sample used for EtA-CoT\n",
      "EtA-CoT models\n",
      "shared_text\n",
      "A training data sample used for EtA-CoT is shown in Table 5.\n",
      "Table 6 presents ROUGE scores, BERTScores, and extraction performance using our gold extractive labels measured by F1 for EtA-CoT models.\n",
      "\n",
      "\n",
      "Path 346: 59.231780219511336\n",
      "Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization,\n",
      "our extractive and abstractive summarization annotations\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "our extractive and abstractive summarization annotations\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "we\n",
      "coref\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "its summarization abilities\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "its summarization abilities\n",
      "the model\n",
      "coref\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "\n",
      "the model\n",
      "the model\n",
      "shared_text\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the model\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "subj_obj\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "A training data sample used for EtA-CoT\n",
      "shared_text\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "A training data sample used for EtA-CoT is shown in Table 5.\n",
      "\n",
      "A training data sample used for EtA-CoT\n",
      "EtA-CoT models\n",
      "shared_text\n",
      "A training data sample used for EtA-CoT is shown in Table 5.\n",
      "Table 6 presents ROUGE scores, BERTScores, and extraction performance using our gold extractive labels measured by F1 for EtA-CoT models.\n",
      "\n",
      "\n",
      "Path 347: 59.231780219511336\n",
      "Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization,\n",
      "our extractive and abstractive summarization annotations\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "our extractive and abstractive summarization annotations\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "we\n",
      "coref\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "its summarization abilities\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "its summarization abilities\n",
      "the model\n",
      "coref\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "\n",
      "the model\n",
      "the model\n",
      "shared_text\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the model\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "subj_obj\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "A training data sample used for EtA-CoT\n",
      "shared_text\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "A training data sample used for EtA-CoT is shown in Table 5.\n",
      "\n",
      "A training data sample used for EtA-CoT\n",
      "EtA-CoT models\n",
      "shared_text\n",
      "A training data sample used for EtA-CoT is shown in Table 5.\n",
      "Table 6 presents ROUGE scores, BERTScores, and extraction performance using our gold extractive labels measured by F1 for EtA-CoT models.\n",
      "\n",
      "\n",
      "Path 348: 59.231780219511336\n",
      "Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization,\n",
      "our extractive and abstractive summarization annotations\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "our extractive and abstractive summarization annotations\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "we\n",
      "coref\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "the popular Llama 2 model\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "its summarization abilities\n",
      "coref\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the model\n",
      "the model\n",
      "shared_text\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the model\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "subj_obj\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "A training data sample used for EtA-CoT\n",
      "shared_text\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "A training data sample used for EtA-CoT is shown in Table 5.\n",
      "\n",
      "A training data sample used for EtA-CoT\n",
      "EtA-CoT models\n",
      "shared_text\n",
      "A training data sample used for EtA-CoT is shown in Table 5.\n",
      "Table 6 presents ROUGE scores, BERTScores, and extraction performance using our gold extractive labels measured by F1 for EtA-CoT models.\n",
      "\n",
      "\n",
      "Path 349: 59.231780219511336\n",
      "Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization,\n",
      "our extractive and abstractive summarization annotations\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "our extractive and abstractive summarization annotations\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "we\n",
      "coref\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "the popular Llama 2 model\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "its summarization abilities\n",
      "coref\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the model\n",
      "the model\n",
      "shared_text\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the model\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "subj_obj\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "A training data sample used for EtA-CoT\n",
      "shared_text\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "A training data sample used for EtA-CoT is shown in Table 5.\n",
      "\n",
      "A training data sample used for EtA-CoT\n",
      "EtA-CoT models\n",
      "shared_text\n",
      "A training data sample used for EtA-CoT is shown in Table 5.\n",
      "Table 6 presents ROUGE scores, BERTScores, and extraction performance using our gold extractive labels measured by F1 for EtA-CoT models.\n",
      "\n",
      "\n",
      "Path 350: 59.231780219511336\n",
      "Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization,\n",
      "our extractive and abstractive summarization annotations\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "our extractive and abstractive summarization annotations\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "we\n",
      "coref\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "its summarization abilities\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "its summarization abilities\n",
      "the model\n",
      "coref\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "\n",
      "the model\n",
      "the model\n",
      "shared_text\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the model\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "subj_obj\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "A training data sample used for EtA-CoT\n",
      "shared_text\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "A training data sample used for EtA-CoT is shown in Table 5.\n",
      "\n",
      "A training data sample used for EtA-CoT\n",
      "EtA-CoT models\n",
      "shared_text\n",
      "A training data sample used for EtA-CoT is shown in Table 5.\n",
      "Table 6 presents ROUGE scores, BERTScores, and extraction performance using our gold extractive labels measured by F1 for EtA-CoT models.\n",
      "\n",
      "\n",
      "Path 351: 59.231780219511336\n",
      "Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization,\n",
      "our extractive and abstractive summarization annotations\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "our extractive and abstractive summarization annotations\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "we\n",
      "coref\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "its summarization abilities\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "its summarization abilities\n",
      "the model\n",
      "coref\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "\n",
      "the model\n",
      "the model\n",
      "shared_text\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the model\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "subj_obj\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "A training data sample used for EtA-CoT\n",
      "shared_text\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "A training data sample used for EtA-CoT is shown in Table 5.\n",
      "\n",
      "A training data sample used for EtA-CoT\n",
      "EtA-CoT models\n",
      "shared_text\n",
      "A training data sample used for EtA-CoT is shown in Table 5.\n",
      "Table 6 presents ROUGE scores, BERTScores, and extraction performance using our gold extractive labels measured by F1 for EtA-CoT models.\n",
      "\n",
      "\n",
      "Path 352: 59.236431142325294\n",
      "Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization,\n",
      "our extractive and abstractive summarization annotations\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "our extractive and abstractive summarization annotations\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "we\n",
      "coref\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "the popular Llama 2 model\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "fine-tune the Llama 2 7B.\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "\n",
      "fine-tune the Llama 2 7B.\n",
      "We\n",
      "subj_obj\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "\n",
      "We\n",
      "We\n",
      "coref\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "We\n",
      "not its instruction-tuned variant\n",
      "subj_obj\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "not its instruction-tuned variant\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "coref\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "performance between Llama 2\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "While it is difficult to compare performance between Llama 2 and T5 due to the massive difference in model sizes (Llama 2: 7B vs. \\text{T5}_{\\textsc{LARGE}}: 770M parameters), the E2E model with Llama 2 substantially outperforms the latter on the Challenge aspect.\n",
      "\n",
      "\n",
      "Path 353: 59.236431142325294\n",
      "Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization,\n",
      "our extractive and abstractive summarization annotations\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "our extractive and abstractive summarization annotations\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "we\n",
      "coref\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "the popular Llama 2 model\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "fine-tune the Llama 2 7B.\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "\n",
      "fine-tune the Llama 2 7B.\n",
      "We\n",
      "subj_obj\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "\n",
      "We\n",
      "We\n",
      "coref\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "We\n",
      "not its instruction-tuned variant\n",
      "subj_obj\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "not its instruction-tuned variant\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "coref\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "performance between Llama 2\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "While it is difficult to compare performance between Llama 2 and T5 due to the massive difference in model sizes (Llama 2: 7B vs. \\text{T5}_{\\textsc{LARGE}}: 770M parameters), the E2E model with Llama 2 substantially outperforms the latter on the Challenge aspect.\n",
      "\n",
      "\n",
      "Path 354: 59.236431142325294\n",
      "Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization,\n",
      "our extractive and abstractive summarization annotations\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "our extractive and abstractive summarization annotations\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "we\n",
      "coref\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "the popular Llama 2 model\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "fine-tune the Llama 2 7B.\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "\n",
      "fine-tune the Llama 2 7B.\n",
      "the Llama 2 model\n",
      "coref\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "the Llama 2 model\n",
      "We\n",
      "subj_obj\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "We\n",
      "not its instruction-tuned variant\n",
      "subj_obj\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "not its instruction-tuned variant\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "coref\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "performance between Llama 2\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "While it is difficult to compare performance between Llama 2 and T5 due to the massive difference in model sizes (Llama 2: 7B vs. \\text{T5}_{\\textsc{LARGE}}: 770M parameters), the E2E model with Llama 2 substantially outperforms the latter on the Challenge aspect.\n",
      "\n",
      "\n",
      "Path 355: 59.236431142325294\n",
      "Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization,\n",
      "our extractive and abstractive summarization annotations\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "our extractive and abstractive summarization annotations\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "we\n",
      "coref\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "the popular Llama 2 model\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "fine-tune the Llama 2 7B.\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "\n",
      "fine-tune the Llama 2 7B.\n",
      "the Llama 2 model\n",
      "coref\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "the Llama 2 model\n",
      "We\n",
      "subj_obj\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "We\n",
      "not its instruction-tuned variant\n",
      "subj_obj\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "not its instruction-tuned variant\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "coref\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "performance between Llama 2\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "While it is difficult to compare performance between Llama 2 and T5 due to the massive difference in model sizes (Llama 2: 7B vs. \\text{T5}_{\\textsc{LARGE}}: 770M parameters), the E2E model with Llama 2 substantially outperforms the latter on the Challenge aspect.\n",
      "\n",
      "\n",
      "Path 356: 59.236431142325294\n",
      "Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization,\n",
      "our extractive and abstractive summarization annotations\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "our extractive and abstractive summarization annotations\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "we\n",
      "coref\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "the popular Llama 2 model\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "fine-tune the Llama 2 7B.\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "\n",
      "fine-tune the Llama 2 7B.\n",
      "the Llama 2 model\n",
      "coref\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "the Llama 2 model\n",
      "we\n",
      "subj_obj\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "we\n",
      "not its instruction-tuned variant\n",
      "subj_obj\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "not its instruction-tuned variant\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "coref\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "performance between Llama 2\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "While it is difficult to compare performance between Llama 2 and T5 due to the massive difference in model sizes (Llama 2: 7B vs. \\text{T5}_{\\textsc{LARGE}}: 770M parameters), the E2E model with Llama 2 substantially outperforms the latter on the Challenge aspect.\n",
      "\n",
      "\n",
      "Path 357: 59.236431142325294\n",
      "Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization,\n",
      "our extractive and abstractive summarization annotations\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "our extractive and abstractive summarization annotations\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "we\n",
      "coref\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "the popular Llama 2 model\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "fine-tune the Llama 2 7B.\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "\n",
      "fine-tune the Llama 2 7B.\n",
      "the Llama 2 model\n",
      "coref\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "the Llama 2 model\n",
      "we\n",
      "subj_obj\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "we\n",
      "not its instruction-tuned variant\n",
      "subj_obj\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "not its instruction-tuned variant\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "coref\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "performance between Llama 2\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "While it is difficult to compare performance between Llama 2 and T5 due to the massive difference in model sizes (Llama 2: 7B vs. \\text{T5}_{\\textsc{LARGE}}: 770M parameters), the E2E model with Llama 2 substantially outperforms the latter on the Challenge aspect.\n",
      "\n",
      "\n",
      "Path 358: 59.236431142325294\n",
      "Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization,\n",
      "our extractive and abstractive summarization annotations\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "our extractive and abstractive summarization annotations\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "we\n",
      "coref\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "the popular Llama 2 model\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "fine-tune the Llama 2 7B.\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "\n",
      "fine-tune the Llama 2 7B.\n",
      "the Llama 2 model\n",
      "coref\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "the Llama 2 model\n",
      "We\n",
      "subj_obj\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "We\n",
      "not its instruction-tuned variant\n",
      "subj_obj\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "not its instruction-tuned variant\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "coref\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "performance between Llama 2\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "While it is difficult to compare performance between Llama 2 and T5 due to the massive difference in model sizes (Llama 2: 7B vs. \\text{T5}_{\\textsc{LARGE}}: 770M parameters), the E2E model with Llama 2 substantially outperforms the latter on the Challenge aspect.\n",
      "\n",
      "\n",
      "Path 359: 59.236431142325294\n",
      "Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization,\n",
      "our extractive and abstractive summarization annotations\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "our extractive and abstractive summarization annotations\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "we\n",
      "coref\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "the popular Llama 2 model\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "fine-tune the Llama 2 7B.\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "\n",
      "fine-tune the Llama 2 7B.\n",
      "the Llama 2 model\n",
      "coref\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "the Llama 2 model\n",
      "We\n",
      "subj_obj\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "We\n",
      "not its instruction-tuned variant\n",
      "subj_obj\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "not its instruction-tuned variant\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "coref\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "performance between Llama 2\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "While it is difficult to compare performance between Llama 2 and T5 due to the massive difference in model sizes (Llama 2: 7B vs. \\text{T5}_{\\textsc{LARGE}}: 770M parameters), the E2E model with Llama 2 substantially outperforms the latter on the Challenge aspect.\n",
      "\n",
      "\n",
      "Path 360: 59.236431142325294\n",
      "Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization,\n",
      "our extractive and abstractive summarization annotations\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "our extractive and abstractive summarization annotations\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "we\n",
      "coref\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "the popular Llama 2 model\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "fine-tune the Llama 2 7B.\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "\n",
      "fine-tune the Llama 2 7B.\n",
      "the Llama 2 model\n",
      "coref\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "the Llama 2 model\n",
      "we\n",
      "subj_obj\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "we\n",
      "not its instruction-tuned variant\n",
      "subj_obj\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "not its instruction-tuned variant\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "coref\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "performance between Llama 2\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "While it is difficult to compare performance between Llama 2 and T5 due to the massive difference in model sizes (Llama 2: 7B vs. \\text{T5}_{\\textsc{LARGE}}: 770M parameters), the E2E model with Llama 2 substantially outperforms the latter on the Challenge aspect.\n",
      "\n",
      "\n",
      "Path 361: 59.236431142325294\n",
      "Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization,\n",
      "our extractive and abstractive summarization annotations\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "our extractive and abstractive summarization annotations\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "we\n",
      "coref\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "the popular Llama 2 model\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "fine-tune the Llama 2 7B.\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "\n",
      "fine-tune the Llama 2 7B.\n",
      "the Llama 2 model\n",
      "coref\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "the Llama 2 model\n",
      "we\n",
      "subj_obj\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "we\n",
      "not its instruction-tuned variant\n",
      "subj_obj\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "not its instruction-tuned variant\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "coref\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "performance between Llama 2\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "While it is difficult to compare performance between Llama 2 and T5 due to the massive difference in model sizes (Llama 2: 7B vs. \\text{T5}_{\\textsc{LARGE}}: 770M parameters), the E2E model with Llama 2 substantially outperforms the latter on the Challenge aspect.\n",
      "\n",
      "\n",
      "Path 362: 59.236431142325294\n",
      "Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization,\n",
      "our extractive and abstractive summarization annotations\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "our extractive and abstractive summarization annotations\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "we\n",
      "coref\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "the popular Llama 2 model\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "fine-tune the Llama 2 7B.\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "\n",
      "fine-tune the Llama 2 7B.\n",
      "We\n",
      "subj_obj\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "\n",
      "We\n",
      "We\n",
      "coref\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "We\n",
      "not its instruction-tuned variant\n",
      "subj_obj\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "not its instruction-tuned variant\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "coref\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "performance between Llama 2\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "While it is difficult to compare performance between Llama 2 and T5 due to the massive difference in model sizes (Llama 2: 7B vs. \\text{T5}_{\\textsc{LARGE}}: 770M parameters), the E2E model with Llama 2 substantially outperforms the latter on the Challenge aspect.\n",
      "\n",
      "\n",
      "Path 363: 59.236431142325294\n",
      "Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization,\n",
      "our extractive and abstractive summarization annotations\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "our extractive and abstractive summarization annotations\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "we\n",
      "coref\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "the popular Llama 2 model\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "fine-tune the Llama 2 7B.\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "\n",
      "fine-tune the Llama 2 7B.\n",
      "We\n",
      "subj_obj\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "\n",
      "We\n",
      "We\n",
      "coref\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "We\n",
      "not its instruction-tuned variant\n",
      "subj_obj\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "not its instruction-tuned variant\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "coref\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "performance between Llama 2\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "While it is difficult to compare performance between Llama 2 and T5 due to the massive difference in model sizes (Llama 2: 7B vs. \\text{T5}_{\\textsc{LARGE}}: 770M parameters), the E2E model with Llama 2 substantially outperforms the latter on the Challenge aspect.\n",
      "\n",
      "\n",
      "Path 364: 59.236431142325294\n",
      "Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization,\n",
      "our extractive and abstractive summarization annotations\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "our extractive and abstractive summarization annotations\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "we\n",
      "coref\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "the popular Llama 2 model\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "fine-tune the Llama 2 7B.\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "\n",
      "fine-tune the Llama 2 7B.\n",
      "the Llama 2 model\n",
      "coref\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "the Llama 2 model\n",
      "We\n",
      "subj_obj\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "We\n",
      "not its instruction-tuned variant\n",
      "subj_obj\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "not its instruction-tuned variant\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "coref\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "performance between Llama 2\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "While it is difficult to compare performance between Llama 2 and T5 due to the massive difference in model sizes (Llama 2: 7B vs. \\text{T5}_{\\textsc{LARGE}}: 770M parameters), the E2E model with Llama 2 substantially outperforms the latter on the Challenge aspect.\n",
      "\n",
      "\n",
      "Path 365: 59.236431142325294\n",
      "Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization,\n",
      "our extractive and abstractive summarization annotations\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "our extractive and abstractive summarization annotations\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "we\n",
      "coref\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "the popular Llama 2 model\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "fine-tune the Llama 2 7B.\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "\n",
      "fine-tune the Llama 2 7B.\n",
      "the Llama 2 model\n",
      "coref\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "the Llama 2 model\n",
      "We\n",
      "subj_obj\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "We\n",
      "not its instruction-tuned variant\n",
      "subj_obj\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "not its instruction-tuned variant\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "coref\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "performance between Llama 2\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "While it is difficult to compare performance between Llama 2 and T5 due to the massive difference in model sizes (Llama 2: 7B vs. \\text{T5}_{\\textsc{LARGE}}: 770M parameters), the E2E model with Llama 2 substantially outperforms the latter on the Challenge aspect.\n",
      "\n",
      "\n",
      "Path 366: 59.236431142325294\n",
      "Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization,\n",
      "our extractive and abstractive summarization annotations\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "our extractive and abstractive summarization annotations\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "we\n",
      "coref\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "the popular Llama 2 model\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "fine-tune the Llama 2 7B.\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "\n",
      "fine-tune the Llama 2 7B.\n",
      "the Llama 2 model\n",
      "coref\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "the Llama 2 model\n",
      "we\n",
      "subj_obj\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "we\n",
      "not its instruction-tuned variant\n",
      "subj_obj\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "not its instruction-tuned variant\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "coref\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "performance between Llama 2\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "While it is difficult to compare performance between Llama 2 and T5 due to the massive difference in model sizes (Llama 2: 7B vs. \\text{T5}_{\\textsc{LARGE}}: 770M parameters), the E2E model with Llama 2 substantially outperforms the latter on the Challenge aspect.\n",
      "\n",
      "\n",
      "Path 367: 59.236431142325294\n",
      "Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization,\n",
      "our extractive and abstractive summarization annotations\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "our extractive and abstractive summarization annotations\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "we\n",
      "coref\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "the popular Llama 2 model\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "fine-tune the Llama 2 7B.\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "\n",
      "fine-tune the Llama 2 7B.\n",
      "the Llama 2 model\n",
      "coref\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "the Llama 2 model\n",
      "we\n",
      "subj_obj\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "we\n",
      "not its instruction-tuned variant\n",
      "subj_obj\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "not its instruction-tuned variant\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "coref\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "performance between Llama 2\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "While it is difficult to compare performance between Llama 2 and T5 due to the massive difference in model sizes (Llama 2: 7B vs. \\text{T5}_{\\textsc{LARGE}}: 770M parameters), the E2E model with Llama 2 substantially outperforms the latter on the Challenge aspect.\n",
      "\n",
      "\n",
      "Path 368: 59.236431142325294\n",
      "Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization,\n",
      "our extractive and abstractive summarization annotations\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "our extractive and abstractive summarization annotations\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "we\n",
      "coref\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "the popular Llama 2 model\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "fine-tune the Llama 2 7B.\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "\n",
      "fine-tune the Llama 2 7B.\n",
      "the Llama 2 model\n",
      "coref\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "the Llama 2 model\n",
      "We\n",
      "subj_obj\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "We\n",
      "not its instruction-tuned variant\n",
      "subj_obj\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "not its instruction-tuned variant\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "coref\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "performance between Llama 2\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "While it is difficult to compare performance between Llama 2 and T5 due to the massive difference in model sizes (Llama 2: 7B vs. \\text{T5}_{\\textsc{LARGE}}: 770M parameters), the E2E model with Llama 2 substantially outperforms the latter on the Challenge aspect.\n",
      "\n",
      "\n",
      "Path 369: 59.236431142325294\n",
      "Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization,\n",
      "our extractive and abstractive summarization annotations\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "our extractive and abstractive summarization annotations\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "we\n",
      "coref\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "the popular Llama 2 model\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "fine-tune the Llama 2 7B.\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "\n",
      "fine-tune the Llama 2 7B.\n",
      "the Llama 2 model\n",
      "coref\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "the Llama 2 model\n",
      "We\n",
      "subj_obj\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "We\n",
      "not its instruction-tuned variant\n",
      "subj_obj\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "not its instruction-tuned variant\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "coref\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "performance between Llama 2\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "While it is difficult to compare performance between Llama 2 and T5 due to the massive difference in model sizes (Llama 2: 7B vs. \\text{T5}_{\\textsc{LARGE}}: 770M parameters), the E2E model with Llama 2 substantially outperforms the latter on the Challenge aspect.\n",
      "\n",
      "\n",
      "Path 370: 59.236431142325294\n",
      "Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization,\n",
      "our extractive and abstractive summarization annotations\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "our extractive and abstractive summarization annotations\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "we\n",
      "coref\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "the popular Llama 2 model\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "fine-tune the Llama 2 7B.\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "\n",
      "fine-tune the Llama 2 7B.\n",
      "the Llama 2 model\n",
      "coref\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "the Llama 2 model\n",
      "we\n",
      "subj_obj\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "we\n",
      "not its instruction-tuned variant\n",
      "subj_obj\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "not its instruction-tuned variant\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "coref\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "performance between Llama 2\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "While it is difficult to compare performance between Llama 2 and T5 due to the massive difference in model sizes (Llama 2: 7B vs. \\text{T5}_{\\textsc{LARGE}}: 770M parameters), the E2E model with Llama 2 substantially outperforms the latter on the Challenge aspect.\n",
      "\n",
      "\n",
      "Path 371: 59.236431142325294\n",
      "Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization,\n",
      "our extractive and abstractive summarization annotations\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "our extractive and abstractive summarization annotations\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "we\n",
      "coref\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "the popular Llama 2 model\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "fine-tune the Llama 2 7B.\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "\n",
      "fine-tune the Llama 2 7B.\n",
      "the Llama 2 model\n",
      "coref\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "the Llama 2 model\n",
      "we\n",
      "subj_obj\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "we\n",
      "not its instruction-tuned variant\n",
      "subj_obj\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "not its instruction-tuned variant\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "coref\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "performance between Llama 2\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "While it is difficult to compare performance between Llama 2 and T5 due to the massive difference in model sizes (Llama 2: 7B vs. \\text{T5}_{\\textsc{LARGE}}: 770M parameters), the E2E model with Llama 2 substantially outperforms the latter on the Challenge aspect.\n",
      "\n",
      "\n",
      "Path 372: 59.61525722588271\n",
      "Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization,\n",
      "our extractive and abstractive summarization annotations\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "our extractive and abstractive summarization annotations\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "we\n",
      "coref\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "the popular Llama 2 model\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "fine-tune the Llama 2 7B.\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "\n",
      "fine-tune the Llama 2 7B.\n",
      "the Llama 2 model\n",
      "coref\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "the Llama 2 model\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "shared_text\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "We\n",
      "subj_obj\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "We\n",
      "zero-shot prompting\n",
      "subj_obj\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "zero-shot prompting\n",
      "zero-shot prompting\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "By comparing zero-shot prompting and end-to-end tuning, one can observe that even with LLMs that are shown to be strong in summarization without any training, our dataset can help to improve their performance.\n",
      "\n",
      "\n",
      "Path 373: 59.61525722588271\n",
      "Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization,\n",
      "our extractive and abstractive summarization annotations\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "our extractive and abstractive summarization annotations\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "we\n",
      "coref\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "the popular Llama 2 model\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "fine-tune the Llama 2 7B.\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "\n",
      "fine-tune the Llama 2 7B.\n",
      "the Llama 2 model\n",
      "coref\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "the Llama 2 model\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "shared_text\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "We\n",
      "subj_obj\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "We\n",
      "zero-shot prompting\n",
      "subj_obj\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "zero-shot prompting\n",
      "zero-shot prompting\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "By comparing zero-shot prompting and end-to-end tuning, one can observe that even with LLMs that are shown to be strong in summarization without any training, our dataset can help to improve their performance.\n",
      "\n",
      "\n",
      "Path 374: 59.61525722588271\n",
      "Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization,\n",
      "our extractive and abstractive summarization annotations\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "our extractive and abstractive summarization annotations\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "we\n",
      "coref\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "the popular Llama 2 model\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "fine-tune the Llama 2 7B.\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "\n",
      "fine-tune the Llama 2 7B.\n",
      "the Llama 2 model\n",
      "coref\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "the Llama 2 model\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "shared_text\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "We\n",
      "subj_obj\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "We\n",
      "zero-shot prompting\n",
      "subj_obj\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "zero-shot prompting\n",
      "zero-shot prompting\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "By comparing zero-shot prompting and end-to-end tuning, one can observe that even with LLMs that are shown to be strong in summarization without any training, our dataset can help to improve their performance.\n",
      "\n",
      "\n",
      "Path 375: 59.61525722588271\n",
      "Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization,\n",
      "our extractive and abstractive summarization annotations\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "our extractive and abstractive summarization annotations\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "we\n",
      "coref\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "the popular Llama 2 model\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "fine-tune the Llama 2 7B.\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "\n",
      "fine-tune the Llama 2 7B.\n",
      "the Llama 2 model\n",
      "coref\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "the Llama 2 model\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "shared_text\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "We\n",
      "subj_obj\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "We\n",
      "zero-shot prompting\n",
      "subj_obj\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "zero-shot prompting\n",
      "zero-shot prompting\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "By comparing zero-shot prompting and end-to-end tuning, one can observe that even with LLMs that are shown to be strong in summarization without any training, our dataset can help to improve their performance.\n",
      "\n",
      "\n",
      "Path 376: 59.63430915755434\n",
      "Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization,\n",
      "our extractive and abstractive summarization annotations\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "our extractive and abstractive summarization annotations\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "we\n",
      "coref\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "its summarization abilities\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "its summarization abilities\n",
      "the model\n",
      "coref\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "\n",
      "the model\n",
      "the popular Llama 2 model\n",
      "shared_text\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "the Llama 2 model\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "the Llama 2 model\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "shared_text\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "performance between Llama 2\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "While it is difficult to compare performance between Llama 2 and T5 due to the massive difference in model sizes (Llama 2: 7B vs. \\text{T5}_{\\textsc{LARGE}}: 770M parameters), the E2E model with Llama 2 substantially outperforms the latter on the Challenge aspect.\n",
      "\n",
      "\n",
      "Path 377: 59.63430915755434\n",
      "Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization,\n",
      "our extractive and abstractive summarization annotations\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "our extractive and abstractive summarization annotations\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "we\n",
      "coref\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "its summarization abilities\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "its summarization abilities\n",
      "the model\n",
      "coref\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "\n",
      "the model\n",
      "the popular Llama 2 model\n",
      "shared_text\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "the Llama 2 model\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "the Llama 2 model\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "shared_text\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "performance between Llama 2\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "While it is difficult to compare performance between Llama 2 and T5 due to the massive difference in model sizes (Llama 2: 7B vs. \\text{T5}_{\\textsc{LARGE}}: 770M parameters), the E2E model with Llama 2 substantially outperforms the latter on the Challenge aspect.\n",
      "\n",
      "\n",
      "Path 378: 59.822352870528384\n",
      "step chain-of-thought or end-to-end abstractive summarization\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "the model\n",
      "subj_obj\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the model\n",
      "the model\n",
      "coref\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "\n",
      "the model\n",
      "the popular Llama 2 model\n",
      "shared_text\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "fine-tune the Llama 2 7B.\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "\n",
      "fine-tune the Llama 2 7B.\n",
      "We\n",
      "subj_obj\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "\n",
      "We\n",
      "We\n",
      "coref\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "We\n",
      "the Llama 2 model\n",
      "subj_obj\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "the Llama 2 model\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "shared_text\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "performance between Llama 2\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "While it is difficult to compare performance between Llama 2 and T5 due to the massive difference in model sizes (Llama 2: 7B vs. \\text{T5}_{\\textsc{LARGE}}: 770M parameters), the E2E model with Llama 2 substantially outperforms the latter on the Challenge aspect.\n",
      "\n",
      "\n",
      "Path 379: 59.822352870528384\n",
      "step chain-of-thought or end-to-end abstractive summarization\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "the model\n",
      "subj_obj\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the model\n",
      "the model\n",
      "coref\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "\n",
      "the model\n",
      "the popular Llama 2 model\n",
      "shared_text\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "fine-tune the Llama 2 7B.\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "\n",
      "fine-tune the Llama 2 7B.\n",
      "We\n",
      "subj_obj\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "\n",
      "We\n",
      "We\n",
      "coref\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "We\n",
      "the Llama 2 model\n",
      "subj_obj\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "the Llama 2 model\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "shared_text\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "performance between Llama 2\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "While it is difficult to compare performance between Llama 2 and T5 due to the massive difference in model sizes (Llama 2: 7B vs. \\text{T5}_{\\textsc{LARGE}}: 770M parameters), the E2E model with Llama 2 substantially outperforms the latter on the Challenge aspect.\n",
      "\n",
      "\n",
      "Path 380: 60.145117829484974\n",
      "step chain-of-thought or end-to-end abstractive summarization\n",
      "our extractive and abstractive summarization annotations\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "our extractive and abstractive summarization annotations\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "we\n",
      "coref\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "the popular Llama 2 model\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "the model\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "\n",
      "the model\n",
      "the model\n",
      "coref\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the model\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "subj_obj\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "A training data sample used for EtA-CoT\n",
      "shared_text\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "A training data sample used for EtA-CoT is shown in Table 5.\n",
      "\n",
      "A training data sample used for EtA-CoT\n",
      "EtA-CoT models\n",
      "shared_text\n",
      "A training data sample used for EtA-CoT is shown in Table 5.\n",
      "Table 6 presents ROUGE scores, BERTScores, and extraction performance using our gold extractive labels measured by F1 for EtA-CoT models.\n",
      "\n",
      "\n",
      "Path 381: 60.145117829484974\n",
      "step chain-of-thought or end-to-end abstractive summarization\n",
      "our extractive and abstractive summarization annotations\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "our extractive and abstractive summarization annotations\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "we\n",
      "coref\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "the popular Llama 2 model\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "the model\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "\n",
      "the model\n",
      "the model\n",
      "coref\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the model\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "subj_obj\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "A training data sample used for EtA-CoT\n",
      "shared_text\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "A training data sample used for EtA-CoT is shown in Table 5.\n",
      "\n",
      "A training data sample used for EtA-CoT\n",
      "EtA-CoT models\n",
      "shared_text\n",
      "A training data sample used for EtA-CoT is shown in Table 5.\n",
      "Table 6 presents ROUGE scores, BERTScores, and extraction performance using our gold extractive labels measured by F1 for EtA-CoT models.\n",
      "\n",
      "\n",
      "Path 382: 60.145117829484974\n",
      "step chain-of-thought or end-to-end abstractive summarization\n",
      "our extractive and abstractive summarization annotations\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "our extractive and abstractive summarization annotations\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "we\n",
      "coref\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "its summarization abilities\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "its summarization abilities\n",
      "the popular Llama 2 model\n",
      "coref\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "the model\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "\n",
      "the model\n",
      "the model\n",
      "coref\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the model\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "subj_obj\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "A training data sample used for EtA-CoT\n",
      "shared_text\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "A training data sample used for EtA-CoT is shown in Table 5.\n",
      "\n",
      "A training data sample used for EtA-CoT\n",
      "EtA-CoT models\n",
      "shared_text\n",
      "A training data sample used for EtA-CoT is shown in Table 5.\n",
      "Table 6 presents ROUGE scores, BERTScores, and extraction performance using our gold extractive labels measured by F1 for EtA-CoT models.\n",
      "\n",
      "\n",
      "Path 383: 60.145117829484974\n",
      "step chain-of-thought or end-to-end abstractive summarization\n",
      "our extractive and abstractive summarization annotations\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "our extractive and abstractive summarization annotations\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "we\n",
      "coref\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "its summarization abilities\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "its summarization abilities\n",
      "the popular Llama 2 model\n",
      "coref\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "the model\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "\n",
      "the model\n",
      "the model\n",
      "coref\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the model\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "subj_obj\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "A training data sample used for EtA-CoT\n",
      "shared_text\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "A training data sample used for EtA-CoT is shown in Table 5.\n",
      "\n",
      "A training data sample used for EtA-CoT\n",
      "EtA-CoT models\n",
      "shared_text\n",
      "A training data sample used for EtA-CoT is shown in Table 5.\n",
      "Table 6 presents ROUGE scores, BERTScores, and extraction performance using our gold extractive labels measured by F1 for EtA-CoT models.\n",
      "\n",
      "\n",
      "Path 384: 60.145117829484974\n",
      "step chain-of-thought or end-to-end abstractive summarization\n",
      "our extractive and abstractive summarization annotations\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "our extractive and abstractive summarization annotations\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "we\n",
      "coref\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "the popular Llama 2 model\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "the model\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "\n",
      "the model\n",
      "the model\n",
      "coref\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the model\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "subj_obj\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "A training data sample used for EtA-CoT\n",
      "shared_text\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "A training data sample used for EtA-CoT is shown in Table 5.\n",
      "\n",
      "A training data sample used for EtA-CoT\n",
      "EtA-CoT models\n",
      "shared_text\n",
      "A training data sample used for EtA-CoT is shown in Table 5.\n",
      "Table 6 presents ROUGE scores, BERTScores, and extraction performance using our gold extractive labels measured by F1 for EtA-CoT models.\n",
      "\n",
      "\n",
      "Path 385: 60.145117829484974\n",
      "step chain-of-thought or end-to-end abstractive summarization\n",
      "our extractive and abstractive summarization annotations\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "our extractive and abstractive summarization annotations\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "we\n",
      "coref\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "the popular Llama 2 model\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "the model\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "\n",
      "the model\n",
      "the model\n",
      "coref\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the model\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "subj_obj\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "A training data sample used for EtA-CoT\n",
      "shared_text\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "A training data sample used for EtA-CoT is shown in Table 5.\n",
      "\n",
      "A training data sample used for EtA-CoT\n",
      "EtA-CoT models\n",
      "shared_text\n",
      "A training data sample used for EtA-CoT is shown in Table 5.\n",
      "Table 6 presents ROUGE scores, BERTScores, and extraction performance using our gold extractive labels measured by F1 for EtA-CoT models.\n",
      "\n",
      "\n",
      "Path 386: 60.145117829484974\n",
      "step chain-of-thought or end-to-end abstractive summarization\n",
      "our extractive and abstractive summarization annotations\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "our extractive and abstractive summarization annotations\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "we\n",
      "coref\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "its summarization abilities\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "its summarization abilities\n",
      "the popular Llama 2 model\n",
      "coref\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "the model\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "\n",
      "the model\n",
      "the model\n",
      "coref\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the model\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "subj_obj\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "A training data sample used for EtA-CoT\n",
      "shared_text\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "A training data sample used for EtA-CoT is shown in Table 5.\n",
      "\n",
      "A training data sample used for EtA-CoT\n",
      "EtA-CoT models\n",
      "shared_text\n",
      "A training data sample used for EtA-CoT is shown in Table 5.\n",
      "Table 6 presents ROUGE scores, BERTScores, and extraction performance using our gold extractive labels measured by F1 for EtA-CoT models.\n",
      "\n",
      "\n",
      "Path 387: 60.145117829484974\n",
      "step chain-of-thought or end-to-end abstractive summarization\n",
      "our extractive and abstractive summarization annotations\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "our extractive and abstractive summarization annotations\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "we\n",
      "coref\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "its summarization abilities\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "its summarization abilities\n",
      "the popular Llama 2 model\n",
      "coref\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "the model\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "\n",
      "the model\n",
      "the model\n",
      "coref\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the model\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "subj_obj\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "A training data sample used for EtA-CoT\n",
      "shared_text\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "A training data sample used for EtA-CoT is shown in Table 5.\n",
      "\n",
      "A training data sample used for EtA-CoT\n",
      "EtA-CoT models\n",
      "shared_text\n",
      "A training data sample used for EtA-CoT is shown in Table 5.\n",
      "Table 6 presents ROUGE scores, BERTScores, and extraction performance using our gold extractive labels measured by F1 for EtA-CoT models.\n",
      "\n",
      "\n",
      "Path 388: 60.68622565179317\n",
      "step chain-of-thought or end-to-end abstractive summarization\n",
      "our extractive and abstractive summarization annotations\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "our extractive and abstractive summarization annotations\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "we\n",
      "coref\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "the popular Llama 2 model\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "fine-tune the Llama 2 7B.\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "\n",
      "fine-tune the Llama 2 7B.\n",
      "the Llama 2 model\n",
      "coref\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "the Llama 2 model\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "shared_text\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "performance between Llama 2\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "While it is difficult to compare performance between Llama 2 and T5 due to the massive difference in model sizes (Llama 2: 7B vs. \\text{T5}_{\\textsc{LARGE}}: 770M parameters), the E2E model with Llama 2 substantially outperforms the latter on the Challenge aspect.\n",
      "\n",
      "\n",
      "Path 389: 60.68622565179317\n",
      "step chain-of-thought or end-to-end abstractive summarization\n",
      "our extractive and abstractive summarization annotations\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "our extractive and abstractive summarization annotations\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "we\n",
      "coref\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "the popular Llama 2 model\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "fine-tune the Llama 2 7B.\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "\n",
      "fine-tune the Llama 2 7B.\n",
      "the Llama 2 model\n",
      "coref\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "the Llama 2 model\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "shared_text\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "performance between Llama 2\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "While it is difficult to compare performance between Llama 2 and T5 due to the massive difference in model sizes (Llama 2: 7B vs. \\text{T5}_{\\textsc{LARGE}}: 770M parameters), the E2E model with Llama 2 substantially outperforms the latter on the Challenge aspect.\n",
      "\n",
      "\n",
      "Path 390: 60.68622565179317\n",
      "step chain-of-thought or end-to-end abstractive summarization\n",
      "our extractive and abstractive summarization annotations\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "our extractive and abstractive summarization annotations\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "we\n",
      "coref\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "its summarization abilities\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "its summarization abilities\n",
      "the popular Llama 2 model\n",
      "coref\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "fine-tune the Llama 2 7B.\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "\n",
      "fine-tune the Llama 2 7B.\n",
      "the Llama 2 model\n",
      "coref\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "the Llama 2 model\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "shared_text\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "performance between Llama 2\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "While it is difficult to compare performance between Llama 2 and T5 due to the massive difference in model sizes (Llama 2: 7B vs. \\text{T5}_{\\textsc{LARGE}}: 770M parameters), the E2E model with Llama 2 substantially outperforms the latter on the Challenge aspect.\n",
      "\n",
      "\n",
      "Path 391: 60.68622565179317\n",
      "step chain-of-thought or end-to-end abstractive summarization\n",
      "our extractive and abstractive summarization annotations\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "our extractive and abstractive summarization annotations\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "we\n",
      "coref\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "its summarization abilities\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "its summarization abilities\n",
      "the popular Llama 2 model\n",
      "coref\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "fine-tune the Llama 2 7B.\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "\n",
      "fine-tune the Llama 2 7B.\n",
      "the Llama 2 model\n",
      "coref\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "the Llama 2 model\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "shared_text\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "performance between Llama 2\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "While it is difficult to compare performance between Llama 2 and T5 due to the massive difference in model sizes (Llama 2: 7B vs. \\text{T5}_{\\textsc{LARGE}}: 770M parameters), the E2E model with Llama 2 substantially outperforms the latter on the Challenge aspect.\n",
      "\n",
      "\n",
      "Path 392: 60.68622565179317\n",
      "step chain-of-thought or end-to-end abstractive summarization\n",
      "our extractive and abstractive summarization annotations\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "our extractive and abstractive summarization annotations\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "we\n",
      "coref\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "the popular Llama 2 model\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "fine-tune the Llama 2 7B.\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "\n",
      "fine-tune the Llama 2 7B.\n",
      "the Llama 2 model\n",
      "coref\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "the Llama 2 model\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "shared_text\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "performance between Llama 2\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "While it is difficult to compare performance between Llama 2 and T5 due to the massive difference in model sizes (Llama 2: 7B vs. \\text{T5}_{\\textsc{LARGE}}: 770M parameters), the E2E model with Llama 2 substantially outperforms the latter on the Challenge aspect.\n",
      "\n",
      "\n",
      "Path 393: 60.68622565179317\n",
      "step chain-of-thought or end-to-end abstractive summarization\n",
      "our extractive and abstractive summarization annotations\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "our extractive and abstractive summarization annotations\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "we\n",
      "coref\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "the popular Llama 2 model\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "fine-tune the Llama 2 7B.\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "\n",
      "fine-tune the Llama 2 7B.\n",
      "the Llama 2 model\n",
      "coref\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "the Llama 2 model\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "shared_text\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "performance between Llama 2\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "While it is difficult to compare performance between Llama 2 and T5 due to the massive difference in model sizes (Llama 2: 7B vs. \\text{T5}_{\\textsc{LARGE}}: 770M parameters), the E2E model with Llama 2 substantially outperforms the latter on the Challenge aspect.\n",
      "\n",
      "\n",
      "Path 394: 60.68622565179317\n",
      "step chain-of-thought or end-to-end abstractive summarization\n",
      "our extractive and abstractive summarization annotations\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "our extractive and abstractive summarization annotations\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "we\n",
      "coref\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "its summarization abilities\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "its summarization abilities\n",
      "the popular Llama 2 model\n",
      "coref\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "fine-tune the Llama 2 7B.\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "\n",
      "fine-tune the Llama 2 7B.\n",
      "the Llama 2 model\n",
      "coref\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "the Llama 2 model\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "shared_text\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "performance between Llama 2\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "While it is difficult to compare performance between Llama 2 and T5 due to the massive difference in model sizes (Llama 2: 7B vs. \\text{T5}_{\\textsc{LARGE}}: 770M parameters), the E2E model with Llama 2 substantially outperforms the latter on the Challenge aspect.\n",
      "\n",
      "\n",
      "Path 395: 60.68622565179317\n",
      "step chain-of-thought or end-to-end abstractive summarization\n",
      "our extractive and abstractive summarization annotations\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "our extractive and abstractive summarization annotations\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "we\n",
      "coref\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "its summarization abilities\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "its summarization abilities\n",
      "the popular Llama 2 model\n",
      "coref\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "fine-tune the Llama 2 7B.\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "\n",
      "fine-tune the Llama 2 7B.\n",
      "the Llama 2 model\n",
      "coref\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "the Llama 2 model\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "shared_text\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "performance between Llama 2\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "While it is difficult to compare performance between Llama 2 and T5 due to the massive difference in model sizes (Llama 2: 7B vs. \\text{T5}_{\\textsc{LARGE}}: 770M parameters), the E2E model with Llama 2 substantially outperforms the latter on the Challenge aspect.\n",
      "\n",
      "\n",
      "Path 396: 60.76624095561337\n",
      "Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization,\n",
      "our extractive and abstractive summarization annotations\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "our extractive and abstractive summarization annotations\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "we\n",
      "coref\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "the popular Llama 2 model\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "the model\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "\n",
      "the model\n",
      "the model\n",
      "coref\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the model\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "subj_obj\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "A training data sample used for EtA-CoT\n",
      "shared_text\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "A training data sample used for EtA-CoT is shown in Table 5.\n",
      "\n",
      "A training data sample used for EtA-CoT\n",
      "EtA-CoT models\n",
      "shared_text\n",
      "A training data sample used for EtA-CoT is shown in Table 5.\n",
      "Table 6 presents ROUGE scores, BERTScores, and extraction performance using our gold extractive labels measured by F1 for EtA-CoT models.\n",
      "\n",
      "\n",
      "Path 397: 60.76624095561337\n",
      "Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization,\n",
      "our extractive and abstractive summarization annotations\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "our extractive and abstractive summarization annotations\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "we\n",
      "coref\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "the popular Llama 2 model\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "the model\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "\n",
      "the model\n",
      "the model\n",
      "coref\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the model\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "subj_obj\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "A training data sample used for EtA-CoT\n",
      "shared_text\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "A training data sample used for EtA-CoT is shown in Table 5.\n",
      "\n",
      "A training data sample used for EtA-CoT\n",
      "EtA-CoT models\n",
      "shared_text\n",
      "A training data sample used for EtA-CoT is shown in Table 5.\n",
      "Table 6 presents ROUGE scores, BERTScores, and extraction performance using our gold extractive labels measured by F1 for EtA-CoT models.\n",
      "\n",
      "\n",
      "Path 398: 60.76624095561337\n",
      "Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization,\n",
      "our extractive and abstractive summarization annotations\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "our extractive and abstractive summarization annotations\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "we\n",
      "coref\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "its summarization abilities\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "its summarization abilities\n",
      "the popular Llama 2 model\n",
      "coref\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "the model\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "\n",
      "the model\n",
      "the model\n",
      "coref\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the model\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "subj_obj\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "A training data sample used for EtA-CoT\n",
      "shared_text\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "A training data sample used for EtA-CoT is shown in Table 5.\n",
      "\n",
      "A training data sample used for EtA-CoT\n",
      "EtA-CoT models\n",
      "shared_text\n",
      "A training data sample used for EtA-CoT is shown in Table 5.\n",
      "Table 6 presents ROUGE scores, BERTScores, and extraction performance using our gold extractive labels measured by F1 for EtA-CoT models.\n",
      "\n",
      "\n",
      "Path 399: 60.76624095561337\n",
      "Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization,\n",
      "our extractive and abstractive summarization annotations\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "our extractive and abstractive summarization annotations\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "we\n",
      "coref\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "its summarization abilities\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "its summarization abilities\n",
      "the popular Llama 2 model\n",
      "coref\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "the model\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "\n",
      "the model\n",
      "the model\n",
      "coref\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the model\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "subj_obj\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "A training data sample used for EtA-CoT\n",
      "shared_text\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "A training data sample used for EtA-CoT is shown in Table 5.\n",
      "\n",
      "A training data sample used for EtA-CoT\n",
      "EtA-CoT models\n",
      "shared_text\n",
      "A training data sample used for EtA-CoT is shown in Table 5.\n",
      "Table 6 presents ROUGE scores, BERTScores, and extraction performance using our gold extractive labels measured by F1 for EtA-CoT models.\n",
      "\n",
      "\n",
      "Path 400: 60.76624095561337\n",
      "Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization,\n",
      "our extractive and abstractive summarization annotations\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "our extractive and abstractive summarization annotations\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "we\n",
      "coref\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "the popular Llama 2 model\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "the model\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "\n",
      "the model\n",
      "the model\n",
      "coref\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the model\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "subj_obj\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "A training data sample used for EtA-CoT\n",
      "shared_text\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "A training data sample used for EtA-CoT is shown in Table 5.\n",
      "\n",
      "A training data sample used for EtA-CoT\n",
      "EtA-CoT models\n",
      "shared_text\n",
      "A training data sample used for EtA-CoT is shown in Table 5.\n",
      "Table 6 presents ROUGE scores, BERTScores, and extraction performance using our gold extractive labels measured by F1 for EtA-CoT models.\n",
      "\n",
      "\n",
      "Path 401: 60.76624095561337\n",
      "Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization,\n",
      "our extractive and abstractive summarization annotations\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "our extractive and abstractive summarization annotations\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "we\n",
      "coref\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "the popular Llama 2 model\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "the model\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "\n",
      "the model\n",
      "the model\n",
      "coref\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the model\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "subj_obj\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "A training data sample used for EtA-CoT\n",
      "shared_text\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "A training data sample used for EtA-CoT is shown in Table 5.\n",
      "\n",
      "A training data sample used for EtA-CoT\n",
      "EtA-CoT models\n",
      "shared_text\n",
      "A training data sample used for EtA-CoT is shown in Table 5.\n",
      "Table 6 presents ROUGE scores, BERTScores, and extraction performance using our gold extractive labels measured by F1 for EtA-CoT models.\n",
      "\n",
      "\n",
      "Path 402: 60.76624095561337\n",
      "Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization,\n",
      "our extractive and abstractive summarization annotations\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "our extractive and abstractive summarization annotations\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "we\n",
      "coref\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "its summarization abilities\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "its summarization abilities\n",
      "the popular Llama 2 model\n",
      "coref\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "the model\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "\n",
      "the model\n",
      "the model\n",
      "coref\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the model\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "subj_obj\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "A training data sample used for EtA-CoT\n",
      "shared_text\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "A training data sample used for EtA-CoT is shown in Table 5.\n",
      "\n",
      "A training data sample used for EtA-CoT\n",
      "EtA-CoT models\n",
      "shared_text\n",
      "A training data sample used for EtA-CoT is shown in Table 5.\n",
      "Table 6 presents ROUGE scores, BERTScores, and extraction performance using our gold extractive labels measured by F1 for EtA-CoT models.\n",
      "\n",
      "\n",
      "Path 403: 60.76624095561337\n",
      "Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization,\n",
      "our extractive and abstractive summarization annotations\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "our extractive and abstractive summarization annotations\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "we\n",
      "coref\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "its summarization abilities\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "its summarization abilities\n",
      "the popular Llama 2 model\n",
      "coref\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "the model\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "\n",
      "the model\n",
      "the model\n",
      "coref\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the model\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "subj_obj\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "A training data sample used for EtA-CoT\n",
      "shared_text\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "A training data sample used for EtA-CoT is shown in Table 5.\n",
      "\n",
      "A training data sample used for EtA-CoT\n",
      "EtA-CoT models\n",
      "shared_text\n",
      "A training data sample used for EtA-CoT is shown in Table 5.\n",
      "Table 6 presents ROUGE scores, BERTScores, and extraction performance using our gold extractive labels measured by F1 for EtA-CoT models.\n",
      "\n",
      "\n",
      "Path 404: 61.30734877792157\n",
      "Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization,\n",
      "our extractive and abstractive summarization annotations\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "our extractive and abstractive summarization annotations\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "we\n",
      "coref\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "the popular Llama 2 model\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "fine-tune the Llama 2 7B.\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "\n",
      "fine-tune the Llama 2 7B.\n",
      "the Llama 2 model\n",
      "coref\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "the Llama 2 model\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "shared_text\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "performance between Llama 2\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "While it is difficult to compare performance between Llama 2 and T5 due to the massive difference in model sizes (Llama 2: 7B vs. \\text{T5}_{\\textsc{LARGE}}: 770M parameters), the E2E model with Llama 2 substantially outperforms the latter on the Challenge aspect.\n",
      "\n",
      "\n",
      "Path 405: 61.30734877792157\n",
      "Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization,\n",
      "our extractive and abstractive summarization annotations\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "our extractive and abstractive summarization annotations\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "we\n",
      "coref\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "the popular Llama 2 model\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "fine-tune the Llama 2 7B.\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "\n",
      "fine-tune the Llama 2 7B.\n",
      "the Llama 2 model\n",
      "coref\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "the Llama 2 model\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "shared_text\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "performance between Llama 2\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "While it is difficult to compare performance between Llama 2 and T5 due to the massive difference in model sizes (Llama 2: 7B vs. \\text{T5}_{\\textsc{LARGE}}: 770M parameters), the E2E model with Llama 2 substantially outperforms the latter on the Challenge aspect.\n",
      "\n",
      "\n",
      "Path 406: 61.30734877792157\n",
      "Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization,\n",
      "our extractive and abstractive summarization annotations\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "our extractive and abstractive summarization annotations\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "we\n",
      "coref\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "its summarization abilities\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "its summarization abilities\n",
      "the popular Llama 2 model\n",
      "coref\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "fine-tune the Llama 2 7B.\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "\n",
      "fine-tune the Llama 2 7B.\n",
      "the Llama 2 model\n",
      "coref\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "the Llama 2 model\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "shared_text\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "performance between Llama 2\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "While it is difficult to compare performance between Llama 2 and T5 due to the massive difference in model sizes (Llama 2: 7B vs. \\text{T5}_{\\textsc{LARGE}}: 770M parameters), the E2E model with Llama 2 substantially outperforms the latter on the Challenge aspect.\n",
      "\n",
      "\n",
      "Path 407: 61.30734877792157\n",
      "Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization,\n",
      "our extractive and abstractive summarization annotations\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "our extractive and abstractive summarization annotations\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "we\n",
      "coref\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "its summarization abilities\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "its summarization abilities\n",
      "the popular Llama 2 model\n",
      "coref\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "fine-tune the Llama 2 7B.\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "\n",
      "fine-tune the Llama 2 7B.\n",
      "the Llama 2 model\n",
      "coref\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "the Llama 2 model\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "shared_text\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "performance between Llama 2\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "While it is difficult to compare performance between Llama 2 and T5 due to the massive difference in model sizes (Llama 2: 7B vs. \\text{T5}_{\\textsc{LARGE}}: 770M parameters), the E2E model with Llama 2 substantially outperforms the latter on the Challenge aspect.\n",
      "\n",
      "\n",
      "Path 408: 61.30734877792157\n",
      "Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization,\n",
      "our extractive and abstractive summarization annotations\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "our extractive and abstractive summarization annotations\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "we\n",
      "coref\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "the popular Llama 2 model\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "fine-tune the Llama 2 7B.\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "\n",
      "fine-tune the Llama 2 7B.\n",
      "the Llama 2 model\n",
      "coref\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "the Llama 2 model\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "shared_text\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "performance between Llama 2\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "While it is difficult to compare performance between Llama 2 and T5 due to the massive difference in model sizes (Llama 2: 7B vs. \\text{T5}_{\\textsc{LARGE}}: 770M parameters), the E2E model with Llama 2 substantially outperforms the latter on the Challenge aspect.\n",
      "\n",
      "\n",
      "Path 409: 61.30734877792157\n",
      "Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization,\n",
      "our extractive and abstractive summarization annotations\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "our extractive and abstractive summarization annotations\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "we\n",
      "coref\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "the popular Llama 2 model\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "fine-tune the Llama 2 7B.\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "\n",
      "fine-tune the Llama 2 7B.\n",
      "the Llama 2 model\n",
      "coref\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "the Llama 2 model\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "shared_text\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "performance between Llama 2\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "While it is difficult to compare performance between Llama 2 and T5 due to the massive difference in model sizes (Llama 2: 7B vs. \\text{T5}_{\\textsc{LARGE}}: 770M parameters), the E2E model with Llama 2 substantially outperforms the latter on the Challenge aspect.\n",
      "\n",
      "\n",
      "Path 410: 61.30734877792157\n",
      "Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization,\n",
      "our extractive and abstractive summarization annotations\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "our extractive and abstractive summarization annotations\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "we\n",
      "coref\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "its summarization abilities\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "its summarization abilities\n",
      "the popular Llama 2 model\n",
      "coref\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "fine-tune the Llama 2 7B.\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "\n",
      "fine-tune the Llama 2 7B.\n",
      "the Llama 2 model\n",
      "coref\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "the Llama 2 model\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "shared_text\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "performance between Llama 2\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "While it is difficult to compare performance between Llama 2 and T5 due to the massive difference in model sizes (Llama 2: 7B vs. \\text{T5}_{\\textsc{LARGE}}: 770M parameters), the E2E model with Llama 2 substantially outperforms the latter on the Challenge aspect.\n",
      "\n",
      "\n",
      "Path 411: 61.30734877792157\n",
      "Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization,\n",
      "our extractive and abstractive summarization annotations\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "our extractive and abstractive summarization annotations\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "we\n",
      "coref\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "its summarization abilities\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "its summarization abilities\n",
      "the popular Llama 2 model\n",
      "coref\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "fine-tune the Llama 2 7B.\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "\n",
      "fine-tune the Llama 2 7B.\n",
      "the Llama 2 model\n",
      "coref\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "the Llama 2 model\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "shared_text\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "performance between Llama 2\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "While it is difficult to compare performance between Llama 2 and T5 due to the massive difference in model sizes (Llama 2: 7B vs. \\text{T5}_{\\textsc{LARGE}}: 770M parameters), the E2E model with Llama 2 substantially outperforms the latter on the Challenge aspect.\n",
      "\n",
      "\n",
      "Path 412: 62.220686387895206\n",
      "step chain-of-thought or end-to-end abstractive summarization\n",
      "our extractive and abstractive summarization annotations\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "our extractive and abstractive summarization annotations\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "we\n",
      "coref\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "its summarization abilities\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "its summarization abilities\n",
      "the model\n",
      "coref\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "\n",
      "the model\n",
      "the popular Llama 2 model\n",
      "shared_text\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "fine-tune the Llama 2 7B.\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "\n",
      "fine-tune the Llama 2 7B.\n",
      "the Llama 2 model\n",
      "coref\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "the Llama 2 model\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "shared_text\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "performance between Llama 2\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "While it is difficult to compare performance between Llama 2 and T5 due to the massive difference in model sizes (Llama 2: 7B vs. \\text{T5}_{\\textsc{LARGE}}: 770M parameters), the E2E model with Llama 2 substantially outperforms the latter on the Challenge aspect.\n",
      "\n",
      "\n",
      "Path 413: 62.220686387895206\n",
      "step chain-of-thought or end-to-end abstractive summarization\n",
      "our extractive and abstractive summarization annotations\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "our extractive and abstractive summarization annotations\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "we\n",
      "coref\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "its summarization abilities\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "its summarization abilities\n",
      "the model\n",
      "coref\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "\n",
      "the model\n",
      "the popular Llama 2 model\n",
      "shared_text\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "fine-tune the Llama 2 7B.\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "\n",
      "fine-tune the Llama 2 7B.\n",
      "the Llama 2 model\n",
      "coref\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "the Llama 2 model\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "shared_text\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "performance between Llama 2\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "While it is difficult to compare performance between Llama 2 and T5 due to the massive difference in model sizes (Llama 2: 7B vs. \\text{T5}_{\\textsc{LARGE}}: 770M parameters), the E2E model with Llama 2 substantially outperforms the latter on the Challenge aspect.\n",
      "\n",
      "\n",
      "Path 414: 62.220686387895206\n",
      "step chain-of-thought or end-to-end abstractive summarization\n",
      "our extractive and abstractive summarization annotations\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "our extractive and abstractive summarization annotations\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "we\n",
      "coref\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "its summarization abilities\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "its summarization abilities\n",
      "the model\n",
      "coref\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "\n",
      "the model\n",
      "the popular Llama 2 model\n",
      "shared_text\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "fine-tune the Llama 2 7B.\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "\n",
      "fine-tune the Llama 2 7B.\n",
      "the Llama 2 model\n",
      "coref\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "the Llama 2 model\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "shared_text\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "performance between Llama 2\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "While it is difficult to compare performance between Llama 2 and T5 due to the massive difference in model sizes (Llama 2: 7B vs. \\text{T5}_{\\textsc{LARGE}}: 770M parameters), the E2E model with Llama 2 substantially outperforms the latter on the Challenge aspect.\n",
      "\n",
      "\n",
      "Path 415: 62.220686387895206\n",
      "step chain-of-thought or end-to-end abstractive summarization\n",
      "our extractive and abstractive summarization annotations\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "our extractive and abstractive summarization annotations\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "we\n",
      "coref\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "its summarization abilities\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "its summarization abilities\n",
      "the model\n",
      "coref\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "\n",
      "the model\n",
      "the popular Llama 2 model\n",
      "shared_text\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "fine-tune the Llama 2 7B.\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "\n",
      "fine-tune the Llama 2 7B.\n",
      "the Llama 2 model\n",
      "coref\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "the Llama 2 model\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "shared_text\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "performance between Llama 2\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "While it is difficult to compare performance between Llama 2 and T5 due to the massive difference in model sizes (Llama 2: 7B vs. \\text{T5}_{\\textsc{LARGE}}: 770M parameters), the E2E model with Llama 2 substantially outperforms the latter on the Challenge aspect.\n",
      "\n",
      "\n",
      "Path 416: 62.51231770824492\n",
      "step chain-of-thought or end-to-end abstractive summarization\n",
      "our extractive and abstractive summarization annotations\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "our extractive and abstractive summarization annotations\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "this instruction-tuning dataset\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "this instruction-tuning dataset\n",
      "an instruction\n",
      "shared_text\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "\n",
      "an instruction\n",
      "The first strategy\n",
      "subj_obj\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "\n",
      "The first strategy\n",
      "a summary\n",
      "subj_obj\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "\n",
      "a summary\n",
      "a summary\n",
      "shared_text\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "a summary\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "subj_obj\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "A training data sample used for EtA-CoT\n",
      "shared_text\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "A training data sample used for EtA-CoT is shown in Table 5.\n",
      "\n",
      "A training data sample used for EtA-CoT\n",
      "EtA-CoT models\n",
      "shared_text\n",
      "A training data sample used for EtA-CoT is shown in Table 5.\n",
      "Table 6 presents ROUGE scores, BERTScores, and extraction performance using our gold extractive labels measured by F1 for EtA-CoT models.\n",
      "\n",
      "\n",
      "Path 417: 62.51231770824492\n",
      "step chain-of-thought or end-to-end abstractive summarization\n",
      "our extractive and abstractive summarization annotations\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "our extractive and abstractive summarization annotations\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "this instruction-tuning dataset\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "this instruction-tuning dataset\n",
      "an instruction\n",
      "shared_text\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "\n",
      "an instruction\n",
      "The first strategy\n",
      "subj_obj\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "\n",
      "The first strategy\n",
      "a summary\n",
      "subj_obj\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "\n",
      "a summary\n",
      "a summary\n",
      "shared_text\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "a summary\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "subj_obj\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "A training data sample used for EtA-CoT\n",
      "shared_text\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "A training data sample used for EtA-CoT is shown in Table 5.\n",
      "\n",
      "A training data sample used for EtA-CoT\n",
      "EtA-CoT models\n",
      "shared_text\n",
      "A training data sample used for EtA-CoT is shown in Table 5.\n",
      "Table 6 presents ROUGE scores, BERTScores, and extraction performance using our gold extractive labels measured by F1 for EtA-CoT models.\n",
      "\n",
      "\n",
      "Path 418: 62.68622565179317\n",
      "step chain-of-thought or end-to-end abstractive summarization\n",
      "our extractive and abstractive summarization annotations\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "our extractive and abstractive summarization annotations\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "we\n",
      "coref\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "the popular Llama 2 model\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "fine-tune the Llama 2 7B.\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "\n",
      "fine-tune the Llama 2 7B.\n",
      "We\n",
      "subj_obj\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "\n",
      "We\n",
      "We\n",
      "coref\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "We\n",
      "the Llama 2 model\n",
      "subj_obj\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "the Llama 2 model\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "shared_text\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "performance between Llama 2\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "While it is difficult to compare performance between Llama 2 and T5 due to the massive difference in model sizes (Llama 2: 7B vs. \\text{T5}_{\\textsc{LARGE}}: 770M parameters), the E2E model with Llama 2 substantially outperforms the latter on the Challenge aspect.\n",
      "\n",
      "\n",
      "Path 419: 62.68622565179317\n",
      "step chain-of-thought or end-to-end abstractive summarization\n",
      "our extractive and abstractive summarization annotations\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "our extractive and abstractive summarization annotations\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "we\n",
      "coref\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "the popular Llama 2 model\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "fine-tune the Llama 2 7B.\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "\n",
      "fine-tune the Llama 2 7B.\n",
      "We\n",
      "subj_obj\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "\n",
      "We\n",
      "We\n",
      "coref\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "We\n",
      "the Llama 2 model\n",
      "subj_obj\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "the Llama 2 model\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "shared_text\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "performance between Llama 2\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "While it is difficult to compare performance between Llama 2 and T5 due to the massive difference in model sizes (Llama 2: 7B vs. \\text{T5}_{\\textsc{LARGE}}: 770M parameters), the E2E model with Llama 2 substantially outperforms the latter on the Challenge aspect.\n",
      "\n",
      "\n",
      "Path 420: 62.8418095140236\n",
      "Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization,\n",
      "our extractive and abstractive summarization annotations\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "our extractive and abstractive summarization annotations\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "we\n",
      "coref\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "its summarization abilities\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "its summarization abilities\n",
      "the model\n",
      "coref\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "\n",
      "the model\n",
      "the popular Llama 2 model\n",
      "shared_text\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "fine-tune the Llama 2 7B.\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "\n",
      "fine-tune the Llama 2 7B.\n",
      "the Llama 2 model\n",
      "coref\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "the Llama 2 model\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "shared_text\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "performance between Llama 2\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "While it is difficult to compare performance between Llama 2 and T5 due to the massive difference in model sizes (Llama 2: 7B vs. \\text{T5}_{\\textsc{LARGE}}: 770M parameters), the E2E model with Llama 2 substantially outperforms the latter on the Challenge aspect.\n",
      "\n",
      "\n",
      "Path 421: 62.8418095140236\n",
      "Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization,\n",
      "our extractive and abstractive summarization annotations\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "our extractive and abstractive summarization annotations\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "we\n",
      "coref\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "its summarization abilities\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "its summarization abilities\n",
      "the model\n",
      "coref\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "\n",
      "the model\n",
      "the popular Llama 2 model\n",
      "shared_text\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "fine-tune the Llama 2 7B.\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "\n",
      "fine-tune the Llama 2 7B.\n",
      "the Llama 2 model\n",
      "coref\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "the Llama 2 model\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "shared_text\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "performance between Llama 2\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "While it is difficult to compare performance between Llama 2 and T5 due to the massive difference in model sizes (Llama 2: 7B vs. \\text{T5}_{\\textsc{LARGE}}: 770M parameters), the E2E model with Llama 2 substantially outperforms the latter on the Challenge aspect.\n",
      "\n",
      "\n",
      "Path 422: 62.8418095140236\n",
      "Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization,\n",
      "our extractive and abstractive summarization annotations\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "our extractive and abstractive summarization annotations\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "we\n",
      "coref\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "its summarization abilities\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "its summarization abilities\n",
      "the model\n",
      "coref\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "\n",
      "the model\n",
      "the popular Llama 2 model\n",
      "shared_text\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "fine-tune the Llama 2 7B.\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "\n",
      "fine-tune the Llama 2 7B.\n",
      "the Llama 2 model\n",
      "coref\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "the Llama 2 model\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "shared_text\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "performance between Llama 2\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "While it is difficult to compare performance between Llama 2 and T5 due to the massive difference in model sizes (Llama 2: 7B vs. \\text{T5}_{\\textsc{LARGE}}: 770M parameters), the E2E model with Llama 2 substantially outperforms the latter on the Challenge aspect.\n",
      "\n",
      "\n",
      "Path 423: 62.8418095140236\n",
      "Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization,\n",
      "our extractive and abstractive summarization annotations\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "our extractive and abstractive summarization annotations\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "we\n",
      "coref\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "its summarization abilities\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "its summarization abilities\n",
      "the model\n",
      "coref\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "\n",
      "the model\n",
      "the popular Llama 2 model\n",
      "shared_text\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "fine-tune the Llama 2 7B.\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "\n",
      "fine-tune the Llama 2 7B.\n",
      "the Llama 2 model\n",
      "coref\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "the Llama 2 model\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "shared_text\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "performance between Llama 2\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "While it is difficult to compare performance between Llama 2 and T5 due to the massive difference in model sizes (Llama 2: 7B vs. \\text{T5}_{\\textsc{LARGE}}: 770M parameters), the E2E model with Llama 2 substantially outperforms the latter on the Challenge aspect.\n",
      "\n",
      "\n",
      "Path 424: 63.13344083437332\n",
      "Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization,\n",
      "our extractive and abstractive summarization annotations\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "our extractive and abstractive summarization annotations\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "this instruction-tuning dataset\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "this instruction-tuning dataset\n",
      "an instruction\n",
      "shared_text\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "\n",
      "an instruction\n",
      "The first strategy\n",
      "subj_obj\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "\n",
      "The first strategy\n",
      "a summary\n",
      "subj_obj\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "\n",
      "a summary\n",
      "a summary\n",
      "shared_text\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "a summary\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "subj_obj\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "A training data sample used for EtA-CoT\n",
      "shared_text\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "A training data sample used for EtA-CoT is shown in Table 5.\n",
      "\n",
      "A training data sample used for EtA-CoT\n",
      "EtA-CoT models\n",
      "shared_text\n",
      "A training data sample used for EtA-CoT is shown in Table 5.\n",
      "Table 6 presents ROUGE scores, BERTScores, and extraction performance using our gold extractive labels measured by F1 for EtA-CoT models.\n",
      "\n",
      "\n",
      "Path 425: 63.13344083437332\n",
      "Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization,\n",
      "our extractive and abstractive summarization annotations\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "our extractive and abstractive summarization annotations\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "this instruction-tuning dataset\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "this instruction-tuning dataset\n",
      "an instruction\n",
      "shared_text\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "\n",
      "an instruction\n",
      "The first strategy\n",
      "subj_obj\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "\n",
      "The first strategy\n",
      "a summary\n",
      "subj_obj\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "\n",
      "a summary\n",
      "a summary\n",
      "shared_text\n",
      "The first strategy simply fine-tunes the model to generate a summary given an instruction (E2E).\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "a summary\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "subj_obj\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "\n",
      "the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT),\n",
      "A training data sample used for EtA-CoT\n",
      "shared_text\n",
      "In contrast, the second strategy, dubbed extract-then-abstract chain-of-thought (EtA-CoT), trains the model to generate a summary by first generating a list of indexes to sentences that are relevant to produce the summary as an immediate reasoning step.\n",
      "A training data sample used for EtA-CoT is shown in Table 5.\n",
      "\n",
      "A training data sample used for EtA-CoT\n",
      "EtA-CoT models\n",
      "shared_text\n",
      "A training data sample used for EtA-CoT is shown in Table 5.\n",
      "Table 6 presents ROUGE scores, BERTScores, and extraction performance using our gold extractive labels measured by F1 for EtA-CoT models.\n",
      "\n",
      "\n",
      "Path 426: 63.30734877792157\n",
      "Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization,\n",
      "our extractive and abstractive summarization annotations\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "our extractive and abstractive summarization annotations\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "we\n",
      "coref\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "the popular Llama 2 model\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "fine-tune the Llama 2 7B.\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "\n",
      "fine-tune the Llama 2 7B.\n",
      "We\n",
      "subj_obj\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "\n",
      "We\n",
      "We\n",
      "coref\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "We\n",
      "the Llama 2 model\n",
      "subj_obj\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "the Llama 2 model\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "shared_text\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "performance between Llama 2\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "While it is difficult to compare performance between Llama 2 and T5 due to the massive difference in model sizes (Llama 2: 7B vs. \\text{T5}_{\\textsc{LARGE}}: 770M parameters), the E2E model with Llama 2 substantially outperforms the latter on the Challenge aspect.\n",
      "\n",
      "\n",
      "Path 427: 63.30734877792157\n",
      "Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization,\n",
      "our extractive and abstractive summarization annotations\n",
      "shared_text\n",
      "•RQ1: Which approach using PLMs, i.e., two-stage extract-then-abstract or end-to-end abstractive summarization, performs best on our dataset?•RQ2: Which tuning strategy for LLMs, i.e., two-step chain-of-thought or end-to-end abstractive summarization, is better for our task?•RQ3: How does a commonly used heuristic to induce silver-standard extractive summaries perform against our manually annotated aspects?\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "our extractive and abstractive summarization annotations\n",
      "We\n",
      "subj_obj\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "\n",
      "We\n",
      "we\n",
      "coref\n",
      "We build this instruction-tuning dataset using our extractive and abstractive summarization annotations.\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "we\n",
      "the popular Llama 2 model\n",
      "subj_obj\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "\n",
      "the popular Llama 2 model\n",
      "fine-tune the Llama 2 7B.\n",
      "shared_text\n",
      "Next, we take the popular Llama 2 model as a representative of recently proposed LLMs to evaluate its summarization abilities using ACLSum by fine-tuning it in two different ways.\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "\n",
      "fine-tune the Llama 2 7B.\n",
      "We\n",
      "subj_obj\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "\n",
      "We\n",
      "We\n",
      "coref\n",
      "(2023): we apply LoRA and enable gradient checkpointing to fine-tune the Llama 2 7B. We train one model on a joint dataset of all three aspects and specify the target aspect in the instruction.\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "We\n",
      "the Llama 2 model\n",
      "subj_obj\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "\n",
      "the Llama 2 model\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "shared_text\n",
      "We only trained the Llama 2 model but not its instruction-tuned variant since in our preliminary study we only observed marginal differences between them.\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "\n",
      "the instruction-tuned Llama 2 Chat model\n",
      "performance between Llama 2\n",
      "shared_text\n",
      "We also report results by zero-shot prompting using the instruction-tuned Llama 2 Chat model.\n",
      "While it is difficult to compare performance between Llama 2 and T5 due to the massive difference in model sizes (Llama 2: 7B vs. \\text{T5}_{\\textsc{LARGE}}: 770M parameters), the E2E model with Llama 2 substantially outperforms the latter on the Challenge aspect.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "path_len_pairs = list[tuple[float, int, int]]()\n",
    "for start_ent in block_start_ents:\n",
    "    for end_ent in block_end_ents.intersection(nx.descendants(subgraph, start_ent)):\n",
    "        for temp_path in nx.all_simple_paths(subgraph, start_ent, end_ent, cutoff=10):\n",
    "            if all(doc_manager.tid2block_id[doc_manager.phrases[node].start] in valid_path_blocks for node in temp_path[1:-1]):\n",
    "                path_len_pairs.append((sum(min(subgraph.edges[u, v, edge_type]['weight'] for edge_type in [SUBJ_OBJ, COREF, SHARED_TEXT] if subgraph.has_edge(u, v, key=edge_type)) for u, v in zip(temp_path[:-1], temp_path[1:])), start_ent, end_ent, temp_path))\n",
    "path_len_pairs = sorted(path_len_pairs, key=lambda x: x[0])\n",
    "for path_id, (path_len, start_ent, end_ent, temp_path) in enumerate(path_len_pairs[:]):\n",
    "    print(f'Path {path_id}: {path_len}')\n",
    "    last_edge_type = None\n",
    "    for edge_start, edge_end in zip(temp_path[:-1], temp_path[1:]):\n",
    "        for edge_type in [SUBJ_OBJ, COREF, SHARED_TEXT]:\n",
    "            if subgraph.has_edge(edge_start, edge_end, key=edge_type):\n",
    "                if last_edge_type == COREF and edge_type == COREF:\n",
    "                    continue\n",
    "                last_edge_type = edge_type\n",
    "                print(doc_manager.phrases[edge_start])\n",
    "                print(doc_manager.phrases[edge_end])\n",
    "                print(edge_type)\n",
    "                start_sent_id = doc_manager.tid2sent_id[doc_manager.phrases[edge_start].start]\n",
    "                end_sent_id = doc_manager.tid2sent_id[doc_manager.phrases[edge_end].start]\n",
    "                print(sents[start_sent_id])\n",
    "                if start_sent_id != end_sent_id:\n",
    "                    print(sents[end_sent_id])\n",
    "                print('')\n",
    "                break\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "False\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print(undir_dkg.has_edge(58, 74, key=SUBJ_OBJ))\n",
    "print(undir_dkg.has_edge(58, 74, key=COREF))\n",
    "print(undir_dkg.has_edge(58, 74, key=SHARED_TEXT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path[1][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.displacy import render"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "render(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dkg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
