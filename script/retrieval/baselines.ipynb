{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sci_review.data_base import *\n",
    "import jsonlines\n",
    "from sci_review.agentic_rag import *\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try a range of different questions. Besides extracting information into a taxonomy, I am converting the following datasets into test questions:\n",
    "+ ACLSum (Summarize the Challenge, Approach, and Outcome in the paper)\n",
    "+ SciREX (extract the main results of a scientific article including Dataset, Metric, Task and Method)\n",
    "+ arxivDIGESTables (given a table schema for literature survey and extract targeted values from scientific papers to fill in the table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('words_alpha.txt') as f:\n",
    "    words_alpha = set(f.read().splitlines())\n",
    "doc_manager = DocManager(word_vocab=words_alpha)\n",
    "\n",
    "agentic_rag = AgenticRAG()\n",
    "agentic_rag.doc_manager = doc_manager\n",
    "\n",
    "eval_metrics = EvalMetrics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ACLSum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize Data Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from aclsum import ACLSum\n",
    "\n",
    "# Load per split (\"train\", \"val\", \"test\")\n",
    "split = \"train\"\n",
    "train = ACLSum(split)\n",
    "\n",
    "aclsum_dataset = list[dict]()\n",
    "for doc in train:\n",
    "    aclsum_dataset.append(Sample(\n",
    "        doc_file=f'https://aclanthology.org/{doc.id}.pdf',\n",
    "        doc_strs=[\n",
    "            'Abstract', \n",
    "            DocManager.remove_citations(DocManager.remove_space_before_punct(' '.join(doc.get_all_sentences(['abstract'])))), \n",
    "            'Introduction', \n",
    "            DocManager.remove_citations(DocManager.remove_space_before_punct(' '.join(doc.get_all_sentences(['introduction'])))), \n",
    "            'Conclusion', \n",
    "            DocManager.remove_citations(DocManager.remove_space_before_punct(' '.join(doc.get_all_sentences(['conclusion'])))), \n",
    "        ],\n",
    "        outline='Abstract\\nIntroduction\\nConclusion',\n",
    "        question_types=['challenge', 'approach', 'outcome'],\n",
    "        questions={\n",
    "            'challenge': 'Summarize the challenge of the paper, which is the current situation faced by the researcher. It will normally include a Problem Statement, the Motivation, a Hypothesis and/or a Goal.', \n",
    "            'approach': 'Summarize the approach of the paper: How they intend to carry out the investigation, comments on a theoretical model or framework.', \n",
    "            'outcome': 'Summarize the outcome of the paper: Overall conclusion that should reject or support the research hypothesis.'\n",
    "        },\n",
    "        answers={\n",
    "            'challenge': doc.summaries['challenge'], \n",
    "            'approach': doc.summaries['approach'], \n",
    "            'outcome': doc.summaries['outcome']\n",
    "        },\n",
    "        extractions={\n",
    "            'challenge': [DocManager.remove_citations(DocManager.remove_space_before_punct(sent)) for sent in doc.get_all_highlighted_sentences('challenge')],\n",
    "            'approach': [DocManager.remove_citations(DocManager.remove_space_before_punct(sent)) for sent in doc.get_all_highlighted_sentences('approach')],\n",
    "            'outcome': [DocManager.remove_citations(DocManager.remove_space_before_punct(sent)) for sent in doc.get_all_highlighted_sentences('outcome')],\n",
    "        }\n",
    "    ).model_dump())\n",
    "    \n",
    "with jsonlines.open(f'../../data/ACLSum/{split}_dataset.jsonl', 'w') as f_out:\n",
    "    f_out.write_all(aclsum_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[0].get_all_highlighted_sentences('challenge')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset config\n",
    "split = 'train'\n",
    "load_from_pdf = False\n",
    "question_type = 'challenge'\n",
    "\n",
    "# Chunk config\n",
    "sent_chunk = True\n",
    "max_seq_len = None\n",
    "k = 10\n",
    "# sent_chunk = False\n",
    "# max_seq_len = None\n",
    "# k = 10\n",
    "# sent_chunk = False\n",
    "# max_seq_len = 100\n",
    "# k = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with jsonlines.open(f'../../data/ACLSum/{split}_dataset.jsonl') as f_in:\n",
    "    aclsum_dataset = [Sample.model_validate(line) for line in f_in]\n",
    "    for sid, sample in enumerate(tqdm(aclsum_dataset)):\n",
    "        if load_from_pdf:\n",
    "            # Load from full pdf\n",
    "            doc_file = f\"../../data/ACLSum/{sample.doc_file.split('/')[-1]}\"\n",
    "            outline_file = f\"../../data/ACLSum/outline_{sample.doc_file.split('/')[-1].replace('.pdf', '.txt')}\"\n",
    "            if not os.path.exists(doc_file):\n",
    "                download_file(sample.doc_file, doc_file)\n",
    "            if os.path.exists(outline_file):\n",
    "                with open(outline_file) as f:\n",
    "                    outline = f.read()\n",
    "            else:\n",
    "                outline = None\n",
    "            doc_manager.load_doc(doc_file, outline)\n",
    "            if not outline:\n",
    "                with open(outline_file, 'w') as f:\n",
    "                    f.write(doc_manager.full_outline)\n",
    "        else:\n",
    "            # Load from partial text\n",
    "            doc_manager.load_doc(doc_strs=sample.doc_strs, outline=sample.outline)\n",
    "            \n",
    "        unique_ngram2sent = get_sent_index([sent.text for sent in doc_manager.sents])\n",
    "        doc_manager.build_chunks(sent_chunk=sent_chunk, max_seq_length=max_seq_len)\n",
    "        agentic_rag.load_langgraph([RetrieveByDenseRetrieval(doc_manager, k), RewriteQuestion])\n",
    "        process = agentic_rag.invoke(sample.questions[question_type])\n",
    "        process_file = f'../../data/ACLSum/generation/{split}_{sid}_{question_type}_{load_from_pdf}_{sent_chunk}_{max_seq_len}_{k}.json'\n",
    "        AgenticRAG.dump_process(process, process_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_file = f'../../data/ACLSum/generation/{split}_{3}_{question_type}_{load_from_pdf}_{sent_chunk}_{max_seq_len}_{k}.json'\n",
    "process = AgenticRAG.load_process(process_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "message = process[0]['agent']['messages'][0].model_dump()\n",
    "message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieved_sents = passages if sent_chunk else [sent for passage in passages for sent in sent_tokenize(passage)]\n",
    "retrieved_sent_ids = get_binary_sent_ids(retrieved_sents, unique_ngram2sent)\n",
    "gold_sent_ids = get_binary_sent_ids(test_sample.extractions[question_type], unique_ngram2sent)\n",
    "eval_metrics.eval_precision_recall_f1(predictions=retrieved_sent_ids, references=gold_sent_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SciREX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Salient Entity Extraction\n",
    "  + Extract the salient Dataset, Method, Task and Metric of the paper.\n",
    "  + An entity is extracted if one of its mentions is being returned.\n",
    "+ Salient Entity Mention Extraction\n",
    "  + Extract the sentences where a salient entity's mention appear.\n",
    "  + An entity mention is extracted if the sentence containing the mention is extracted.\n",
    "+ Salient N-ary Relation Extraction\n",
    "  + Extract the Dataset, Method, Task and Metric tuples that are bounded together."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Observation and Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with jsonlines.open('../../data/SciREX/train.jsonl') as f_in:\n",
    "    scirex_dataset = list(f_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sample = scirex_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sample.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sample['n_ary_relations']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sample['doc_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sample['words'][12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from time import sleep\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "failed_ids = []\n",
    "for sample in tqdm(scirex_dataset[2:]):\n",
    "    paper_meta = requests.get(f\"https://api.semanticscholar.org/graph/v1/paper/{sample['doc_id']}\", params={'fields': 'externalIds'}).json()\n",
    "    while 'externalIds' not in paper_meta:\n",
    "        sleep(10)\n",
    "        paper_meta = requests.get(f\"https://api.semanticscholar.org/graph/v1/paper/{sample['doc_id']}\", params={'fields': 'externalIds'}).json()\n",
    "    if 'ArXiv' not in paper_meta['externalIds']:\n",
    "        failed_ids.append(sample['doc_id'])\n",
    "        continue\n",
    "    download_file(f\"https://arxiv.org/pdf/{paper_meta['externalIds']['ArXiv']}\", f\"../../data/SciREX/pdfs/{sample['doc_id']}.pdf\")\n",
    "    sleep(2)\n",
    "with open('../../data/SciREX/failed_ids.txt', 'w') as f_out:\n",
    "    f_out.write('\\n'.join(failed_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_manager = DocManager()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_file = f\"../../data/SciREX/pdfs/{test_sample['doc_id']}.pdf\"\n",
    "if os.path.exists(test_file):\n",
    "    doc_manager.load_doc(test_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(doc_manager.outline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_manager.get_section_by_header('6. Conclusion').text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_manager.sections[5].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_manager.sections[3].blocks[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# doc_strs = list[str]()\n",
    "# for section_range in test_sample['sections']:\n",
    "#     section_words = test_sample['words'][section_range[0]:section_range[1]]\n",
    "#     if section_words[0] == 'section' and section_words[1] == ':':\n",
    "#         section_words = section_words[2:]\n",
    "#     doc_strs.append(' '.join(section_words))\n",
    "'https://arxiv.org/pdf/2210.14427'\n",
    "doc_manager.load_doc(doc_file='https://arxiv.org/pdf/1611.08323')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sample['sentences']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sample['method_subrelations']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Self-RAG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plan and Solve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CoT"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dkg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
