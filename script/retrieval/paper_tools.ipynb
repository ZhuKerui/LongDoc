{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict, Counter\n",
    "import math\n",
    "import re\n",
    "import pymupdf\n",
    "import pymupdf4llm\n",
    "from nltk import sent_tokenize, word_tokenize\n",
    "import os\n",
    "from openai import OpenAI\n",
    "client = OpenAI(api_key=os.environ['OPENAI_AUTO_SURVEY'])\n",
    "\n",
    "import spacy\n",
    "import spacy.tokens\n",
    "import pytextrank\n",
    "from fastcoref import spacy_component\n",
    "import numpy as np\n",
    "\n",
    "# nlp.add_pipe(\"fastcoref\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question decompose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_general_term_prompt = '''The following task involves extracting specific information from a paper. The task description may include general terms that represent types of concrete entities, which need to be identified and clarified based on the paper. Your objective is to identify and list **ALL** general terms or concepts in the task description that might be open to interpretation, require further specification using details from the paper and be critical in locating relevant information in the paper. These include:\n",
    "    1.\tSpecific entities, models, methods, or processes referenced in the description.\n",
    "    2.\tBroad categories or classifications that require more detailed breakdowns.\n",
    "    3.\tImplicit generalizations or assumptions that could benefit from contextual examples or precise definitions.\n",
    "\n",
    "Some general terms may refer to the same entity in the description. You should only list one general term for each entity. Make sure you cover **ALL** the entities.\n",
    "\n",
    "Task: {task}'''\n",
    "\n",
    "\n",
    "organize_general_term_prompt = '''Understand the hierarchy among the general terms you listed above with respect to the \"Parent-Child\" relationship:\n",
    "\n",
    "Parent Concept:\n",
    "A parent concept represents a broader, overarching idea or category that serves as the foundation for related subordinate ideas. It is independent and provides the contextual framework or structure for its associated dependent concepts.\n",
    "\n",
    "Child Concept:\n",
    "A child concept is a more specific, subordinate idea that derives meaning, classification, or context from its associated parent concept. It depends on the parent concept for its definition and existence within a hierarchical structure.\n",
    "\n",
    "Organize the general terms you listed above hierarchically based on their dependencies, ensuring that parent concepts are listed first, followed by their dependent child concepts. Use indentation to represent the hierarchy, with the format as follows:\n",
    "\n",
    "1.\tParent concept\n",
    "    1.1 Dependent child concept\n",
    "        1.1.1 Dependent grandchild concept\n",
    "        1.1.2 Dependent grandchild concept\n",
    "    1.2 Dependent child concept\n",
    "2.\tParent concept\n",
    "    2.1 Dependent child concept\n",
    "\n",
    "Only use the general terms identified in your previous response to create this hierarchical structure.'''\n",
    "\n",
    "generate_checkpoint_prompt = '''To find the relevant information step by step, break down the task into a series of simple, single-step questions. Each question should be narrowly focused, collecting or verifying only one attribute of one entity or entity type, or serving as a follow-up to refine the scope with one additional attribute. Each question can be either a \"What\" question or a \"True or False\" question. Always start with questions for the low level entities (child entities) and then move forward to questions for their parent entity. This structured approach ensures clarity and precision in locating relevant information from the paper.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# task = '''Extract the modeling paradigms proposed in the paper that satisfy the following type:\n",
    "\n",
    "# LLM Embeddings + RS. This modeling paradigm views the language model as a feature extractor, which feeds the features of items and users into LLMs and outputs corresponding embeddings. A traditional RS model can utilize knowledge-aware embeddings for various recommendation tasks.'''\n",
    "\n",
    "task = '''Extract the modeling paradigms proposed in the paper that satisfy the following type:\n",
    "\n",
    "LLM as RS. This paradigm aims to directly transfer pre-trained LLM into a powerful recommendation system. The input sequence usually consists of the profile description, behavior prompt, and task instruction. The output sequence is expected to offer a reasonable recommendation result.'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sub-questions are designed to find necessary information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_completion = client.chat.completions.create(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": extract_general_term_prompt.format(task=task),\n",
    "        }\n",
    "    ],\n",
    "    model=GPT_MODEL_EXPENSIVE,\n",
    ")\n",
    "general_term_str = chat_completion.choices[0].message.content\n",
    "print(general_term_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_completion = client.chat.completions.create(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": extract_general_term_prompt.format(task=task),\n",
    "        }, {\n",
    "            \"role\": \"assistant\",\n",
    "            \"content\": general_term_str,\n",
    "        }, {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": organize_general_term_prompt,\n",
    "        }\n",
    "    ],\n",
    "    model=GPT_MODEL_EXPENSIVE,\n",
    ")\n",
    "general_term_hierarchy_str = chat_completion.choices[0].message.content\n",
    "print(general_term_hierarchy_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_completion = client.chat.completions.create(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": extract_general_term_prompt.format(task=task),\n",
    "        }, {\n",
    "            \"role\": \"assistant\",\n",
    "            \"content\": general_term_str,\n",
    "        }, {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": organize_general_term_prompt,\n",
    "        }, {\n",
    "            \"role\": \"assistant\",\n",
    "            \"content\": general_term_hierarchy_str,\n",
    "        }, {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": generate_checkpoint_prompt,\n",
    "        }\n",
    "    ],\n",
    "    model=GPT_MODEL_EXPENSIVE,\n",
    ")\n",
    "checkpoint_str = chat_completion.choices[0].message.content\n",
    "print(checkpoint_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some necessary sub-questions are not asked in the above example.\n",
    "The sub-questions above are more about asking definition of terms.\n",
    "Check how other papers do question decomposition."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sci_review.paper import *\n",
    "import spacy.displacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from run_aclsum import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# doc_file = '../../data/systematic_review_papers/planning/CALM.pdf'\n",
    "# doc_file = 'aclsum.pdf'\n",
    "doc_file = f'{ACLSUM_PDF_DIR}/P19-1352.pdf' # 41\n",
    "outline = '''```\n",
    "1 Abstract\n",
    "2 Introduction\n",
    "3 Approach\n",
    "    3.1 Shared-Private Bilingual Word Embeddings\n",
    "        3.1.1 Words with Similar Lexical Meaning\n",
    "        3.1.2 Words with Same Word Form\n",
    "        3.1.3 Unrelated Words\n",
    "    3.2 Implementation\n",
    "4 Experiments\n",
    "    4.1 Setup\n",
    "    4.2 Main Results\n",
    "    4.3 Effect on Sharing Coefficients\n",
    "    4.4 Effect on Alignment Quality\n",
    "    4.5 Analysis of the Translation Results\n",
    "    4.6 Analysis of the Learned Embeddings\n",
    "5 Related Work\n",
    "6 Conclusion\n",
    "Acknowledgements\n",
    "References\n",
    "```\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Todo The following section name is placed in the wrong position in the table of content. Please ensure that all sections are listed in the correct order as they appear in the paper.\n",
    "\n",
    "# 2.1 Tree Substitution Grammar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('words_alpha.txt') as f:\n",
    "    words_alpha = set(f.read().splitlines())\n",
    "doc = DocManager(word_vocab=words_alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc.load_doc(doc_file, outline=outline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(doc.full_outline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"{ACLSUM_PDF_DIR}/outline_E06-1051.txt\", 'w') as f:\n",
    "    f.write(doc.full_outline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(doc.sections[1].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(doc.outline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc.sections[4].header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc.full_outline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(doc.sections[20].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot DKG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc.plot_dkg()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dkg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
