{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict, Counter\n",
    "import math\n",
    "import re\n",
    "import pymupdf\n",
    "import pymupdf4llm\n",
    "from nltk import sent_tokenize, word_tokenize\n",
    "import os\n",
    "from openai import OpenAI\n",
    "client = OpenAI(api_key=os.environ['OPENAI_AUTO_SURVEY'])\n",
    "\n",
    "import spacy\n",
    "import spacy.tokens\n",
    "import pytextrank\n",
    "from fastcoref import spacy_component\n",
    "import numpy as np\n",
    "\n",
    "# nlp.add_pipe(\"fastcoref\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question decompose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_general_term_prompt = '''The following task involves extracting specific information from a paper. The task description may include general terms that represent types of concrete entities, which need to be identified and clarified based on the paper. Your objective is to identify and list **ALL** general terms or concepts in the task description that might be open to interpretation, require further specification using details from the paper and be critical in locating relevant information in the paper. These include:\n",
    "    1.\tSpecific entities, models, methods, or processes referenced in the description.\n",
    "    2.\tBroad categories or classifications that require more detailed breakdowns.\n",
    "    3.\tImplicit generalizations or assumptions that could benefit from contextual examples or precise definitions.\n",
    "\n",
    "Some general terms may refer to the same entity in the description. You should only list one general term for each entity. Make sure you cover **ALL** the entities.\n",
    "\n",
    "Task: {task}'''\n",
    "\n",
    "\n",
    "organize_general_term_prompt = '''Understand the hierarchy among the general terms you listed above with respect to the \"Parent-Child\" relationship:\n",
    "\n",
    "Parent Concept:\n",
    "A parent concept represents a broader, overarching idea or category that serves as the foundation for related subordinate ideas. It is independent and provides the contextual framework or structure for its associated dependent concepts.\n",
    "\n",
    "Child Concept:\n",
    "A child concept is a more specific, subordinate idea that derives meaning, classification, or context from its associated parent concept. It depends on the parent concept for its definition and existence within a hierarchical structure.\n",
    "\n",
    "Organize the general terms you listed above hierarchically based on their dependencies, ensuring that parent concepts are listed first, followed by their dependent child concepts. Use indentation to represent the hierarchy, with the format as follows:\n",
    "\n",
    "1.\tParent concept\n",
    "    1.1 Dependent child concept\n",
    "        1.1.1 Dependent grandchild concept\n",
    "        1.1.2 Dependent grandchild concept\n",
    "    1.2 Dependent child concept\n",
    "2.\tParent concept\n",
    "    2.1 Dependent child concept\n",
    "\n",
    "Only use the general terms identified in your previous response to create this hierarchical structure.'''\n",
    "\n",
    "generate_checkpoint_prompt = '''To find the relevant information step by step, break down the task into a series of simple, single-step questions. Each question should be narrowly focused, collecting or verifying only one attribute of one entity or entity type, or serving as a follow-up to refine the scope with one additional attribute. Each question can be either a \"What\" question or a \"True or False\" question. Always start with questions for the low level entities (child entities) and then move forward to questions for their parent entity. This structured approach ensures clarity and precision in locating relevant information from the paper.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# task = '''Extract the modeling paradigms proposed in the paper that satisfy the following type:\n",
    "\n",
    "# LLM Embeddings + RS. This modeling paradigm views the language model as a feature extractor, which feeds the features of items and users into LLMs and outputs corresponding embeddings. A traditional RS model can utilize knowledge-aware embeddings for various recommendation tasks.'''\n",
    "\n",
    "task = '''Extract the modeling paradigms proposed in the paper that satisfy the following type:\n",
    "\n",
    "LLM as RS. This paradigm aims to directly transfer pre-trained LLM into a powerful recommendation system. The input sequence usually consists of the profile description, behavior prompt, and task instruction. The output sequence is expected to offer a reasonable recommendation result.'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sub-questions are designed to find necessary information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_completion = client.chat.completions.create(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": extract_general_term_prompt.format(task=task),\n",
    "        }\n",
    "    ],\n",
    "    model=GPT_MODEL_EXPENSIVE,\n",
    ")\n",
    "general_term_str = chat_completion.choices[0].message.content\n",
    "print(general_term_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_completion = client.chat.completions.create(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": extract_general_term_prompt.format(task=task),\n",
    "        }, {\n",
    "            \"role\": \"assistant\",\n",
    "            \"content\": general_term_str,\n",
    "        }, {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": organize_general_term_prompt,\n",
    "        }\n",
    "    ],\n",
    "    model=GPT_MODEL_EXPENSIVE,\n",
    ")\n",
    "general_term_hierarchy_str = chat_completion.choices[0].message.content\n",
    "print(general_term_hierarchy_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_completion = client.chat.completions.create(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": extract_general_term_prompt.format(task=task),\n",
    "        }, {\n",
    "            \"role\": \"assistant\",\n",
    "            \"content\": general_term_str,\n",
    "        }, {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": organize_general_term_prompt,\n",
    "        }, {\n",
    "            \"role\": \"assistant\",\n",
    "            \"content\": general_term_hierarchy_str,\n",
    "        }, {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": generate_checkpoint_prompt,\n",
    "        }\n",
    "    ],\n",
    "    model=GPT_MODEL_EXPENSIVE,\n",
    ")\n",
    "checkpoint_str = chat_completion.choices[0].message.content\n",
    "print(checkpoint_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some necessary sub-questions are not asked in the above example.\n",
    "The sub-questions above are more about asking definition of terms.\n",
    "Check how other papers do question decomposition."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/keruiz2/miniconda3/envs/dkg/lib/python3.11/site-packages\n"
     ]
    }
   ],
   "source": [
    "from sci_review.paper import *\n",
    "from sci_review.text import *\n",
    "import spacy.displacy\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# doc_file = '../../data/systematic_review_papers/planning/CALM.pdf'\n",
    "doc_file = 'aclsum.pdf'\n",
    "outline = '''1 Introduction\n",
    "2 Related Work\n",
    "    Unfaithful summaries.\n",
    "    Noisy data.\n",
    "    Legal issues.\n",
    "    Missing gold extractive labels.\n",
    "3 Dataset creation\n",
    "    Source documents\n",
    "    Summary aspects\n",
    "    Annotation process\n",
    "4 ACLS UM\n",
    "5 Experiments and Results\n",
    "    5.1 RQ1: Extract-then-abstract vs. end-to-end\n",
    "        Experimental setup.\n",
    "        Results and discussions.\n",
    "    5.2 RQ2: CoT vs. E2E instruct-tuning\n",
    "        Experimental setup.\n",
    "        Results and discussions.\n",
    "    5.3 RQ3: How good is the heuristic for inducing extractive summarization labels?\n",
    "6 Conclusion\n",
    "7 Limitations\n",
    "References'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01/25/2025 14:08:51 - INFO - \t missing_keys: []\n",
      "01/25/2025 14:08:51 - INFO - \t unexpected_keys: []\n",
      "01/25/2025 14:08:51 - INFO - \t mismatched_keys: []\n",
      "01/25/2025 14:08:51 - INFO - \t error_msgs: []\n",
      "01/25/2025 14:08:51 - INFO - \t Model Parameters: 90.5M, Transformer: 82.1M, Coref head: 8.4M\n",
      "01/25/2025 14:08:52 - INFO - \t Load pretrained SentenceTransformer: sentence-transformers/all-mpnet-base-v2\n"
     ]
    }
   ],
   "source": [
    "with open('words_alpha.txt') as f:\n",
    "    words_alpha = set(f.read().splitlines())\n",
    "doc = DocManager(word_vocab=words_alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01/25/2025 14:08:59 - INFO - \t Tokenize 20 inputs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67af0515c8464259813105b646d8c868",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/20 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01/25/2025 14:09:01 - INFO - \t ***** Running Inference on 20 texts *****\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5dd31f9f09e646baba365ac22e264aee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Inference:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01/25/2025 14:09:03 - INFO - \t Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.\n"
     ]
    }
   ],
   "source": [
    "doc.load_doc(doc_file, outline=outline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing gold extractive labels.\n",
      "\n",
      "While extractive and aspect-based summarization are both active research subjects, there are no freely available datasets with ground-truth labels for such tasks. For extractive summarization, the de facto standard approach has been relying on a heuristic-based algorithm that automatically induces labels from abstractive summarization datasets without validating its effectiveness, including recent improvements from Xu and Lapata (2022).\n",
      "\n",
      "The work closest to ours is SQuALITY from Wang et al. (2022). While this work shares the core motivation with our work, which is to build a reliable and validated summarization dataset, our dataset has several different properties. First, besides the abstractive reference summaries, our dataset also has passage annotations (i.e., aspects) that can serve as gold labels for extractive summarization. Second, in contrast to the SQuALITY, which provides question-focused summaries, our dataset has multi-aspect summaries more suitable for our target scholarly domain. Third, SQuALITY uses novel stories as its source documents, whereas our dataset uses research articles from the field of NLP, which makes our dataset highly domain-specific and challenging. Lastly, the size: our ACLS UM contains 250 documents, which is more than twice larger than the 100 documents provided in SQuALITY. Another work similar to ours is SciTLDR, a collection of papers from computer science and one-sentence summaries, later extended by Takeshita et al. (2022) for cross-lingual summarization. This work has inspired us to design reference summaries in our dataset to have one-sentence summaries. Our work differs from theirs in (i) the structure of summaries: ours has multi-aspect summaries instead of one overview summary, (ii) type of annotations: while SciTLDR contains only abstractive reference summaries, our dataset also contains annotations of the relevant sentences.\n"
     ]
    }
   ],
   "source": [
    "print(doc.sections[5].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot DKG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dash app running on http://128.174.136.27:8051/\n"
     ]
    }
   ],
   "source": [
    "import dash\n",
    "import dash_cytoscape as cyto\n",
    "from dash import html\n",
    "\n",
    "y_start = 0\n",
    "width = 80\n",
    "nodes = []\n",
    "for section in doc.sections:\n",
    "    if section.section_nlp_local:\n",
    "        # start_idx = 0\n",
    "        for sent in section.section_nlp_local.sents:\n",
    "            start_idx = sent[0].idx\n",
    "            last_chunk_tid = sent.start + section.section_nlp_global.start\n",
    "            last_chunk_id = doc.tid2phrase_id[last_chunk_tid]\n",
    "            curr_chunk_tid = last_chunk_tid\n",
    "            curr_chunk_id = last_chunk_id\n",
    "            for token in sent[1:]:\n",
    "                curr_chunk_tid = token.i + section.section_nlp_global.start\n",
    "                curr_chunk_id = doc.tid2phrase_id[curr_chunk_tid]\n",
    "                if curr_chunk_id != last_chunk_id:\n",
    "                    dist2start = doc.doc_spacy[last_chunk_tid].idx - section.section_nlp_global[0].idx - start_idx\n",
    "                    if dist2start > width:\n",
    "                        y_start += 20\n",
    "                        start_idx = doc.doc_spacy[last_chunk_tid].idx - section.section_nlp_global[0].idx\n",
    "                        dist2start = 0\n",
    "                    nodes.append({'data': {'id': last_chunk_tid, 'label': doc.doc_spacy[last_chunk_tid:curr_chunk_tid].text}, 'position': {'x': dist2start * 6.1, 'y': y_start}, 'classes': 'noun_phrase' if last_chunk_id >= 0 else 'text', 'locked': True})\n",
    "                    last_chunk_tid = curr_chunk_tid\n",
    "                    last_chunk_id = curr_chunk_id\n",
    "            dist2start = doc.doc_spacy[last_chunk_tid].idx - section.section_nlp_global[0].idx - start_idx\n",
    "            if dist2start > width:\n",
    "                y_start += 20\n",
    "                start_idx = doc.doc_spacy[last_chunk_tid].idx - section.section_nlp_global[0].idx\n",
    "                dist2start = 0\n",
    "            nodes.append({'data': {'id': last_chunk_tid, 'label': doc.doc_spacy[last_chunk_tid:sent.end+section.section_nlp_global.start].text}, 'position': {'x': dist2start * 6.1, 'y': y_start}, 'classes': 'noun_phrase' if last_chunk_id >= 0 else 'text', 'locked': True})\n",
    "            y_start += 50\n",
    "        y_start += 100\n",
    "        \n",
    "edges = [{'data': {'source': doc.phrases[u].start, 'target': doc.phrases[v].start, 'type': edge_type}} for u, v, edge_type in dkg.edges]\n",
    "\n",
    "app = dash.Dash(__name__)\n",
    "app.layout = html.Div([\n",
    "    cyto.Cytoscape(\n",
    "        id='cytoscape',\n",
    "        # elements=[\n",
    "        #     {'data': {'id': 'one', 'label': 'Node 1'}, 'position': {'x': 50, 'y': 50}},\n",
    "        #     {'data': {'id': 'two', 'label': 'Node 2'}, 'position': {'x': 200, 'y': 200}},\n",
    "        #     {'data': {'source': 'one', 'target': 'two','label': 'Node 1 to 2'}}\n",
    "        # ],\n",
    "        # elements=[{'data': {'id': token.i, 'label': token.text}, 'position': {'x': (token.idx - sent[0].idx) * 6, 'y': 0}} for token in sent],\n",
    "        elements=nodes+edges,\n",
    "        layout={'name': 'preset',\n",
    "                'zoomingEnabled': False,\n",
    "                },\n",
    "        style={\n",
    "            # 'width': '1000px', \n",
    "            'height': '2000px', \n",
    "            # 'height': '100%',\n",
    "            'backgroundColor': \"#1E1E1E\",\n",
    "        },\n",
    "        stylesheet=[\n",
    "            {\n",
    "                'selector': 'node',\n",
    "                'style': {\n",
    "                    'label': 'data(label)',\n",
    "                    'font-family': 'Courier',\n",
    "                    'font-size': '10',\n",
    "                    'text-halign': 'right',\n",
    "                    'width': '1',\n",
    "                    'height': '1',\n",
    "                    'color': \"#ce9178\",\n",
    "                    # 'autoungrabify': True,\n",
    "                }\n",
    "            },\n",
    "            {\n",
    "                'selector': '.noun_phrase',\n",
    "                'style': {\n",
    "                    # 'label': 'data(label)',\n",
    "                    # 'font-family': 'Courier',\n",
    "                    # 'font-weight': 'bold',\n",
    "                    # 'text-halign': 'right',\n",
    "                    # 'width': '1',\n",
    "                    # 'height': '1',\n",
    "                    'color': \"#9CDCFE\",\n",
    "                    'font-weight': 'bold',\n",
    "                }\n",
    "            },\n",
    "            {\n",
    "                'selector': 'edge',\n",
    "                'style': {\n",
    "                    # 'label': 'data(label)',\n",
    "                    # 'font-family': 'Courier New',\n",
    "                    # 'font-size': '12px'\n",
    "                    'curve-style': 'unbundled-bezier',\n",
    "                    'target-arrow-shape': 'vee',\n",
    "                    'width': 1,\n",
    "                    'opacity': 0.3\n",
    "                }\n",
    "            },\n",
    "            {\n",
    "                'selector': f'edge[type = \"{SUBJ_OBJ}\"]', \n",
    "                'style': {\n",
    "                    'line-color': \"#C586C0\",\n",
    "                    'target-arrow-color': \"#C586C0\",\n",
    "                }\n",
    "            },\n",
    "            {\n",
    "                'selector': f'edge[type = \"{COREF}\"]', \n",
    "                'style': {\n",
    "                    'line-color': \"#4EC9B0\", \n",
    "                    'line-style': 'dashed',\n",
    "                    'target-arrow-color': \"#4EC9B0\",\n",
    "                }\n",
    "            },\n",
    "            {\n",
    "                'selector': f'edge[type = \"{SHARED_TEXT}\"]', \n",
    "                'style': {\n",
    "                    'line-color': \"#4FC1FF\", \n",
    "                    'line-style': 'dashed',\n",
    "                    'target-arrow-color': \"#4FC1FF\",\n",
    "                }\n",
    "            }\n",
    "        ]\n",
    "    )\n",
    "])\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run_server(jupyter_mode=\"external\", port=8051, host='128.174.136.27')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dkg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
