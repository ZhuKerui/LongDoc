{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "# os.environ[\"LANGCHAIN_API_KEY\"] = getpass.getpass()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import things that are needed generically\n",
    "from langchain.pydantic_v1 import BaseModel, Field\n",
    "from langchain.tools import BaseTool, StructuredTool, tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SearchNextStep(BaseModel):\n",
    "    summary_level: str = Field(description='the summary level under which the sub-tree will be explored.', default='summary_0')\n",
    "    query: str = Field(description='a query for the information you expect to find in the sub-tree')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, Optional, Type\n",
    "\n",
    "\n",
    "    \n",
    "class SummaryTree(BaseTool):\n",
    "    name = 'branch retrieval'\n",
    "    description = ' '.join('''\n",
    "        This tool organizes the document in a summary tree. \n",
    "        The leaf nodes are the chunks from the document and the non-leaf nodes are the summaries of their children. \n",
    "        Higher-level nodes contain more general but less reliable information. \n",
    "        In the initial call, \n",
    "        Given a query, if  and a summary level, the tool will return the relevant chunk and all its ancestors as a branch in the summary tree. provide the multi-granularity context. \n",
    "        This context is useful in connecting the current relevant node with the remaining parts in the document.\n",
    "    '''.split())\n",
    "    args_schema: Type[BaseModel] = SearchNextStep\n",
    "    return_direct: bool = False\n",
    "    \n",
    "    def __init__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import TreeIndex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.node_parser import SentenceSplitter, SemanticSplitterNodeParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SemanticSplitterNodeParser()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NavigateAgent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../..')\n",
    "\n",
    "from src.summary_tree import *\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from langsmith import Client\n",
    "from langsmith.schemas import Run\n",
    "from uuid import UUID\n",
    "import pickle\n",
    "\n",
    "client = Client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_map = defaultdict(list)\n",
    "trace2runs: Dict[UUID, Dict[int, List[Run]]] = {}\n",
    "for project in tqdm(client.list_projects(), total=38):\n",
    "    traces = list(client.list_runs(project_name=project.name, is_root=True))\n",
    "    trace_ids = [t.trace_id for t in traces]\n",
    "    if 'tree' in project.name:\n",
    "        project_map['tree'].extend(trace_ids)\n",
    "    elif 'dpr' in project.name:\n",
    "        project_map['dpr'].extend(trace_ids)\n",
    "    for trace in traces:\n",
    "        runs = [d for d in client.list_runs(run_ids=trace.child_run_ids) if 'langgraph_node' in d.extra['metadata']][::-1]\n",
    "        step2runs = defaultdict(list)\n",
    "        for run in runs:\n",
    "            step2runs[run.extra['metadata']['langgraph_step']].append({'metadata': run.extra['metadata'], 'inputs': run.inputs, 'outputs': run.outputs})\n",
    "        trace2runs[trace.trace_id] = step2runs\n",
    "\n",
    "with open('result.pickle', 'wb') as f_out:\n",
    "    pickle.dump(trace2runs, f_out)\n",
    "    \n",
    "with open('project_map.pickle', 'wb') as f_out:\n",
    "    pickle.dump(project_map, f_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('result.pickle', 'rb') as f_in:\n",
    "    trace2runs = pickle.load(f_in)\n",
    "    \n",
    "with open('project_map.pickle', 'rb') as f_in:\n",
    "    project_map = pickle.load(f_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_steps(step2runs:Dict[int, Any], node:str):\n",
    "    return [step for step, runs in step2runs.items() if runs and runs[0]['metadata']['langgraph_node'] == node]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trace_keys = [trace_key for trace_key, step2runs in trace2runs.items() if get_steps(step2runs, NavigateAgent.Nodes.REFORM_QUERY) and get_steps(step2runs, NavigateAgent.Nodes.GENERATE_ANSWER)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(trace_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = defaultdict(list)\n",
    "proposes = defaultdict(list)\n",
    "for trace_key in trace_keys:\n",
    "    step2runs = trace2runs[trace_key]\n",
    "    answer_steps = get_steps(step2runs, NavigateAgent.Nodes.GENERATE_ANSWER)\n",
    "    reform_steps = get_steps(step2runs, NavigateAgent.Nodes.REFORM_QUERY)\n",
    "    propose_num = 0\n",
    "    accept_num = 0\n",
    "    temp_proposes = []\n",
    "    for s in reform_steps:\n",
    "        propose_num += len(step2runs[s+1][0]['outputs']['output']['new_document_ids'])\n",
    "        if len(step2runs[s+1][0]['outputs']['output']['new_document_ids']):\n",
    "            temp_proposes.append(len(step2runs[s+1][0]['outputs']['output']['new_document_ids']))\n",
    "        accept_num += len(step2runs[s+2][0]['outputs']['output']['new_document_ids'])\n",
    "        if len(step2runs[s+2][0]['outputs']['output']['new_document_ids']) == 0:\n",
    "            break\n",
    "    \n",
    "    if propose_num > 0:\n",
    "        if trace_key in project_map['dpr']:\n",
    "            scores['dpr'].append(accept_num * 1. / propose_num)\n",
    "            proposes['dpr'].extend(temp_proposes)\n",
    "        if trace_key in project_map['tree']:\n",
    "            scores['tree'].append(accept_num * 1. / propose_num)\n",
    "            proposes['tree'].extend(temp_proposes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(scores['dpr'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(proposes['dpr'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(scores['dpr'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(scores['tree'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(proposes['tree'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(scores['tree'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "propose_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accept_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grades = [run['outputs']['output']['score'] for grade_step in grade_steps for run in step2runs[grade_step] if 'output' in run['outputs'] and 'score' in run['outputs']['output']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grade_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[run['outputs'] for run in step2runs[grade_steps[1]]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[run['outputs'] for run in step2runs[retrieve_steps[1]]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_steps(step2runs, NavigateAgent.Nodes.REFORM_QUERY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "step2runs[4][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_steps(step2runs, NavigateAgent.Nodes.GENERATE_ANSWER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[run.inputs for run in step2runs[5]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "step2runs[6][0].extra['metadata']['langgraph_node']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "step = 4\n",
    "print(step2runs[step][0].extra['metadata']['langgraph_node'])\n",
    "print(step2runs[step][0].inputs['input'])\n",
    "print(step2runs[step][0].outputs['output'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c[3].extra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c[1].outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"EMPTY\"\n",
    "f = Factory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = QualityDataset(None, split='dev')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_id = 19\n",
    "article = dataset.get_article(dataset.data[test_id])\n",
    "questions, answers = dataset.get_questions_and_answers(dataset.data[test_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dpr_retriever, tree_retriever, documents = f.build_corpus(article, dpr_file=os.path.join(dataset.data_dir, f'dpr_{test_id}.json'), tree_file=os.path.join(dataset.data_dir, f'tree_{test_id}.json'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_retriever.retrieve_children(tree_retriever.docs[14])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "longdoc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
